%% Generated by Sphinx.
\def\sphinxdocclass{jupyterBook}
\documentclass[letterpaper,10pt,english]{jupyterBook}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]


\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}



         \usepackage[Latin,Greek]{ucharclasses}
        \usepackage{unicode-math}
        % fixing title of the toc
        \addto\captionsenglish{\renewcommand{\contentsname}{Contents}}
        

\title{Mathematics for Natural Sciences 2}
\date{Jan 30, 2022}
\release{}
\author{Natural Sciences}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{intro::doc}}


\sphinxAtStartPar
This module is designed as a follow on to NSCI0005, a second module mathematical methods for natural sciences students.  In it we will cover:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Vector methods and multivariable calculus OR Set theory, logic and methods of proof

\item {} 
\sphinxAtStartPar
Matrices, vector spaces and linear algebra

\item {} 
\sphinxAtStartPar
Dynamical systems theory and stability

\end{itemize}


\chapter{Multivariable Calculus}
\label{\detokenize{VectorCalculus/partialdifferentiation:multivariable-calculus}}\label{\detokenize{VectorCalculus/partialdifferentiation::doc}}

\section{First Partial Derivatives}
\label{\detokenize{VectorCalculus/partialdifferentiation:first-partial-derivatives}}
\sphinxAtStartPar
The plot shown in \hyperref[\detokenize{VectorCalculus/partialdifferentiation:surf1}]{Fig.\@ \ref{\detokenize{VectorCalculus/partialdifferentiation:surf1}}} is of a function, \(f(x,\, y)= x^3 - y^3 - 2xy + 2\), on which curves marked on the surface for lines of constant \(x,\,y\).

\sphinxAtStartPar
We can consider the rate of change of the function, however since it is a function of two variables, we can see there are two possible kinds of derivative we can find:
\begin{itemize}
\item {} 
\sphinxAtStartPar
along a curve parallel to the \(x\)\sphinxhyphen{}axis, by holding \(y\) constant and differentiating with respect to \(x\).

\item {} 
\sphinxAtStartPar
along a curve parallel to the \(y\)\sphinxhyphen{}axis, by holding \(x\) constant and differentiating with respect to \(y\).

\end{itemize}

\sphinxAtStartPar
We call these partial derivatives, denoted here by:
\begin{equation*}
\begin{split}\frac{\partial f}{\partial x} &=&\,  3x^2 - 2y \quad \textrm{(holding $y$ constant and differentiating with respect to $x$)}\\
\frac{\partial f}{\partial y} &=&\, -3y^2 - 2x \quad \textrm{(holding $x$ constant and differentiating with respect to $y$)}\end{split}
\end{equation*}
\sphinxAtStartPar
note that the notation \(\partial\) is distinct from the \(\mathrm{d}\) used for one variable calculus.  It is partial because we
consider only variations in one of the two variables here.  The results show the local rate of change parallel to each axis at a point \((x,\,y)\).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{surf1}.png}
\caption{A plot of the function \(f(x,\, y) = x^3 - y^3 - 2xy + 2\), along with lines of constant \(x,\,y\).}\label{\detokenize{VectorCalculus/partialdifferentiation:surf1}}\end{figure}

\sphinxAtStartPar
Just like the one variable derivative, there is a limit definition for partial derivatives for a function \(f = f(x,\,y)\):
\begin{equation*}
\begin{split}\frac{\partial f}{\partial x} &=&\, \lim_{\Delta x \rightarrow 0} \left[\frac{f(x + \Delta x,\, y) - f(x,\, y)}{\Delta x} \right]\\
\frac{\partial f}{\partial y} &=&\, \lim_{\Delta x \rightarrow 0} \left[\frac{f(x,\, y + \Delta y) - f(x,\, y)}{\Delta y} \right]\end{split}
\end{equation*}
\sphinxAtStartPar
By way of examples, we can calculate all the first partial derivatives \(\partial/\partial x,\, \partial/\partial y\) for the following functions:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f(x,\,y) = 3x^3 y^2 + 2 y \)

\end{itemize}
\begin{equation*}
\begin{split}\frac{\partial f}{\partial x} &=&\, x^2 y^2, \\
\frac{\partial f}{\partial y} &=&\, 6x^3 y+2\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f(x,\,y) = x^2 \ln(3x+y)\)

\end{itemize}
\begin{equation*}
\begin{split}\frac{\partial f}{\partial x} &=&\, 2x\ln(3x+y) + \frac{3x^2}{3x+y}, \\
\frac{\partial f}{\partial y} &=&\, \frac{x^2}{3x+y}\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
\(z(x,\,y) = \ln(x+y^2\sin(x))\)

\end{itemize}
\begin{equation*}
\begin{split}\frac{\partial z}{\partial x} &=&\, \frac{1+y^2\cos(x)}{x+y^2\sin(x)}, \\
\frac{\partial z}{\partial y} &=&\, \frac{2y\sin(x)}{x+y^2\sin(x)}\end{split}
\end{equation*}

\section{Second Partial Derivatives}
\label{\detokenize{VectorCalculus/partialdifferentiation:second-partial-derivatives}}
\sphinxAtStartPar
The second partial derivatives with respect to \(x\) and \(y\) are denoted as follows:
\begin{equation*}
\begin{split}\frac{\partial^2 f}{\partial x^2} &=&\, \frac{\partial}{\partial x}\left(\frac{\partial f}{\partial x}\right), \\
\frac{\partial^2 f}{\partial y^2} &=&\, \frac{\partial}{\partial y}\left(\frac{\partial f}{\partial y}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
The notation can also be extended to mixed second partial derivative, where we take the \(x\) and the \(y\) partial derivative:
\begin{equation*}
\begin{split}\frac{\partial^2 f}{\partial y \,\partial x} &=&\, \frac{\partial}{\partial y}\left(\frac{\partial f}{\partial x}\right), \\
\frac{\partial^2 f}{\partial x\, \partial y} &=&\, \frac{\partial}{\partial x}\left(\frac{\partial f}{\partial y}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
Notice that we work from the inside out, as with function composition and matrix multiplication.  For any well behaved, differntiable and continuous function,
these two expressions are always equal.  The proof of this result (called Schwarz’s theorem) is quite involved and is beyond the scope of this course.

\sphinxAtStartPar
As an example, lets calculate all second partial derivatives of the function \(f(x,y)=3x^3y^2+2y\)
\begin{equation*}
\begin{split}\frac{\partial f}{\partial x} = 9 x^2 y^2, &\quad&\, \frac{\partial f}{\partial y} = 6 x^3 y + 2, \\
\frac{\partial^2 f}{\partial x^2} = 18x y^2, &\quad&\, \frac{\partial^2 f}{\partial y^2} = 6x^3, \\
\frac{\partial^2 f}{\partial y\,\partial x} = 18x^2 y, &\quad&\, \frac{\partial^2 f}{\partial x\,\partial y} = 18x^2 y \end{split}
\end{equation*}

\section{A Common Mistake}
\label{\detokenize{VectorCalculus/partialdifferentiation:a-common-mistake}}
\sphinxAtStartPar
Lets look at the function \(f(x,\, y) = x^2 y^3 + x + y\) at the point \((1,\, 1)\), calculating the mixed partial derivative:
\begin{equation*}
\begin{split}\frac{\partial^2}{\partial y\,\partial x}(x^2 y^3 + x + y)\end{split}
\end{equation*}
\sphinxAtStartPar
we could argue that we follow the process:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Put \(y=1\) into the function and then differentiate with respect to \(x\) to obtain:

\end{itemize}
\begin{equation*}
\begin{split}\frac{\partial}{\partial x}(x^2+x+1)=2x\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
Then put \(x=1\) into this function and differentiate with respect to \(y\) to obtain:

\end{itemize}
\begin{equation*}
\begin{split}\frac{\partial}{\partial y}(2)=0\end{split}
\end{equation*}
\sphinxAtStartPar
The result is wrong, because we took \(y=1\) before differentiating with respect to \(y\) \sphinxhyphen{} to avoid mistakes of this nature, we should always
perform differentiation first and only substitute in the values in the very last step. The correct result is:
\begin{equation*}
\begin{split}\Bigg[\frac{\partial^2}{\partial y\,\partial x}\left(x^2 y^3 +x+y\right)\Bigg]_{(1,1)} 
= \Bigg[\frac{\partial }{\partial y}(2xy^3+1)\Big]_{(1,1)} = \Big[6xy^2\Bigg]_{(1,1)} = 6\end{split}
\end{equation*}

\section{Notation for Partial Derivatives}
\label{\detokenize{VectorCalculus/partialdifferentiation:notation-for-partial-derivatives}}
\sphinxAtStartPar
Partial derivatives are commonly denoted using subscript notation:
\begin{equation*}
\begin{split}f_x=\frac{\partial f}{\partial x}, &\quad&\, f_y=\frac{\partial f}{\partial y}, \\
\quad f_{xx}=\frac{\partial^2 f}{\partial x^2} &\quad&\, f_{yy}=\frac{\partial^2 f}{\partial y^2}\end{split}
\end{equation*}
\sphinxAtStartPar
For mixed derivatives the order or subscripts is from left to right:
\begin{equation*}
\begin{split}f_{xy} &=&\, (f_x)_y = \frac{\partial^2 f}{\partial y\, \partial x}, \\
f_{yx} &=&\, (f_y)_x = \frac{\partial^2 f}{\partial x\, \partial y}\end{split}
\end{equation*}
\sphinxAtStartPar
You will likely come across yet more alternative notations in the literature, another common one being:
\begin{equation*}
\begin{split}D_x=\frac{\partial}{\partial x}\end{split}
\end{equation*}

\section{Multivariable Chain Rule}
\label{\detokenize{VectorCalculus/partialdifferentiation:multivariable-chain-rule}}
\sphinxAtStartPar
We now consider a function \(f(x,\,y)\) subjected to small variations in both \(x\) and \(y\) as shown in \hyperref[\detokenize{VectorCalculus/partialdifferentiation:two-step}]{Fig.\@ \ref{\detokenize{VectorCalculus/partialdifferentiation:two-step}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{two_step}.png}
\caption{Showing the variations \(f(x+\Delta x, \,y+\Delta y)\) in two steps.}\label{\detokenize{VectorCalculus/partialdifferentiation:two-step}}\end{figure}

\sphinxAtStartPar
Loosely speaking, the total change in the function \(f(x,\, y)\) is the sum of changes due to each variable:
\begin{equation*}
\begin{split}\Delta f = \frac{\partial f}{\partial x}\Delta x + \frac{\partial f}{\partial y}\Delta y\end{split}
\end{equation*}
\sphinxAtStartPar
If we now suppose that we parameterise \(x=x(u,\, v)\) and \(y=y(u,\, v)\) then we may similarly write \(\Delta x\) and \(\Delta y\) as the sum of changes
due to variables \(u\) and \(v\):
\begin{equation*}
\begin{split}\Delta f = \frac{\partial f}{\partial x}\left[\frac{\partial x}{\partial u}\Delta u +\frac{\partial x}{\partial v}\Delta v\right] 
+ \frac{\partial f}{\partial y}\left[\frac{\partial y}{\partial u}\Delta u +\frac{\partial y}{\partial v}\Delta v\right]\end{split}
\end{equation*}
\sphinxAtStartPar
Holding \(v\) constant in this expression (\(\Delta v=0\)) gives:
\begin{equation*}
\begin{split}\frac{\Delta f}{\Delta u}=\frac{\partial f}{\partial x}\frac{\partial x}{\partial u}+\frac{\partial f}{\partial y}\frac{\partial y}{\partial u}\end{split}
\end{equation*}
\sphinxAtStartPar
Holding \(u\) constant in this expression (\(\Delta u=0\)) gives:
\begin{equation*}
\begin{split}\frac{\Delta f}{\Delta v}=\frac{\partial f}{\partial x}\frac{\partial x}{\partial v}+\frac{\partial f}{\partial y}\frac{\partial y}{\partial v}\end{split}
\end{equation*}
\sphinxAtStartPar
This was a somewhat hand\sphinxhyphen{}waving argument, but the results are valid in the limit \(\Delta u\rightarrow 0, \, \Delta v\rightarrow 0\) and can be proved
using the limit definition of the derivative and from this we obtain the multivariable chain rule.

\sphinxAtStartPar
If \(f = f(x,\, y)\) where \(x=x(u,\, v)\) and \(y=y(u,\, v)\) then:
\begin{equation*}
\begin{split}\frac{\partial f}{\partial u} &=&\, \frac{\partial f}{\partial x}\frac{\partial x}{\partial u} + \frac{\partial f}{\partial y}\frac{\partial y}{\partial u}\\
\frac{\partial f}{\partial v} &=&\, \frac{\partial f}{\partial x}\frac{\partial x}{\partial v} + \frac{\partial f}{\partial y}\frac{\partial y}{\partial v}\end{split}
\end{equation*}
\sphinxAtStartPar
Many student’s first go at encountering this rule often think that it “can’t be right”, because replacing the partial derivatives with differences gives:
\begin{equation*}
\begin{split}\Delta f = \frac{\Delta f}{\Delta x}\Delta x + \frac{\Delta f}{\Delta y}\Delta y\end{split}
\end{equation*}
\sphinxAtStartPar
which suggests the result \(\Delta f = 2\Delta f\). However, this misunderstanding comes from ambiguity in writing \(\Delta f\).

\sphinxAtStartPar
On the left\sphinxhyphen{}hand side it means changes in \(f\) dues to variations in both \(x\) and \(y\), whilst in \(f_x\) and \(f_y\) the changes are due to only one of these variables, whilst the other
is held constant. Written formally:
\begin{equation*}
\begin{split}\frac{\partial f}{\partial u} &=&\, \lim_{\Delta u\rightarrow 0}\frac{f(x(u+\Delta u,v),y(u+\Delta u,v))-f(x(u,v),y(u,v))}{\Delta u}, \\
\frac{\partial f}{\partial x} &=&\, \lim_{\Delta x\rightarrow 0}\frac{f(x+\Delta x,y)-f(x,v)}{\Delta x}
=\lim_{\Delta u\rightarrow 0}\frac{f(x(u+\Delta u,v),y(u,v))-f(x(u,v),y(u,v))}{\Delta u}\end{split}
\end{equation*}
\sphinxAtStartPar
The lseson here is \sphinxhyphen{} it is dangerous to treat partial derivatives as fractions!


\section{Dependency Trees}
\label{\detokenize{VectorCalculus/partialdifferentiation:dependency-trees}}
\sphinxAtStartPar
The multivariate chain rule can be illustrated as a dependency tree, in \hyperref[\detokenize{VectorCalculus/partialdifferentiation:dependency1}]{Fig.\@ \ref{\detokenize{VectorCalculus/partialdifferentiation:dependency1}}}, where we examine \(f(x,\, y)\) with \(x = x(u,\, v)\) and \(y = y(u,\, v)\):

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{dependency1}.png}
\caption{Dependency tree for first derivatives.}\label{\detokenize{VectorCalculus/partialdifferentiation:dependency1}}\end{figure}

\sphinxAtStartPar
For instance, if we follow the dependency routes involving \(u\), we get \(f_u = f_x\, x_u + f_y\, y_u\).

\sphinxAtStartPar
We can do the same thing for the second derivatives (a repeat application of the chain rule), in \hyperref[\detokenize{VectorCalculus/partialdifferentiation:dependency2}]{Fig.\@ \ref{\detokenize{VectorCalculus/partialdifferentiation:dependency2}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{dependency2}.png}
\caption{Dependency tree for second derivatives.}\label{\detokenize{VectorCalculus/partialdifferentiation:dependency2}}\end{figure}

\sphinxAtStartPar
As an example lets look at the function \(f(x,y)=x^2 y+y^2\), if we have \(x = u+v\) and \(y = u-v\), then we can calculate \(f_u,\, f_v\) using dependency trees:
\begin{equation*}
\begin{split}f_u = f_x\, x_u + f_y\, y_u\\
f_v = f_x\, x_v + f_y\, y_v\end{split}
\end{equation*}
\sphinxAtStartPar
meaning that:
\begin{equation*}
\begin{split}f_x &=&\, 2xy, \\
f_y &=&\, x^2+2y \\
x_u=1, &\quad&\, x_v=1, \\
y_u=1, &\quad&\, y_v=-1\end{split}
\end{equation*}
\sphinxAtStartPar
Putting these results together:
\begin{equation*}
\begin{split}f_u = f_x\, x_u + f_y\, y_u &=&\, 2xy+(x^2+2y) = 2(u+v)(u-v)+(u+v)^2+2(u-v)\\
f_v = f_x\, x_v + f_y\, y_v &=&\, 2xy-(x^2+2y) = 2(u+v)(u-v)-(u+v)^2-2(u-v)\end{split}
\end{equation*}
\sphinxAtStartPar
We can also use techniques to simplify calculating more complicated derivatives, for example for the function:
\begin{equation*}
\begin{split}f(x,\, y) = \sin\left(x^2+2xy\right)+(x-y)^2\end{split}
\end{equation*}
\sphinxAtStartPar
To find \(f_x\), we can let \(u = x^2 + 2xy\), \(v = x-y\), then:
\begin{equation*}
\begin{split}f_x = f_u\, u_x +f_v\, v_x = \cos(u)(2x+2y)+2v = 2(x+y)\cos(x^2+2xy) + 2(x-y)\end{split}
\end{equation*}

\section{Exact derivatives and differentials}
\label{\detokenize{VectorCalculus/partialdifferentiation:exact-derivatives-and-differentials}}
\sphinxAtStartPar
The multivariate chain rule is sometimes written in differential form:
\begin{equation*}
\begin{split}\mathrm{d}F=\frac{\partial F}{\partial x}\,\mathrm{d}x+\frac{\partial F}{\partial y}\,\mathrm{d}y\end{split}
\end{equation*}
\sphinxAtStartPar
Comparing this result to a general expression of the form:
\begin{equation*}
\begin{split}\mathrm{d}F=A(x,y)\,\mathrm{d}x+B(x,y)\,\mathrm{d}y\end{split}
\end{equation*}
\sphinxAtStartPar
which tells us that:
\begin{equation*}
\begin{split}A = \frac{\partial F}{\partial x}, \quad B=\frac{\partial F}{\partial y}\end{split}
\end{equation*}
\sphinxAtStartPar
For these two results to be consistent, we require that the mixed second derivatives of \(F\) are equal, in accordance with Schwarz’ theorem.
Therefore, we require that:
\begin{equation*}
\begin{split}\frac{\partial A}{\partial y}\equiv\frac{\partial B}{\partial x}\end{split}
\end{equation*}
\sphinxAtStartPar
If the differential is exact, then it can be exactly integrated to obtain a solution \(F\). Whilst you might not be asked to obtain solutions for \(F\), you
may be asked to verify if a differential expression is exact by testing this condition.

\sphinxAtStartPar
As an example, lets try showing that:
\begin{equation*}
\begin{split}(y\cos{x}+\sin{y}+y)\,\mathrm{d}x + (\sin{x}+x\cos{y}+x)\,\mathrm{d}y\end{split}
\end{equation*}
\sphinxAtStartPar
is an exact differential.

\sphinxAtStartPar
The expression is of the form:
\begin{equation*}
\begin{split}A(x,\, y)\,\mathrm{d}x + B(x,\, y)\,\mathrm{d}y = 0\end{split}
\end{equation*}
\sphinxAtStartPar
where we have taken:
\begin{equation*}
\begin{split}A &=&\, y\cos{x}+\sin{y}+y \\
B &=&\, \sin{x}+x\cos{y}+x\end{split}
\end{equation*}
\sphinxAtStartPar
Then if we examine the conditions:
\begin{equation*}
\begin{split}\frac{\partial A}{\partial y} &=&\, \cos{x} + \cos{y} + 1\\
\frac{\partial B}{\partial x} &=&\, \cos{x} + \cos{y} + 1\\
\Rightarrow \frac{\partial A}{\partial y} &=&\, \frac{\partial B}{\partial x}\end{split}
\end{equation*}
\sphinxAtStartPar
and therefore the expression is exact.


\subsection{Solving 1st order ODEs *}
\label{\detokenize{VectorCalculus/partialdifferentiation:solving-1st-order-odes}}
\sphinxAtStartPar
Optionally, this result could be used to solve the nonlinear 1st order ODE:
\begin{equation*}
\begin{split}\frac{\mathrm{d}y}{\mathrm{d}x} + \frac{y\cos{x} + \sin{y} + y}{\sin{x} + x\cos{y} + x}=0\end{split}
\end{equation*}
\sphinxAtStartPar
We can rewrite this in the form:
\begin{equation*}
\begin{split}(y\cos{x} + \sin{y} + y)\,\mathrm{d}x + (\sin{x} + x\cos{y} + x)\,\mathrm{d}y = 0\\\end{split}
\end{equation*}
\sphinxAtStartPar
and if we let:
\begin{equation*}
\begin{split}A &=&\, y\cos{x} + \sin{y} + y = \frac{\partial F}{\partial x}, \\
B &=&\, \sin{x} + x\cos{y} + x = \frac{\partial F}{\partial y}\end{split}
\end{equation*}
\sphinxAtStartPar
where \(F(x,\,y)\) is to be determined.

\sphinxAtStartPar
By integrating \(A\) w.r.t. \(x\) and \(B\) w.r.t \(y\) we obtain:
\begin{equation*}
\begin{split}F &=&\, y\sin{x} + x\sin{y} + xy + F_1(y)\\
F &=&\, y\sin{x} + x\sin{y} + xy + F_2(x)\end{split}
\end{equation*}
\sphinxAtStartPar
where we introduced the arbitrary functions \(F_1,\, F_2\).  For consistency we require that \(F_1(y) = F_2(x) = \mathrm{const.}\), this
allows us to write the given ODE as:
\begin{equation*}
\begin{split}\frac{\mathrm{d}}{\mathrm{d}x}\left(y\sin{x}+x\sin{y}+xy\right)=0\end{split}
\end{equation*}
\sphinxAtStartPar
and so the solution is given by:
\begin{equation*}
\begin{split}y\sin{x}+x\sin{y}+xy=\mathrm{const.}\end{split}
\end{equation*}
\sphinxAtStartPar
That is, \(F(x,\, y) = 0\) where:
\begin{equation*}
\begin{split}F(x,\, y) = y\sin{x} + x\sin{y} + xy + k\end{split}
\end{equation*}
\sphinxAtStartPar
and \(k\) here is an arbitrary constant.


\section{Stationary Points}
\label{\detokenize{VectorCalculus/partialdifferentiation:stationary-points}}
\sphinxAtStartPar
If we think about stationary points in multivariable calculus:
\begin{itemize}
\item {} 
\sphinxAtStartPar
When \(\frac{\partial f}{\partial x}=0\) the function is stationary (flat) with respect to the \(x\)\sphinxhyphen{}axis

\item {} 
\sphinxAtStartPar
When \(\frac{\partial f}{\partial y}=0\) the function is stationary (flat) with respect to the \(y\)\sphinxhyphen{}axis

\end{itemize}

\sphinxAtStartPar
Recall from the multivariate chain rule:
\begin{equation*}
\begin{split}\mathrm{d}f = \frac{\partial f}{\partial x}\mathrm{d}x+\frac{\partial f}{\partial y}\mathrm{d}y\end{split}
\end{equation*}
\sphinxAtStartPar
then it is apparent that when both \(\frac{\partial f}{\partial x}=0\) AND \(\frac{\partial f}{\partial y}=0\), then the instantaneous rate of change of
\(f\) is zero in any direction.

\sphinxAtStartPar
As an example, lets think again about the function in \hyperref[\detokenize{VectorCalculus/partialdifferentiation:surf1}]{Fig.\@ \ref{\detokenize{VectorCalculus/partialdifferentiation:surf1}}}, \(f(x,\, y) = x^3 - y^3 - 2xy + 2\) can be found by solving \(f_x = f_y = 0\) simultaneously:
\begin{equation*}
\begin{split}3y^2+2x&=&\,0\\
3x^2-2y&=&\,0\end{split}
\end{equation*}
\sphinxAtStartPar
In general, it may be very difficult (or impossible!) to solve nonlinear equations by hand, and so we would need to resort to numerical methods. In this case,
however, we can proceed by rearranging one of the equations to substitute into the other, to obtain
\begin{equation*}
\begin{split}3\left(\frac{3}{2}x^2\right)^2+2x=0 \quad \leftrightarrow\quad x(27x^3+8)=0\end{split}
\end{equation*}
\sphinxAtStartPar
This equation has solutions \(x=0\) and \(x=-\frac{2}{3}\), as well as a complex conjugate pair of solutions \(\frac{1}{3}(1\pm\sqrt{3}i)\), which we will discard here.

\sphinxAtStartPar
Hence, the stationary points are \((0,\, 0,\, 2)\) and \(\left(-\frac{2}{3},\, \frac{2}{3},\, \frac{62}{27}\right)\), where we write \((x,\, y,\, f)\)


\subsection{Classification of Stationary Points}
\label{\detokenize{VectorCalculus/partialdifferentiation:classification-of-stationary-points}}
\sphinxAtStartPar
For a function \(f(x,\,y)\), we might expect to classify stationary points using \(f_{xx}\) and \(f_{yy}\). After all:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f_{xx}\) tells us the function concavity parallel to the \(y\) axis

\item {} 
\sphinxAtStartPar
\(f_{yy}\) tells us the function concavity parallel to the \(x\) axis

\item {} 
\sphinxAtStartPar
If the function is concave up in both the \(x\) and \(y\) directions through a stationary point, then intuition tells us that this is a local minimum.

\item {} 
\sphinxAtStartPar
If the function is concave down in both the \(x\) and \(y\) directions through a stationary point, then our intuition tells us that this is a local maximum.

\end{itemize}

\sphinxAtStartPar
We can examine this through some example functions,

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{bowl1}.png}
\caption{Left: Local minimum of a function \(f(x,y)\). The red lines illustrate the concave upwards behaviour in the \(x\) and \(y\) directions \(f_{xx}>0\), \(f_{yy}>0\).
The black contours are plotted on the surface at constant height. Notice that they form rings around the stationary point.
Right: Contour plot showing locations in the \((x,y)\) plane where \(f(x,y)\) is constant.
The colour scheme blue\(\rightarrow\)yellow is used to indicate the height of the contours, with yellow representing points at higher elevation.
The contour plot shows that the function is increasing in all directions away from the stationary point.}\label{\detokenize{VectorCalculus/partialdifferentiation:bowl1}}\end{figure}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{hill1}.png}
\caption{Left Panel: Local maximum of a function \(f(x,y)\). The red lines illustrate the concave downwards behaviour in the \(x\) and \(y\) directions \(f_{xx}<0\), \(f_{yy}<0\).
The black contours are plotted on the surface at constant height. Notice that they form rings around the stationary point.
Right Panel: Contour plot showing locations in the \((x,y)\) plane where \(f(x,y)\) is constant. The colour scheme blue\(\rightarrow\)yellow is used to indicate
the height of the contours, with yellow representing points at higher elevation. The contour plot shows that the function is decreasing in all directions away
from the stationary point.}\label{\detokenize{VectorCalculus/partialdifferentiation:hill1}}\end{figure}

\sphinxAtStartPar
However, a local maximum/minimum is not the only type of stationary point that a surface \(f(x,\,y)\) can have. For instance, a surface may have a stationary
point that sits where the function is concave upwards with respect to one axis and concave downwards with respect to the other axis. This type of point is called
a saddle point (it looks like a saddle for a horse). The figure below shows an example:

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{saddle1}.png}
\caption{Left Panel: Saddle point of a function \(f(x,\,y)\). The red lines illustrate the concave upwards/downwards behaviour in the \(x\) and \(y\) directions
\(f_{xx}>0\), \(f_{yy}<0\). The black contours are plotted on the surface at constant height. Notice that the contours cross at a saddle point.
Right Panel: Contour plot showing locations in the \((x,\,y)\) plane where \(f(x,\,y)\) is constant. The colour scheme blue\(\rightarrow\)yellow
is used to indicate the height of the contours, with yellow representing points at higher elevation. The contour plot also shows the function concavity in the
\(x,\, y\) directions.}\label{\detokenize{VectorCalculus/partialdifferentiation:saddle1}}\end{figure}

\sphinxAtStartPar
We conclude that at a stationary point, if \(f_{xx}\) and \(f_{yy}\) are opposite sign, then the point is a saddle point. However, the converse is not
necessarily true! It turns out that we can have a saddle point where \(f_{xx}\) and \(f_{yy}\) are both the same sign (or even when they are both zero). An example is
illustrated in the figure below. In this case the saddle point is not aligned squarely with the \((x,\,y)\) coordinate directions.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{squish1}.png}
\caption{Left Panel: Saddle point of a function \(f(x,y)\) that is not aligned squarely with the \(x,\,y\) axes. The red lines illustrate the concave upwards
behaviour in the \(x\) and \(y\) directions \(f_{xx}>0\), \(f_{yy}>0\). The curve has concave down behaviour at approximately \(45^{\circ}\) to the \(x\)\sphinxhyphen{}axis.
Right Panel: Contour plot showing locations in the \((x,\,y)\) plane where \(f(x,\,y)\) is constant. The colour scheme blue\(\rightarrow\)yellow is used
to indicate the height of the contours, with yellow representing points at higher elevation. The competing concave up/down behaviour is apparent from the contour plot.}\label{\detokenize{VectorCalculus/partialdifferentiation:squish}}\end{figure}

\sphinxAtStartPar
So, it turns outs that the condition for a maximum/minimum is more complicated than we first thought! A valid classification algorithm is presented in the box below.

\sphinxAtStartPar
The result can be proved by utilising a multivariate Taylor series expansion about the stationary point and retaining terms only up to quadratic order
so that the shape of the function may be inferred from the properties of a quadratic. Neglecting the higher order terms in the expansion is justified in the
limit approaching the stationary point. We have not studied the multivariate chain rule, so the proof is not presented here.


\subsection{Hessian Matrix}
\label{\detokenize{VectorCalculus/partialdifferentiation:hessian-matrix}}
\sphinxAtStartPar
At a stationary point, \(f_x(x_0,y_0)=f_y(x_0,y_0)\), we calculate the determinant of the Hessian matrix at \(H(x_0,\,y_0)\):
\begin{equation*}
\begin{split}\det(H) = \begin{vmatrix}
f_{xx}&f_{xy}\\
f_{yx}&f_{yy}
\end{vmatrix}=f_{xx}f_{yy}-(f_{xy})^2\end{split}
\end{equation*}
\sphinxAtStartPar
This can have a few different outcomes:
\begin{itemize}
\item {} 
\sphinxAtStartPar
If \(\det(H(x_0,\,y_0))>0\) then the point is a local max/min, depending on the signs of \(f_{xx}\) and \(f_{yy}\).

\item {} 
\sphinxAtStartPar
If \(\det(H(x_0,\,y_0))<0\) then the point is a saddle.

\item {} 
\sphinxAtStartPar
If \(\det(H(x_0,\,y_0))=0\) then the test is inconclusive and further analysis is needed.

\end{itemize}

\sphinxAtStartPar
Example 2:

\sphinxAtStartPar
Lets classify the stationary points of the function \(f=x^3-y^3-2xy+2\), we already found that the stationary points are located at \((0,0,2)\) and
\(\left(-\frac{2}{3},\frac{2}{3},\frac{62}{27}\right)\).

\sphinxAtStartPar
Calculating the Hessian determinant components \(f_{xx}=6x, \quad f_{yy}=-6y, \quad f_{xy}=f_{yx}=-2\) and therefore:
\begin{equation*}
\begin{split}\det(H(x,y)) = \begin{vmatrix} 
6x &-2 \\ 
-2 &-6y 
\end{vmatrix}=-36xy-4\end{split}
\end{equation*}
\sphinxAtStartPar
\(\det(H(0,0))=-4<0\) so the origin is a saddle point.

\sphinxAtStartPar
\(\det\biggr(H\biggr(-\frac{2}{3},\frac{2}{3}\biggr)\biggr)=12>0\) and \(f_{xx}\left(-\frac{2}{3},\frac{2}{3}\right)<0\), so the point
\(\left(-\frac{2}{3}\frac{2}{3}\right)\) is a local maximum.

\sphinxAtStartPar
A contour plot of the function, shown in \hyperref[\detokenize{VectorCalculus/partialdifferentiation:example1}]{Fig.\@ \ref{\detokenize{VectorCalculus/partialdifferentiation:example1}}}, confirms these findings.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{example1}.png}
\caption{Contour plot of \(f=x^3-y^3-2xy+2\), showing stationary points clearly.}\label{\detokenize{VectorCalculus/partialdifferentiation:example1}}\end{figure}


\chapter{Integration Preliminaries}
\label{\detokenize{VectorCalculus/integrationprelim:integration-preliminaries}}\label{\detokenize{VectorCalculus/integrationprelim::doc}}

\section{Arc Length}
\label{\detokenize{VectorCalculus/integrationprelim:arc-length}}
\sphinxAtStartPar
Suppose that we have a function \(y = f(x)\), we know through integration that we can find the area under the curve, as shown in \hyperref[\detokenize{VectorCalculus/integrationprelim:functionarea}]{Fig.\@ \ref{\detokenize{VectorCalculus/integrationprelim:functionarea}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{FunctionArea}.png}
\caption{The area (in blue) under a function \(f(x)\) over the interval \(x \in [a,\,b]\) given by the integral \(\int_a^bf(x)\,\mathrm(d)x\).}\label{\detokenize{VectorCalculus/integrationprelim:functionarea}}\end{figure}

\sphinxAtStartPar
Another question that we could ask however is what is the length of the path traced out by the function \(f(x)\) over the range \([a,\,b]\), as shown in
\hyperref[\detokenize{VectorCalculus/integrationprelim:functionpathlength}]{Fig.\@ \ref{\detokenize{VectorCalculus/integrationprelim:functionpathlength}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{FunctionPathLength}.png}
\caption{The path traced out by the function \(f(x)\) over the interval \(x \in [a,\,b]\).}\label{\detokenize{VectorCalculus/integrationprelim:functionpathlength}}\end{figure}

\sphinxAtStartPar
To find an expression for this length \(S\), we can break up the path into infinitesimal segments and then integrate these over the whole function.  We can see this
process in \hyperref[\detokenize{VectorCalculus/integrationprelim:arclength}]{Fig.\@ \ref{\detokenize{VectorCalculus/integrationprelim:arclength}}}, where we break down the change in arc length \(\Delta s\) by Pythagoras:
\begin{equation*}
\begin{split}(\Delta s)^2 = (\Delta x)^2 + (\Delta y)^2 \Rightarrow \Delta s = \sqrt{(\Delta x)^2 + (\Delta y)^2} = \Delta x\,\sqrt{1 + \left(\frac{\Delta y}{\Delta x}\right)^2}\end{split}
\end{equation*}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{ArcLength2}.png}
\caption{Left Pane: Breaking down path legnth segment \(\Delta s\) into \(x,\, y\) comoonents \(\Delta x,\, \Delta y\),
Right Pane: Effect of taking the limit of smaller \(\Delta x\) in finding the path length.}\label{\detokenize{VectorCalculus/integrationprelim:arclength}}\end{figure}

\sphinxAtStartPar
Taking the limit of \(\Delta x\rightarrow 0\) we find:
\begin{equation*}
\begin{split}\mathrm{d}s = \mathrm{d}x\, \sqrt{1 + \left(\frac{\mathrm{d}y}{\mathrm{d}x}\right)^2}\end{split}
\end{equation*}
\sphinxAtStartPar
and therefore to find the path length:
\begin{equation*}
\begin{split}L = \int_{x=a}^{x=b} \mathrm{d}s = \int_a^b \sqrt{1 + \left(\frac{\mathrm{d}y}{\mathrm{d}x}\right)^2}\,\mathrm{d}x\end{split}
\end{equation*}
\sphinxAtStartPar
Taking an example here, lets look at \(y = \cosh(x)\) over the range \(x \in [0,\,1]\), so we find \(\mathrm{d}y/\mathrm{d}x = \sinh(x)\), and therefore:
\begin{equation*}
\begin{split}L = \int_0^1 \sqrt{1 + \sinh^2(x)}\,\mathrm{d}x = \int_0^1 \cosh(x)\,\mathrm{d}x = \Big[ \sinh(x) \Big]_0^1 = \sinh(1) \simeq 1.175\dots\end{split}
\end{equation*}
\sphinxAtStartPar
We might also have a function which is parameterised \(y = y(t),\, x=x(t)\), it is also possible to find an expression for the path length, taking the limit of
\(\Delta t \rightarrow 0\):
\begin{equation*}
\begin{split}\Delta s &=&\, \Delta t\,\sqrt{\left(\frac{\Delta x}{\Delta t}\right)^2 + \left(\frac{\Delta y}{\Delta t}\right)^2} \\
\Rightarrow \mathrm{d}s &=&\, \mathrm{d}t\, \sqrt{\left(\frac{\mathrm{d}x}{\mathrm{d}t}\right)^2 + \left(\frac{\mathrm{d}y}{\mathrm{d}t}\right)^2}\end{split}
\end{equation*}
\sphinxAtStartPar
An example here would be a circle, parameterised by \(x = R\cos(t),\, y = R\sin(t)\), over the range \(t \in [0,\, 2\pi)\), giving
\(\mathrm{d}x/\mathrm{d}t = -R\sin(t),\, \mathrm{d}y/\mathrm{d}t = R\cos(t)\) and therefore:
\begin{equation*}
\begin{split}L = \int_0^{2\pi} \sqrt{R^2\sin^2(t) + R^2\cos^2(t)}\,\mathrm{d}t = \int_0^{2\pi} R\,\mathrm{d}x = \Big[ Rt \Big]_0^{2\pi} = 2\pi\,R\end{split}
\end{equation*}
\sphinxAtStartPar
which gives the result for the circumference of a circle!


\section{Surfaces of Revolution}
\label{\detokenize{VectorCalculus/integrationprelim:surfaces-of-revolution}}
\sphinxAtStartPar
Lets now go further, what happens if we take a function and rotate it around an axis, as shown in \hyperref[\detokenize{VectorCalculus/integrationprelim:areavolumerevolution}]{Fig.\@ \ref{\detokenize{VectorCalculus/integrationprelim:areavolumerevolution}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{AreaVolumeRevolution}.png}
\caption{Left Pane: Rotating a function \(y = f(x)\) around the \(x\) axis, over  \(x \in [a,\, b]\) producing a solid of revolution,
Right Pane: Breaking down the volume into discrete slices, each of width \(\mathrm{d} x\).}\label{\detokenize{VectorCalculus/integrationprelim:areavolumerevolution}}\end{figure}

\sphinxAtStartPar
To find the volume of such a rotated solid, we need to think about the cross sectional area along the range, which will be \(\pi \,y^2\) since the
radius of each slice at \(x\) is \(y(x)\).  Then we just need to integrate up these slices \(\pi\,y^2\,\mathrm{d}x\) over the range:
\begin{equation*}
\begin{split}V_x = \int_a^b \pi\,y^2\,\mathrm{d}x\end{split}
\end{equation*}
\sphinxAtStartPar
and we can swap round the axis we rotate over to the \(y\) axis and therefore the radius of each slice would be \(\pi\,x^2\) and therefore:
\begin{equation*}
\begin{split}V_y = \int_{y(a)}^{y(b)} \pi\,x^2\,\mathrm{d}y\end{split}
\end{equation*}
\sphinxAtStartPar
We can also find the surface area of this solid of revolution, if we rotate over the \(x\) acis then this surface area is the circumference of each
slice \(2\pi\,y\) multiplied by the path length \(\mathrm{d} s\) along the surface, so we find:
\begin{equation*}
\begin{split}A_x = \int_{x=a}^{x=b} 2\pi\,y\,\mathrm{d}s = \int_a^b 2\pi\,y\,\sqrt{1 + \left(\frac{\mathrm{d}y}{\mathrm{d}x}\right)^2}\,\mathrm{d}x\end{split}
\end{equation*}
\sphinxAtStartPar
We could rotate over the \(y\) axis instead, in which case we just switch the circumference we are interested in to be \(2\pi\,x\) and integrate the
path length over the \(y\) axis:
\begin{equation*}
\begin{split}A_y = \int_{y(a)}^{y(b)} 2\pi\,x\,\mathrm{d}s = \int_{y(a)}^{y(b)} 2\pi\,x\,\sqrt{1 + \left(\frac{\mathrm{d}y}{\mathrm{d}x}\right)^2}\,\mathrm{d}y\end{split}
\end{equation*}
\sphinxAtStartPar
As an exmaple, lets find the volume of a cone depicted in \hyperref[\detokenize{VectorCalculus/integrationprelim:cone}]{Fig.\@ \ref{\detokenize{VectorCalculus/integrationprelim:cone}}}, with height \(h\) and circular radius \(R\), so \(y = R x / h\) over the range \(x \in [0,\, h]\):
\begin{equation*}
\begin{split}V_x = \int_0^h \pi\,\left(\frac{R x}{h}\right)^2\,\mathrm{d}x = \frac{R^2 \,\pi}{h^2}\Big[ \frac{1}{3}x^3\Big]_0^h = \frac{1}{3}\pi \,R^2\,h\\\end{split}
\end{equation*}
\sphinxAtStartPar
which matches the expression we expect and explains where this factor of \(1/3\) comes from!

\sphinxAtStartPar
Likewise we can look at the surface area of this cone,  \(y = R x / h \rightarrow \mathrm{d}y/\mathrm{d}x = R / h\) over the range \(x \in [0,\, h]\):
\begin{equation*}
\begin{split}A_x &=&\, \int_0^h 2\pi\,\frac{R x}{h}\,\sqrt{1 + \left(\frac{R}{h}\right)^2}\,\mathrm{d}x \\
&=&\, 2\pi \frac{R}{h}\sqrt{1 + \left(\frac{R}{h}\right)^2}\Bigg[ \frac{1}{2}x^2\Bigg]_0^h \\
&=&\, \pi R h\sqrt{1 + \left(\frac{R}{h}\right)^2} = \pi R\sqrt{h^2 + R^2}\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\sqrt{h^2 + R^2}\) is the slant length.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{cone}.png}
\caption{Depiction of a function \(y = R x / h\) and the solid of revolution around the \(x\) axis \sphinxhyphen{} a cone.}\label{\detokenize{VectorCalculus/integrationprelim:cone}}\end{figure}

\sphinxAtStartPar
Likewise if we have parametrised expressions \(x = x(t),\, y = y(t)\), over the range \(t \in [t_1,\, t_2]\) then these expressions become:
\begin{equation*}
\begin{split}V_x &=&\, \int_{t_1}^{t_2} \pi\,y^2\,\frac{\mathrm{d}x}{\mathrm{d}t}\,\mathrm{d}t \\
V_y &=&\, \int_{t_1}^{t_2} \pi\,x^2\,\frac{\mathrm{d}y}{\mathrm{d}t}\,\mathrm{d}t \\
A_x &=&\, \int_{t_1}^{t_2} 2\pi\,y\,\sqrt{\left(\frac{\mathrm{d}x}{\mathrm{d}t}\right)^2 + \left(\frac{\mathrm{d}y}{\mathrm{d}t}\right)^2}\,\mathrm{d}t \\
A_y &=&\, \int_{t_1}^{t_2} 2\pi\,x\,\sqrt{\left(\frac{\mathrm{d}x}{\mathrm{d}t}\right)^2 + \left(\frac{\mathrm{d}y}{\mathrm{d}t}\right)^2}\,\mathrm{d}t\end{split}
\end{equation*}

\chapter{Line Integrals}
\label{\detokenize{VectorCalculus/lineintegrals:line-integrals}}\label{\detokenize{VectorCalculus/lineintegrals::doc}}
\sphinxAtStartPar
Following on from the idea of breaking up a function into infintesimal sections \(\mathrm{d} s\), we can think about a path through a vector field \(\bf A(r)\), as depicted
in \hyperref[\detokenize{VectorCalculus/lineintegrals:lineintegral}]{Fig.\@ \ref{\detokenize{VectorCalculus/lineintegrals:lineintegral}}}.  Starting from some vector \(\bf r_A\) we can follow some path through the vector field (which we denote \(C\)), with the path following the
field’s direction at each point before finishing at point \(\bf r_B\):
\begin{equation*}
\begin{split}I = \int_C {\bf G(r)} \cdot \mathrm{d}{\bf r}\end{split}
\end{equation*}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{lineintegral}.png}
\caption{Ilustration of a line integral, with \(I = \int_C {\bf G(r)}\cdot \mathrm{d}{\bf r}\)}\label{\detokenize{VectorCalculus/lineintegrals:lineintegral}}\end{figure}

\sphinxAtStartPar
We see that that this is a scalar, found from the scalar product of \(\bf G\) with the differential line element \(\mathrm{d}{\bf r}\).

\sphinxAtStartPar
IF we pick a closed path, we call this a Loop Integral:
\begin{equation*}
\begin{split}I = \oint_C {\bf G(r)} \cdot \mathrm{d}{\bf r}\end{split}
\end{equation*}

\section{Calculating Line Integrals}
\label{\detokenize{VectorCalculus/lineintegrals:calculating-line-integrals}}
\sphinxAtStartPar
Whilst the notation for a line integral looks compact, it does not really make it clear how we can evaluate over a path \(C\).  In order to make progress,
we need to parametrise the path, lets say with some variable \(t\):
\begin{equation*}
\begin{split}t &\rightarrow&\, {\bf r}(t) \\
[a\, b] &\rightarrow&\, \mathbb{R}^3\end{split}
\end{equation*}
\sphinxAtStartPar
which means the path runs \({\bf r_A} = {\bf r}(a) \rightarrow {\bf r_B} = {\bf r}(b)\).  Looking at the line element:
\begin{equation*}
\begin{split}\mathrm{d}{\bf r}(t) = \begin{pmatrix} \mathrm{d}x (t) \\ \mathrm{d}y (t) \\\mathrm{d}z (t)\end{pmatrix} = 
\begin{pmatrix} x'\mathrm{d}t \\ y'\mathrm{d}t \\ z'\mathrm{d}t\end{pmatrix} = {\bf r}'(t)\,\mathrm{d} t\end{split}
\end{equation*}
\sphinxAtStartPar
and thus to express this as an integral in a way we can calculate it, with some parameter \(t\):
\begin{equation*}
\begin{split}I = \int_C {\bf G}(r) \cdot \mathrm{d}{\bf r} = \int_a^b {\bf G}({\bf r}(t)) \cdot {\bf r}'(t)\,\mathrm{d}t
\end{split}
\end{equation*}
\sphinxAtStartPar
As an example lets consider the vector field \({\bf G(r)} = \begin{pmatrix} xy\\ -y^2 \end{pmatrix}\) and look at the line integral over the points
\((0,\, 0) \rightarrow (1,2)\) across different paths.  Lets pick the parameter \(t\) to be the \(x\) coordinate, so that the path if determined by
\(y = f(x), \, x \in [a,\, b]\) such that:
\begin{equation*}
\begin{split}{\bf r}(x) = \begin{pmatrix} x \\ f(x) \end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
Lets consider different paths:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Straight line path

\end{itemize}

\sphinxAtStartPar
The function following by this path will be \(y = 2x,\, x \in [0, 1]\), so:
\begin{equation*}
\begin{split}{\bf r}(x) = \begin{pmatrix} x \\ 2x \end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
Thus \({\bf G}({\bf r}(x))\) will be:
\begin{equation*}
\begin{split}{\bf G}({\bf r}(x)) = \begin{pmatrix} 2x^2 \\ -4x^2 \end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
and \({\bf r'}(x)\) is given by:
\begin{equation*}
\begin{split}{\bf r}'(x) = \begin{pmatrix} 1 \\ 2 \end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
so the line integral is found by:
\begin{equation*}
\begin{split}I &=&\, \int_C {\bf G}(r) \cdot \mathrm{d}{\bf r} = \int_0^1 {\bf G}({\bf r}(t)) \cdot {\bf r}'(t)\,\mathrm{d}t = 
\int_0^1 \begin{pmatrix} 2x^2 \\ -4x^2 \end{pmatrix} \cdot \begin{pmatrix} 1 \\ 2 \end{pmatrix} \mathrm{d}x \\
&=&\, \int_0^1 \left( 2x^2 - 8x^2 \right)\,\textrm{d}x = -\int_0^1 6x^2 \,\textrm{d}x = \Big[ -\frac{6}{3}x^3\Big ]_0^1 = -2\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
Curved path following \(y = x^2\)

\end{itemize}
\begin{equation*}
\begin{split}{\bf r}(x) = \begin{pmatrix} x \\ x^2 \end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
Thus \({\bf G}({\bf r}(x))\) will be:
\begin{equation*}
\begin{split}{\bf G}({\bf r}(x)) = \begin{pmatrix} x^3 \\ -x^4 \end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
and \({\bf r'}(x)\) is given by:
\begin{equation*}
\begin{split}{\bf r}'(x) = \begin{pmatrix} 1 \\ 2x \end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
so the line integral is found by:
\begin{equation*}
\begin{split}I &=&\, \int_C {\bf G}(r) \cdot \mathrm{d}{\bf r} = \int_0^1 {\bf G}({\bf r}(t)) \cdot {\bf r}'(t)\,\mathrm{d}t = 
\int_0^1 \begin{pmatrix} x^3 \\ -x^4 \end{pmatrix} \cdot \begin{pmatrix} 1 \\ 2x \end{pmatrix} \mathrm{d}x \\
&=&\, \int_0^1 \left( x^3 - 2x^5 \right)\,\textrm{d}x = \Big[\frac{1}{4}x^4 - \frac{1}{3}x^6 \Big ]_0^1 = -\frac{1}{12}\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
Curved path following \(y = x^{1/2}\)

\end{itemize}
\begin{equation*}
\begin{split}{\bf r}(x) = \begin{pmatrix} x \\ x^{1/2} \end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
Thus \({\bf G}({\bf r}(x))\) will be:
\begin{equation*}
\begin{split}{\bf G}({\bf r}(x)) = \begin{pmatrix} x^{3/2} \\ -x \end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
and \({\bf r'}(x)\) is given by:
\begin{equation*}
\begin{split}{\bf r}'(x) = \begin{pmatrix} 1 \\ \frac{1}{2} x^{-1/2} \end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
so the line integral is found by:
\begin{equation*}
\begin{split}I &=&\, \int_C {\bf G}(r) \cdot \mathrm{d}{\bf r} = \int_0^1 {\bf G}({\bf r}(t)) \cdot {\bf r}'(t)\,\mathrm{d}t = 
\int_0^1 \begin{pmatrix} x^{3/2} \\ -x \end{pmatrix} \cdot \begin{pmatrix} 1 \\ \frac{1}{2} x^{-1/2} \end{pmatrix} \mathrm{d}x \\
&=&\, \int_0^1 \left( x^{3/2} - \frac{1}{2}x^{1/2} \right)\,\textrm{d}x = \Big[\frac{2}{5}x^{5/2} - \frac{1}{3}x^{3/2} \Big ]_0^1 = \frac{1}{15}
\end{split}
\end{equation*}

\chapter{Vectors and Vector Algebra}
\label{\detokenize{VectorCalculus/vectoralgebra:vectors-and-vector-algebra}}\label{\detokenize{VectorCalculus/vectoralgebra::doc}}
\sphinxAtStartPar
We can think of vectors at their heart as directions being given to get between two points in space.  If we have to move in one, two or three dimensions, along spatially flat or curved surfaces,
we can attempt to give directions.  At the heart of a any vector system are the basis vectors, these give us the funadmental possible directions within a vector space, which any vector can be
decompsoed into a weighted sum of.

\sphinxAtStartPar
In the Cartesian coordinate system, in three dimensions the basis vectors are given as:
\begin{equation*}
\begin{split}\hat{\bf x} = \,\begin{pmatrix}
 1 \\
 0 \\
 0 
\end{pmatrix}, \quad 
\hat{\bf y} = \,\begin{pmatrix}
 0 \\
 1 \\
 0 
\end{pmatrix}, \quad 
\hat{\bf z} \,\begin{pmatrix}
 0 \\
 0 \\
 1 
\end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
and when we switch to different coordinate systems, we will consider how these change.  Note that a variety of different letters are employed for the Cartessian system:
\begin{equation*}
\begin{split}\hat{\bf x} &=&\, {\bf e_x} = \vec{x} = \hat{\bf i}\\
\hat{\bf y} &=&\, {\bf e_y} = \vec{y} = \hat{\bf j}\\
\hat{\bf z} &=&\, {\bf e_z} = \vec{z} = \hat{\bf k}\end{split}
\end{equation*}
\sphinxAtStartPar
To see how these visually fit together, see \hyperref[\detokenize{VectorCalculus/vectoralgebra:cartcoords}]{Fig.\@ \ref{\detokenize{VectorCalculus/vectoralgebra:cartcoords}}}.  We note that all the coordinates meet at right angles and that we have defined right handed axes.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{CartesianCoordinateSystem}.png}
\caption{Left Pane: Graphical breakdown of the Cartesian coordinate system with vector path in red,
Right Pane: The differences between left handed (top) and right handed (bottom) axes.}\label{\detokenize{VectorCalculus/vectoralgebra:cartcoords}}\end{figure}

\sphinxAtStartPar
We can also write coordinates in so\sphinxhyphen{}called index notation:
\begin{equation*}
\begin{split}x_i = \left(\hat{\bf x},\, \hat{\bf y},\, \hat{\bf z}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
where the value of \(i = \in \{1,\,2,\,3\}\) denotes the specific basis vector.


\section{Addition and Scaling of Vectors}
\label{\detokenize{VectorCalculus/vectoralgebra:addition-and-scaling-of-vectors}}
\sphinxAtStartPar
If we start with the basis vectors as building blocks of our coordinate system, then we can write any three dimensional Cartesian coordinate in terms of
weighted basis vectors, we can see this in \hyperref[\detokenize{VectorCalculus/vectoralgebra:basisvectors}]{Fig.\@ \ref{\detokenize{VectorCalculus/vectoralgebra:basisvectors}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{basisvectors}.png}
\caption{Breakdown of vector \(\bf a = a_x \,\hat{\bf x} + a_y \,\hat{\bf y} + a_z \,\hat{\bf z}\).}\label{\detokenize{VectorCalculus/vectoralgebra:basisvectors}}\end{figure}

\sphinxAtStartPar
As an example we can define two vectors \(\bf v_1,\, v_2\)
\begin{equation*}
\begin{split}{\bf v}_1 &=&\, \begin{pmatrix}
 3 \\
 4 \\
 12 
\end{pmatrix} = 3\hat{\bf x} + 4\hat{\bf y} + 12\hat{\bf z}\\
{\bf v}_2 &=&\, \begin{pmatrix}
 5 \\
 12 \\
 13 
\end{pmatrix} = 5\hat{\bf x} + 12\hat{\bf y} + 13\hat{\bf z}\end{split}
\end{equation*}
\sphinxAtStartPar
Then we can add or sutract these vectors:
\begin{equation*}
\begin{split}{\bf v}_1 + {\bf v}_2  &=&\, \begin{pmatrix}
 3 \\
 4 \\
 12 
\end{pmatrix} + \begin{pmatrix}
 5 \\
 12 \\
 13 
\end{pmatrix} = \begin{pmatrix}
 8 \\
 16 \\
 25 
\end{pmatrix} = 8\hat{\bf x} + 16\hat{\bf y} + 25\hat{\bf z}\\
{\bf v}_2 - {\bf v}_1  &=&\, \begin{pmatrix}
 5 \\
 12 \\
 13 
\end{pmatrix} - 
\begin{pmatrix}
 3 \\
 4 \\
 12 
\end{pmatrix} = \begin{pmatrix}
 2 \\
 8 \\
 1 
\end{pmatrix} = 2\hat{\bf x} + 8\hat{\bf y} + \hat{\bf z}
\end{split}
\end{equation*}
\sphinxAtStartPar
Likewise we can scale each of the vectors and then proceed to add them:
\begin{equation*}
\begin{split}2{\bf v}_1 + 3{\bf v}_2  &=&\,  2\begin{pmatrix}
 3 \\
 4 \\
 12 
\end{pmatrix} + 3\begin{pmatrix}
 5 \\
 12 \\
 13 
\end{pmatrix} = \begin{pmatrix}
 21 \\
 44 \\
 63 
\end{pmatrix} = 21\hat{\bf x} + 44\hat{\bf y} + 49\hat{\bf z}\end{split}
\end{equation*}

\section{Magnitude of a Vector}
\label{\detokenize{VectorCalculus/vectoralgebra:magnitude-of-a-vector}}
\sphinxAtStartPar
Given some vector, which will take us some distance from two points in space, we can find the shortest path length between the points.

\sphinxAtStartPar
In two dimensions this would just follow Pythagoras’s theorem:
\begin{equation*}
\begin{split}{\bf v} = a_x\hat{\bf x} + a_y\hat{\bf y}
v_3 = |{\bf v}| = \sqrt{{a_x}^2 + {a_y}^2}\end{split}
\end{equation*}
\sphinxAtStartPar
and in three dimensions a similar relation holds (which we can prove geometrically:
\begin{equation*}
\begin{split}{\bf v} = a_x\hat{\bf x} + a_y\hat{\bf y} + a_z\hat{\bf z}
v_3 = |{\bf v}| = \sqrt{{a_x}^2 + {a_y}^2 + {a_z}^2} \end{split}
\end{equation*}
\sphinxAtStartPar
As an example lets consider \(\bf v_1\):
\begin{equation*}
\begin{split}|3\hat{\bf x} + 4\hat{\bf y} + 12\hat{\bf z}| = \sqrt{3^2 + 4^2 + 12^2} = 13\end{split}
\end{equation*}

\section{Normalised Vectors}
\label{\detokenize{VectorCalculus/vectoralgebra:normalised-vectors}}
\sphinxAtStartPar
Each of the basis vectors is a normalised vector \(|\hat{\bf x}| = |\hat{\bf y}| = |\hat{\bf z}| = 1\), however if we have a more general vector
\({\bf v} = a_x\hat{\bf x} + a_y\hat{\bf y} + a_z\hat{\bf z}\) moving in some direction, we can also construct a normalised vector:
\begin{equation*}
\begin{split}\hat{\bf v} = \frac{\bf v}{|\bf v|} = \frac{a_x\hat{\bf x} + a_y\hat{\bf y} + a_z\hat{\bf z}}{\sqrt{{a_x}^2 + {a_y}^2 + {a_z}^2}}\end{split}
\end{equation*}
\sphinxAtStartPar
As an example lets consider \(\bf v_1\):
\begin{equation*}
\begin{split}\hat{\bf v_1} = \frac{\bf v_1}{|\bf v_1|} = \frac{3\hat{\bf x} + 4\hat{\bf y} + 12\hat{\bf z}}{\sqrt{3^2 + 4^2 + 12^2}} = \frac{1}{13}\left(3\hat{\bf x} + 4\hat{\bf y} + 12\hat{\bf z}\right)\end{split}
\end{equation*}

\section{Scalar Product / Dot Product}
\label{\detokenize{VectorCalculus/vectoralgebra:scalar-product-dot-product}}

\subsection{Geometric Definiton}
\label{\detokenize{VectorCalculus/vectoralgebra:geometric-definiton}}
\sphinxAtStartPar
Lets consider two vectors \(\bf A,\, B\), as shown in \hyperref[\detokenize{VectorCalculus/vectoralgebra:scalarprojection}]{Fig.\@ \ref{\detokenize{VectorCalculus/vectoralgebra:scalarprojection}}}.  We can consider the scalar projection of the vector \(\bf B\) on to the vector \(\bf A\), where we resolve the
parallel components of \(\bf B\) in the direction of vector \(\bf A\).

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{scalarprojection}.png}
\caption{Left Pane: Vectors \(\bf A,\, B\) which share a common coordinate and span an angle \(\theta\) between them,
Right Pane The scalar projection of the vector \(\bf B\) on to the vector \(\bf A\), which by trigonometry gives the length \(|{\bf B}| \cos\theta\).}\label{\detokenize{VectorCalculus/vectoralgebra:scalarprojection}}\end{figure}

\sphinxAtStartPar
If we multiply these two distances, this is Scalar Product of the vectors:
\begin{equation*}
\begin{split}{\bf A \cdot B} = |{\bf A}||{\bf B}|\cos(\theta)\end{split}
\end{equation*}
\sphinxAtStartPar
also known as the Dot Product.

\sphinxAtStartPar
So we can calculate the scalar projection of \(\bf B\) onto vector \(\bf A\) using \({\bf A \cdot B} / |{\bf A}|\).  Likewise we can think about the scalar projection of \(\bf A\) onto the vector
\(\bf B\), using \({\bf A \cdot B} / |{\bf B}|\).

\sphinxAtStartPar
We can also find the magntiude of a vector from \(\bf A \cdot A = |A|^2 \).


\subsection{Algebraic Definition}
\label{\detokenize{VectorCalculus/vectoralgebra:algebraic-definition}}
\sphinxAtStartPar
There is another perspective on the scalar product, which is for two vectors with components:
\begin{equation*}
\begin{split}{\bf A} &=&\, a_x\,\hat{\bf x} + a_y\,\hat{\bf y} + a_z\,\hat{\bf z} = \begin{pmatrix}
 a_x \\
 a_y \\
 a_z 
\end{pmatrix} \\
{\bf B} &=&\, b_x\,\hat{\bf x} + b_y\,\hat{\bf y} + b_z\,\hat{\bf z} = \begin{pmatrix}
 b_x \\
 b_y \\
 b_z 
\end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
then the dot product can be found by:
\begin{equation*}
\begin{split}{\bf A \cdot B} = a_x\,b_x + a_y\,b_y + a_z\,b_z= \sum_{i=1}^3 a_i\,b_i\end{split}
\end{equation*}
\sphinxAtStartPar
where the last expression uses the index notation.


\subsection{Properties of the Dot Product}
\label{\detokenize{VectorCalculus/vectoralgebra:properties-of-the-dot-product}}
\sphinxAtStartPar
The dot product of two vectors \(\bf a,\, b\) have the following mathematical properties:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Commutative:
\(\mathbf {a} \cdot \mathbf {b} = \mathbf {b} \cdot \mathbf {a}\)

\item {} 
\sphinxAtStartPar
Distributive over Vector Addition:
\(  \mathbf {a} \cdot (\mathbf {b} +\mathbf {c} )=\mathbf {a} \cdot \mathbf {b} +\mathbf {a} \cdot \mathbf {c}\)

\item {} 
\sphinxAtStartPar
Bilinear:
\( \mathbf {a} \cdot (r\mathbf {b} +\mathbf {c} )=r(\mathbf {a} \cdot \mathbf {b} )+(\mathbf {a} \cdot \mathbf {c} )\)

\item {} 
\sphinxAtStartPar
Scalar Multiplication:
\( (c_{1}\mathbf {a} )\cdot (c_{2}\mathbf {b} )=c_{1}c_{2}(\mathbf {a} \cdot \mathbf {b} )\)

\item {} 
\sphinxAtStartPar
Orthogonal:
Two non\sphinxhyphen{}zero vectors \(\bf a,\, b\) are orthogonal if and only if \(\bf a \cdot b = 0\).

\end{itemize}


\section{Vector Product / Cross Product}
\label{\detokenize{VectorCalculus/vectoralgebra:vector-product-cross-product}}

\subsection{Geometric Definition}
\label{\detokenize{VectorCalculus/vectoralgebra:geometric-definition}}
\sphinxAtStartPar
Unsurprisingly we can also make a vector product that results in a vector, rather than a scalar.  This Vector Product, also known as the Cross Product,
can be constructed from the basis vectors:
\begin{equation*}
\begin{split}\hat{\bf x} \times \hat{\bf y} &=&\, \hat{\bf z} \\
\hat{\bf y} \times \hat{\bf z} &=&\, \hat{\bf x} \\
\hat{\bf z} \times \hat{\bf x} &=&\, \hat{\bf y} \end{split}
\end{equation*}
\sphinxAtStartPar
In general however we write the cross product between two vectors as a new vector, normal to the other two (following the right hand rule), as depicted in
\hyperref[\detokenize{VectorCalculus/vectoralgebra:vectorproduct}]{Fig.\@ \ref{\detokenize{VectorCalculus/vectoralgebra:vectorproduct}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{VectorProduct}.png}
\caption{Left Pane: Graphical depiction of the cross product, producing a vector \(\bf a \times b\) which is normal to both \(\bf a,\, b\),
Right Pane: The area of the parallogram produced by vectors \(\bf a,\, b\) is found from \(|\bf a \times b|\)}\label{\detokenize{VectorCalculus/vectoralgebra:vectorproduct}}\end{figure}

\sphinxAtStartPar
This means that if vectors span an angle \(\theta\), then we need to resolve the perpendicular component:
\begin{equation*}
\begin{split}{\bf a \times b} = {\bf |a||b|}\sin(\theta)\,\hat{\bf n}\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\hat{\bf n}\) is vector which is normal to both \(\bf a,\, b\).

\sphinxAtStartPar
Because the cross product follows the right hand rule for axes, it is anti\sphinxhyphen{}commutative:
\begin{equation*}
\begin{split}\bf a \times b = -\,b \times a\end{split}
\end{equation*}
\sphinxAtStartPar
We also find the at the cross product is distributive over addition,
\begin{equation*}
\begin{split}\mathbf {a} \times (\mathbf {b} +\mathbf {c} )=(\mathbf {a} \times \mathbf {b} )+(\mathbf {a} \times \mathbf {c} )\end{split}
\end{equation*}
\sphinxAtStartPar
and compatible with scalar multiplication:
\begin{equation*}
\begin{split}(r\,\mathbf {a} )\times \mathbf {b} =\mathbf {a} \times (r\,\mathbf {b} )=r\,(\mathbf {a} \times \mathbf {b} )\end{split}
\end{equation*}
\sphinxAtStartPar
Likewise since the vector magnitude depends on the angle between the two vectors, if we cross a vector with itself (or another vector that is parallel / anti\sphinxhyphen{}parallel),
the answer is zero:
\begin{equation*}
\begin{split}\bf a \times a = 0\end{split}
\end{equation*}
\sphinxAtStartPar
where \(\bf 0\) is a zero vector.


\subsection{Algebraic Definition}
\label{\detokenize{VectorCalculus/vectoralgebra:id1}}
\sphinxAtStartPar
Once again there is also an algebraic route to the cross product, this is based on the vector components.

\sphinxAtStartPar
Since the cross product is distributive over addition we find that:
\begin{equation*}
\begin{split} \mathbf{a}\times\mathbf{b} = {} &(a_x\,\hat{\bf x} + a_y\,\hat{\bf y} + a_z\,\hat{\bf z}) \times (b_x\,\hat{\bf x} + b_y\,\hat{\bf y} + b_z\,\hat{\bf z})\\
                            = {} &a_x\,b_x(\hat{\bf x} \times \hat{\bf x}) + a_x\,b_y(\hat{\bf x} \times \hat{\bf y}) + a_x\,b_z(\hat{\bf x} \times \hat{\bf z}) + {}\\
                                 &a_y\,b_x(\hat{\bf y} \times \hat{\bf x}) + a_y\,b_y(\hat{\bf y} \times \hat{\bf y}) + a_y\,b_z(\hat{\bf y} \times \hat{\bf z}) + {}\\
                                 &a_z\,b_x(\hat{\bf z} \times \hat{\bf x}) + a_z\,b_y(\hat{\bf z} \times \hat{\bf y}) + a_z\,b_z(\hat{\bf z} \times \hat{\bf z})\\\end{split}
\end{equation*}
\sphinxAtStartPar
If we follow through our rules for computing the cross products of basis vectors, we find this simplifies to:
\begin{equation*}
\begin{split} \mathbf{a}\times\mathbf{b} = {} &a_x\,b_x(0) + a_x\,b_y(\hat{\bf z}) + a_x\,b_z(-\hat{\bf y}) + {}\\
                                 &a_y\,b_x(-\hat{\bf z}) + a_y\,b_y(0) + a_y\,b_z(\hat{\bf x}) + {}\\
                                 &a_z\,b_x(\hat{\bf y}) + a_z\,b_y(-\hat{\bf x}) + a_z\,b_z(0)\\
							= {} &(a_y\,b_z - a_z\,b_y)\hat{\bf x} + (a_z\,b_x - a_x\,b_z)\hat{\bf y} + (a_x\,b_y - a_y\,b_x)\hat{\bf z} \end{split}
\end{equation*}
\sphinxAtStartPar
Finding the cross product can also be found using a matrix determinant:
\begin{equation*}
\begin{split} \mathbf{a}\times\mathbf{b} = \begin{vmatrix}
 \hat{\bf x} & \hat{\bf y} & \hat{\bf z} \\
 a_x & a_y & a_z \\
 b_x & b_y & b_z
\end{vmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
which by the cofactor method along the first row produces:
\begin{equation*}
\begin{split} \mathbf{a}\times\mathbf{b} &=&\, \begin{vmatrix}
 a_y & a_z \\
 b_y & b_z
\end{vmatrix}\hat{\bf x} - \begin{vmatrix}
 a_x & a_z \\
 b_x & b_z
\end{vmatrix}\hat{\bf y} + \begin{vmatrix}
 a_x & a_y 
 b_x & b_y 
\end{vmatrix}\hat{\bf z} \\
&=&\, (a_y\,b_z - a_z\,b_y)\hat{\bf x} - (a_x\,b_z - a_x\,b_z)\hat{\bf y} + (a_x\,b_y - a_y\,b_x)\hat{\bf z} \end{split}
\end{equation*}
\sphinxAtStartPar
which we find are equivalent definitions.


\section{Triple Vector Products}
\label{\detokenize{VectorCalculus/vectoralgebra:triple-vector-products}}
\sphinxAtStartPar
Now that we have multiplcation of two vectors formalised, we find that multiplying three vectors also leads to some further geometric and algebraic ideas.


\subsection{Triple Scalar Product}
\label{\detokenize{VectorCalculus/vectoralgebra:triple-scalar-product}}
\sphinxAtStartPar
Here we have three vectors \(\bf a, \,b,\,c\) composed so that
\begin{equation*}
\begin{split}\bf a \cdot (b \times c)\end{split}
\end{equation*}
\sphinxAtStartPar
since the combination of \(\bf b \times c\) produces a vector, which we can then do a scalar multiplcation with \(\bf a\).  Therefore this produces a scalar result.

\sphinxAtStartPar
Geometrically this is related to the parallepiped, as depicted in \hyperref[\detokenize{VectorCalculus/vectoralgebra:parallepiped}]{Fig.\@ \ref{\detokenize{VectorCalculus/vectoralgebra:parallepiped}}}, where the magnitude of this result is the shapes volume:
\begin{equation*}
\begin{split}V = |{\bf a \cdot (b \times c)}|\end{split}
\end{equation*}
\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{parallepiped}.png}
\caption{A parallepiped, composed from three vectors \(\bf a, \,b,\,c\).}\label{\detokenize{VectorCalculus/vectoralgebra:parallepiped}}\end{figure}

\sphinxAtStartPar
We can also evaluate the triple scalar product from a matrix determinant:
\begin{equation*}
\begin{split} {\bf a \cdot (b \times c)} = \mathbf{a}\times\mathbf{b} = \begin{vmatrix}
 a_x & a_y & a_z \\
 b_x & b_y & b_z \\
 c_x & c_y & c_z \\
\end{vmatrix}\end{split}
\end{equation*}

\subsection{Triple Vector Product}
\label{\detokenize{VectorCalculus/vectoralgebra:triple-vector-product}}
\sphinxAtStartPar
Unsurprisingly we can also find an expression for the vector product between three vectors \(\bf a, \,b,\,c\):
\begin{equation*}
\begin{split}\bf a \times (b \times c) = (a\cdot c)b - (a \cdot b)c\end{split}
\end{equation*}
\sphinxAtStartPar
which is useful particularly when we want to work out results like:
\begin{equation*}
\begin{split}\bf \nabla \times \nabla \times A = \nabla(\nabla \cdot A) - (\nabla\cdot \nabla)A = \nabla(\nabla \cdot A) - \nabla^2 A\end{split}
\end{equation*}
\sphinxAtStartPar
which will be useful later!


\chapter{Vector Fields}
\label{\detokenize{VectorCalculus/calculusonfields:vector-fields}}\label{\detokenize{VectorCalculus/calculusonfields::doc}}
\sphinxAtStartPar
A field in a mathematical sense is some function which can be defined within some domain \(D\), we will examine fields in two and three spatial dimensions,
(but this can be extended to more later as required), therefore \(D \subset \mathbb{R}^2\) or \(D \subset \mathbb{R}^3\) respectively.  If \(D\) is not specified, then
we assume the whole of the space is being used as the domain.

\sphinxAtStartPar
In a physical sense, a field is some physical quantity which has a value at every point within a space, examples of which include temperature, distances, velocities,
acceleations, forces, electric and magnetic fields.

\sphinxAtStartPar
One impoirtant distinction to make between fields is whether they are Scalar, Vector or some other (e.g. Tensor although this is beyond
the scope of this course).


\section{Scalar Fields}
\label{\detokenize{VectorCalculus/calculusonfields:scalar-fields}}
\sphinxAtStartPar
A scalar field is a physical quantity which has some value (or magnitude) but contains no information about direction, at every point \({\bf r} = (x, \,y, \,z)\)
within a domain. Physical examples include pressure and temperature.  Mathematically we can write this as a function \(\phi\) such that:
\begin{equation*}
\begin{split}\phi \,:\, D \,\subset\, \mathbb{R}^3 \,&\longrightarrow&\, \mathbb{R} \\
{\bf r} &\longrightarrow&\, \phi({\bf r})\end{split}
\end{equation*}

\section{Vector Fields}
\label{\detokenize{VectorCalculus/calculusonfields:id1}}
\sphinxAtStartPar
A vector field A scalar field is a physical quantity which has both magnitude and direction, at every point \({\bf r} = (x, \,y, \,z)\) within a domain.  Physical
examples include velocity, force, and electric and magnetic fields.  Mathematically we can write this as a function \(\bf A(r)\) such that:
\begin{equation*}
\begin{split}\phi \,:\, D \,\subset\, \mathbb{R}^3 \,&\longrightarrow&\, \mathbb{R}^3 \\
{\bf r} &\longrightarrow&\, {\bf A(r)} = \begin{pmatrix}
 A_x ({\bf r})\\
 A_y ({\bf r})\\
 A_z ({\bf r}) 
\end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
We can picture these fields in \hyperref[\detokenize{VectorCalculus/calculusonfields:scalarvectorfield}]{Fig.\@ \ref{\detokenize{VectorCalculus/calculusonfields:scalarvectorfield}}}, outlining the difference between scalar and vecor fields.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{scalarvectorfield}.png}
\caption{ Left Pane: An example of a two\sphinxhyphen{}dimensional scalar field, \(\phi(x,\, y) = \exp(-(x^2+y^2))\) (plotted in green on the \(z\) axis) defined
over the domain \(D\,:\,x^2 + y^2 \leq 1\) (shown in red on the \((x,\,y)\) plane),
 Center Pane: Contour lines of the scalar field, showing lines of constant \(\phi\) in blue, within the domain \(D\),
 Right Pane: The vector field \({\bf A(r)} = \frac{1}{10}\begin{pmatrix}
 x\\
 y^2
\end{pmatrix}\) over the same domain \(D\).}\label{\detokenize{VectorCalculus/calculusonfields:scalarvectorfield}}\end{figure}


\section{Calculus on Fields}
\label{\detokenize{VectorCalculus/calculusonfields:calculus-on-fields}}

\subsection{Gradient Operator}
\label{\detokenize{VectorCalculus/calculusonfields:gradient-operator}}
\sphinxAtStartPar
Now that we have defined fields, which can vary according to different parameters at every point within a domain, we can begin to apply
our toolkit of mathematical tools, here calculus.

\sphinxAtStartPar
We can find the partial derivatives of fields in a similar way to functions, for example for \(\phi = \exp(-(x^2+y^2)\), \({\bf A(r)} = \frac{1}{10}\begin{pmatrix}
 x\\
 y^2
\end{pmatrix}\):
\begin{equation*}
\begin{split}\partial_x \phi &=&\, -2x\,\exp(-(x^2+y^2) \\
\partial_y \phi &=&\, -2y\,\exp(-(x^2+y^2) \\
\partial_x {\bf A(r)} &=&\, \frac{1}{10}\begin{pmatrix}
 1\\
 0
\end{pmatrix} \\
\partial_y {\bf A(r)} &=&\, \frac{1}{10}\begin{pmatrix}
 0\\
 2y
\end{pmatrix} \end{split}
\end{equation*}
\sphinxAtStartPar
These partial derivatives measure the change of \(\phi\) along the directions of \(x\) or \(y\), but can we calculate the derivative of \(\phi\) along some
general direction, characterised by a unit vector \(\hat{\bf u}\):
\begin{equation*}
\begin{split}\hat{\bf u} = \begin{pmatrix}
 u_x\\
 u_y\\
 u_z
\end{pmatrix} \end{split}
\end{equation*}
\sphinxAtStartPar
We need a directional derivative, which can tell us about the changes in \(\phi\) along each component of \$\textbackslash{}hat\{\textbackslash{}bf u\}.  This leads us to the gradient
operator:
\begin{equation*}
\begin{split}\nabla = \begin{pmatrix}
 \partial/\partial x \\
 \partial/\partial y \\
 \partial/\partial z 
\end{pmatrix} \end{split}
\end{equation*}
\sphinxAtStartPar
which as an operator needs to act on a scalar field:
\begin{equation*}
\begin{split}\nabla \phi = \begin{pmatrix}
 \partial\phi/\partial x \\
 \partial\phi/\partial y \\
 \partial\phi/\partial z 
\end{pmatrix} \end{split}
\end{equation*}
\sphinxAtStartPar
We see that this is now a vector field, which we can resolve in the \(\hat{\bf u}\) direction:
\begin{equation*}
\begin{split}\hat{\bf u} \cdot \nabla \phi\end{split}
\end{equation*}
\sphinxAtStartPar
which is our directional derivative of \(\phi\) in the \(\hat{\bf u}\) direction, which we often write as \(\nabla_{\hat{\bf u}} \phi\).

\sphinxAtStartPar
Looking at this expression further:
\begin{equation*}
\begin{split}|\nabla_{\hat{\bf u}} \phi| = \hat{\bf u} \cdot \nabla \phi = |\hat{\bf u}||\nabla \phi|\cos (\theta) = |\nabla \phi|\cos (\theta)\end{split}
\end{equation*}
\sphinxAtStartPar
therefore \(|\nabla_{\hat{\bf u}} \phi|\) is maximised when \(\theta = 0\) \sphinxhyphen{} The gradient \(\nabla \phi\) of a scalar field \(\phi\) always points toward the
direction of maximum increase of \(\phi\) (i.e. a maxima).

\sphinxAtStartPar
Likewise the directional derivative is zero when \(\theta = \pi/2\), i.e. tangential surfaces, which would be given by \(\phi({\bf r}) = C\) which is
one dimension lower than the dimension of the problem (therefore in 3D, these would be surface areas, in 2D there would be contour lines).

\sphinxAtStartPar
As example, lets consider \(\phi = \exp(-(x^2+y^2)\) defined over the domain \(x^2 + y^2 \leq 1\):
\begin{equation*}
\begin{split}\nabla \phi = \begin{pmatrix}
 -2x\,\exp(-(x^2+y^2) \\
 -2y\,\exp(-(x^2+y^2)
\end{pmatrix} = -2\,\exp(-(x^2+y^2) \begin{pmatrix}
 x \\
 y
\end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
We see that for all \(x,\, y\) within the domain, the vector will be directed inwards, as we see in \hyperref[\detokenize{VectorCalculus/calculusonfields:scalarfieldgradient}]{Fig.\@ \ref{\detokenize{VectorCalculus/calculusonfields:scalarfieldgradient}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{scalarfieldgradient}.png}
\caption{Gradients \(\nabla \phi\) for a scalr field \(\phi(\hat{\bf r}) = \exp(-(x^2+y^2))\) at a few different points along the contour plot (denoted
\(\bf r=r_0\)).  The gradients are perpendicular to the contour lines and point toward the direction of the largest increase of \(\phi\),
which from \hyperref[\detokenize{VectorCalculus/calculusonfields:scalarvectorfield}]{Fig.\@ \ref{\detokenize{VectorCalculus/calculusonfields:scalarvectorfield}}} we know is a maxima.}\label{\detokenize{VectorCalculus/calculusonfields:scalarfieldgradient}}\end{figure}


\chapter{1st Order Variations of Fields}
\label{\detokenize{VectorCalculus/divandcurl:st-order-variations-of-fields}}\label{\detokenize{VectorCalculus/divandcurl::doc}}

\section{Divergence}
\label{\detokenize{VectorCalculus/divandcurl:divergence}}
\sphinxAtStartPar
If we start with a vector field \({\bf A(r)} = A_x({\bf r})\,\hat{\bf x} + A_y({\bf r})\,\hat{\bf y} + A_z({\bf r})\,\hat{\bf z} \), then we can define the quantity
\(\nabla\cdot {\bf A(r)}\), i.e. taking the scalar product of the gradient operator with vector field \({\bf A(r)} \) which since the gradient vector is a differential
operator, means the expression has the form:
\begin{equation*}
\begin{split}\nabla\cdot {\bf A(r)} = \partial_x\, A_x + \partial_y\, A_y + \partial_z\, A_z\end{split}
\end{equation*}
\sphinxAtStartPar
This is often known as the Divergence of \({\bf A(r)}\) or \(\text{div}\,{\bf A(r)}\).  Note that in the case of operators we need to be a little careful of the
ordering of the terms, since \({\bf A(r)}\cdot \nabla\) would give:
\begin{equation*}
\begin{split}{\bf A(r)} \cdot \nabla= A_x\,\partial_x  + A_y\,\partial_y  + A_z\,\partial_z  \end{split}
\end{equation*}
\sphinxAtStartPar
which is also a differential operator, waiting to act on another term, which we apply on the right.

\sphinxAtStartPar
Lets see the effect of this on two vector fields \({\bf A_1(r)} = \begin{pmatrix} x \\ y \\ 0\end{pmatrix}, \,{\bf A_2(r)} = \begin{pmatrix} y \\ -x \\ 0\end{pmatrix}\):
\begin{equation*}
\begin{split}\nabla \cdot {\bf A_1} &=&\, \partial_x\, x + \partial_y\, y + \partial_z\, 0 = 2 \\
\nabla \cdot {\bf A_2} &=&\, \partial_x\, y - \partial_y\, x + \partial_z\, 0 = 0 \end{split}
\end{equation*}
\sphinxAtStartPar
which we can visualise in \hyperref[\detokenize{VectorCalculus/divandcurl:div}]{Fig.\@ \ref{\detokenize{VectorCalculus/divandcurl:div}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{div}.png}
\caption{Plotting the vector field \({\bf A_1}\) which has non\sphinxhyphen{}zero divergence.}\label{\detokenize{VectorCalculus/divandcurl:div}}\end{figure}

\sphinxAtStartPar
We can see that the origin here really plays the role of a centre of the divergence, the field lines all appear to flow outwards, becuase here \(\nabla \cdot {\bf A} > 0\).  In the case of
\(\nabla \cdot {\bf A} < 0\), field lines would flow into a point and there would be a convergnece of the field.


\section{Curl}
\label{\detokenize{VectorCalculus/divandcurl:curl}}
\sphinxAtStartPar
We can likewise take a vector field \$\({\bf A(r)} \) and here take the vector product with the gradient operator \(\nabla\times {\bf A(r)}\), which has components:
\begin{equation*}
\begin{split}\nabla\times {\bf A(r)} = \begin{pmatrix} \partial_y\, A_z - \partial_z\, A_y \\ \partial_z\, A_x - \partial_x\, A_z \\ \partial_x\, A_y - \partial_y\, A_x  \end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
which is know as the Curl or Rotation of the vector field \(\bf A(r)\) or \(\text{curl}\,{\bf A(r)}\).

\sphinxAtStartPar
To see the effects of these, lets consider again \({\bf A_1(r)} = \begin{pmatrix} x \\ y \\ 0\end{pmatrix}, \,{\bf A_2(r)} = \begin{pmatrix} y \\ -x \\ 0\end{pmatrix}\):
\begin{equation*}
\begin{split}\nabla \times {\bf A_1} &=&\, \begin{pmatrix} \partial_y\, 0 + \partial_z\, x \\ \partial_z\, y - \partial_x\, 0 \\ \partial_x\, y - \partial_y\, x  \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 0 \end{pmatrix} \\
\nabla \times {\bf A_2} &=&\, \begin{pmatrix} \partial_y\, 0 + \partial_z\, x \\ \partial_z\, y - \partial_x\, 0 \\ \partial_x\, x + \partial_y\, y  \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ 2 \end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
which we can visualise in \hyperref[\detokenize{VectorCalculus/divandcurl:id1}]{Fig.\@ \ref{\detokenize{VectorCalculus/divandcurl:id1}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{curl}.png}
\caption{Plotting the vector field \({\bf A_2}\) which has non\sphinxhyphen{}zero curl.}\label{\detokenize{VectorCalculus/divandcurl:id1}}\end{figure}

\sphinxAtStartPar
We note that “centre” of this rotation is at the origin and that \(\nabla \times {\bf A_2}\) points in the \(z\) direction.  We define this rotation as following the right
hand rule, depicted in \hyperref[\detokenize{VectorCalculus/divandcurl:righthandcurl}]{Fig.\@ \ref{\detokenize{VectorCalculus/divandcurl:righthandcurl}}}, curling the fingers on our right hand around and the thumb pointing in the direction of the vector.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{Rhandrule}.png}
\caption{The right hand rule for a curl field}\label{\detokenize{VectorCalculus/divandcurl:righthandcurl}}\end{figure}

\sphinxAtStartPar
We can see that a linear combination of vector fields \(\bf A_1 + A_2\) would produce a vector field with both divergence and curl, which is shown in \hyperref[\detokenize{VectorCalculus/divandcurl:divcurl}]{Fig.\@ \ref{\detokenize{VectorCalculus/divandcurl:divcurl}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{divcurl}.png}
\caption{The effect of adding a divergence (curl free) field to a curl (divergence free) field.}\label{\detokenize{VectorCalculus/divandcurl:divcurl}}\end{figure}

\sphinxAtStartPar
We can use the product rule as well as the rules following scalar and vector products to find a vareity of vector calculus relations:
\begin{equation*}
\begin{split}\nabla(\phi\,\psi) &=&\, \psi(\nabla \phi) + \phi(\nabla \psi)\\
\nabla \cdot(\phi {\bf A}) &=&\, (\nabla \phi)\cdot {\bf A} + \phi(\nabla \cdot {\bf A})\\
\nabla \times(\phi {\bf A}) &=&\, (\nabla \phi)\times {\bf A} + \phi(\nabla \times {\bf A})\\
\nabla \cdot ({\bf A \times B}) &=&\, (\nabla \times {\bf A})\cdot {\bf B} - {\bf A}(\nabla \times\cdot {\bf B})\\
\nabla \times ({\bf A \times B}) &=&\, (\nabla \cdot {\bf B} + {\bf B}\cdot \nabla)\,{\bf A} - (\nabla \cdot {\bf A}+ {\bf A}\cdot \nabla)\,{\bf B}\end{split}
\end{equation*}

\section{2nd Order Variations of Fields}
\label{\detokenize{VectorCalculus/divandcurl:nd-order-variations-of-fields}}
\sphinxAtStartPar
We can combine two or more gradients in a vector expression, one of the most useful is to find the divergence of the gradient of a scalar field \(\phi\),
\begin{equation*}
\begin{split}\textrm{div grad} \,\phi = \nabla \cdot (\nabla \phi) = \nabla^2 \phi = (\partial_x^2 + \partial_y^2 + \partial_z^2)\phi\end{split}
\end{equation*}
\sphinxAtStartPar
This is sometimes also written as \(\Delta\phi = \nabla^2 \phi \) and is known as the Laplacian of \(\phi\).

\sphinxAtStartPar
We can also find the divergence of the curl of a vector field:
\begin{equation*}
\begin{split}\text{div}\,\,\text{curl}\,{\bf A} = \nabla \cdot (\nabla \times {\bf A}) = 0\end{split}
\end{equation*}
\sphinxAtStartPar
which holds for all vector fields.  Thinking again about the fields shown in \hyperref[\detokenize{VectorCalculus/divandcurl:divcurl}]{Fig.\@ \ref{\detokenize{VectorCalculus/divandcurl:divcurl}}},w e can think of these two processes as complementary,
rotation around a point compared with emergence from / convergence to a point.

\sphinxAtStartPar
Likewise if we look at the curl of a gradient field:
\begin{equation*}
\begin{split}\text{curl}\,\,\text{grad}\,\phi = \nabla \times \nabla \phi = 0\end{split}
\end{equation*}
\sphinxAtStartPar
which is true for all scalar fields.

\sphinxAtStartPar
In general we can write a vector field as having two sets of components, one curl free and one divergence free, this is known as the Helmholtz Decomposition of a vector field:
\begin{equation*}
\begin{split}{\bf B} = -\nabla \phi + \nabla \times {\bf A}\end{split}
\end{equation*}

\chapter{Set Theory}
\label{\detokenize{ProofLogic/setsnotation:set-theory}}\label{\detokenize{ProofLogic/setsnotation::doc}}
\sphinxAtStartPar
Set theory is a branch of mathematics that studies collections of objects known as Sets.  The language of set theory, which will start to study here, can be used
to define almost all mathematical objects (if you are interested in what cannot be so easily defined, look up ideas such as Gödel’s incompleteness theorem and Russell’s Paradox).


\section{Notation}
\label{\detokenize{ProofLogic/setsnotation:notation}}
\sphinxAtStartPar
There are lots of symbols in the notation used to describe mathematical objects, some of which we may have seen already.  We can put together some elementary operations on sets:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
Symbol
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Meaning
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Example
\\
\hline
\sphinxAtStartPar
\(\{ \}\)
&
\sphinxAtStartPar
Defines a set
&
\sphinxAtStartPar
e.g. \(A = \{1,\,2,\,3,\,4\}\), \( B = \{3,\,4,\,5\}\)
\\
\hline
\sphinxAtStartPar
\(A \cup B\)
&
\sphinxAtStartPar
Union \sphinxhyphen{} in \(A\) OR \(B\) (OR both)
&
\sphinxAtStartPar
\(A \cup B = \{1, \,2, \,3, \,4, \,5\}\)
\\
\hline
\sphinxAtStartPar
\(A \cap B\)
&
\sphinxAtStartPar
Intersection \sphinxhyphen{} in \(A\) AND \(B\)
&
\sphinxAtStartPar
\(A \cap B = \{3, \,4\}\)
\\
\hline
\sphinxAtStartPar
\(A \subseteq B\)
&
\sphinxAtStartPar
Subset \sphinxhyphen{} every element of \(A\) is in \(B\)
&
\sphinxAtStartPar
\(\{3,\,4,\,5\} \subseteq B\)
\\
\hline
\sphinxAtStartPar
\(A \subset  B\)
&
\sphinxAtStartPar
Proper Subset \sphinxhyphen{} every element of \(A\) is in \(B\), but \(B\) has more elements
&
\sphinxAtStartPar
\(\{1,\, 2,\, 3\} \subset A\)
\\
\hline
\sphinxAtStartPar
\(A \not\subset B\)
&
\sphinxAtStartPar
Not a Subset \sphinxhyphen{} \(A\) is not a subset of \(B\)
&
\sphinxAtStartPar
\(\{1, \,5\} \not\subset A\)
\\
\hline
\sphinxAtStartPar
\(A \supseteq B\)
&
\sphinxAtStartPar
Superset \sphinxhyphen{} every element of \(A\) is in \(B\)
&
\sphinxAtStartPar
\( B \supseteq \{3,\,4,\,5\}\)
\\
\hline
\sphinxAtStartPar
\(A \supset B\)
&
\sphinxAtStartPar
Proper Superset \sphinxhyphen{} every element of \(B\) is in \(A\), but \(A\) has more elements
&
\sphinxAtStartPar
\(A \supset \{1, \,2, \,3\}\)
\\
\hline
\sphinxAtStartPar
\(A \nsupseteq B\)
&
\sphinxAtStartPar
Not a Superset \sphinxhyphen{} \(A\) is not a superset of \(B\)
&
\sphinxAtStartPar
\(\{1, \,2, \,6\} \nsupseteq \{1, \,9\}\)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Additionally we can build up structure with some more advanced operations on sets:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
Symbol
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Meaning
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Example
\\
\hline
\sphinxAtStartPar
\(\varnothing\)
&
\sphinxAtStartPar
Empty set \( = \{\}\)
&
\sphinxAtStartPar
\(\{1,\, 2\} \cap \{3,\, 4\} = \varnothing \)
\\
\hline
\sphinxAtStartPar
\(\mathbb{U}\)
&
\sphinxAtStartPar
Universal Set \sphinxhyphen{} set of all possible values in the area of interest
&
\sphinxAtStartPar
e.g. \(\mathbb{U} = \{1,\,2,\,3,\,4,\,5,\,6,\,7\}\)
\\
\hline
\sphinxAtStartPar
\(A^c\) or \(A'\) or \(\neg A\) or \(\bar{A}\)
&
\sphinxAtStartPar
Complement \sphinxhyphen{} elements not in \(A\)
&
\sphinxAtStartPar
\(\neg A = \{5,\,6,\,7\}\) \(B' = \{1,\, 2, \,6,\, 7\}\)
\\
\hline
\sphinxAtStartPar
\(A - B\) or \(A \setminus B\)
&
\sphinxAtStartPar
Difference \sphinxhyphen{} in \(A\) but not in \(B\)
&
\sphinxAtStartPar
\(\{1,\, 2,\, 3,\, 4\} \setminus \{3,\, 4\} = \{1,\, 2\}\)
\\
\hline
\sphinxAtStartPar
\(A \oplus B\)
&
\sphinxAtStartPar
Symmetric Difference \sphinxhyphen{} in \(A\) or in \(B\) but not in both \(A\) and \(B\)
&
\sphinxAtStartPar
\(\{1,\, 2,\, 3,\, 4\} \ \{3,\, 4\} = \{1,\, 2\}\)
\\
\hline
\sphinxAtStartPar
\(a \in A\)
&
\sphinxAtStartPar
Element of \sphinxhyphen{} \(a\) is in \(A\)
&
\sphinxAtStartPar
\(3 \in A\)
\\
\hline
\sphinxAtStartPar
\(b \notin A\)
&
\sphinxAtStartPar
Not element of \sphinxhyphen{} \(b\) is not in \(A\)
&
\sphinxAtStartPar
\(6 \notin A\)
\\
\hline
\sphinxAtStartPar
\(P(A)\)
&
\sphinxAtStartPar
Power Set \sphinxhyphen{} all subsets of \(A\)
&
\sphinxAtStartPar
\(P(\{1, 2\}) = \{ \{\}, \{1\}, \{2\}, \{1,\, 2\} \}\)
\\
\hline
\sphinxAtStartPar
\(A = B\)
&
\sphinxAtStartPar
Equality \sphinxhyphen{} both sets have the same members
&
\sphinxAtStartPar
e.g. \(C = \{5,\,3,\,4\},\, C = B\)
\\
\hline
\sphinxAtStartPar
\(A \times B\)
&
\sphinxAtStartPar
Cartesian Product \sphinxhyphen{} set of ordered pairs from \(A\) and \(B\)
&
\sphinxAtStartPar
\(\{1,\, 2\} \times \{3, \,4\} \) \(= \{(1, \,3), \,(1,\, 4), \,(2,\, 3),\, (2,\, 4)\}\)
\\
\hline
\sphinxAtStartPar
\(\|A\|\) or \(n(A)\)
&
\sphinxAtStartPar
Cardinality \sphinxhyphen{}  the number of elements in set \(A\)
&
\sphinxAtStartPar
\(\|A\| = 4,\,\|B\| = 3\)
\\
\hline
\sphinxAtStartPar
\(\|\) or \(:\) or st
&
\sphinxAtStartPar
Such that
&
\sphinxAtStartPar
\(\{ n\, \|\, n > 0 \} = \{1, 2, 3, \dots\}\)
\\
\hline
\sphinxAtStartPar
\( \forall\)
&
\sphinxAtStartPar
For All
&
\sphinxAtStartPar
\(\forall \,x > 1,\, x^2 > x\)
\\
\hline
\sphinxAtStartPar
\(\exists\)
&
\sphinxAtStartPar
There Exists
&
\sphinxAtStartPar
\(\exists \, x \,\|\, x^2 > x\)
\\
\hline
\sphinxAtStartPar
\( \therefore\)
&
\sphinxAtStartPar
Therefore
&
\sphinxAtStartPar
\( a = b \therefore b=a\)
\\
\hline
\sphinxAtStartPar
iff or \(\iff\)
&
\sphinxAtStartPar
If and only if
&
\sphinxAtStartPar
\(2a = 2\) iff \(a=1\)
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\section{Definition of a set}
\label{\detokenize{ProofLogic/setsnotation:definition-of-a-set}}
\sphinxAtStartPar
There are two basic ways to define a set:
\begin{itemize}
\item {} 
\sphinxAtStartPar
List / Tabular Form, where we list the members of the set in any order.  For example, the set of all the vowels and consonants:

\end{itemize}
\begin{equation*}
\begin{split}    V &=& \{a,\,e,\,i\,o,\,u\} \\
    C &=& \{b,\,c,\,d,\,f,\,g,\,h,\,j,\,k,\,l,\,m,\,n,\,p,\,q,\,r,\,s,\,t,\,v,\,w,\,x,\,y,\,z\}\end{split}
\end{equation*}
\sphinxAtStartPar
or the set of the Natural number and Integers:
\begin{equation*}
\begin{split}    \mathbb{N} &=& \{1,\,2,\,3,\dots \} \\
    \mathbb{Z} &=& \{ \dots,\,-3,\,-2,\,-1,\,0,\,1,\,2,\,3,\,\dots \}\end{split}
\end{equation*}\begin{itemize}
\item {} 
\sphinxAtStartPar
Set\sphinxhyphen{}Builder Form / Property Method,
where we state the properties which characterise the elements of a set, i.e. those held by members of the set (but not by non\sphinxhyphen{}members.  For example:

\end{itemize}
\begin{equation*}
\begin{split}    A = \{x\,:\, x \text{ is an integer}\}\end{split}
\end{equation*}
\sphinxAtStartPar
which we read is “The set \(A\), defined by elements \(x\), such that \(x\) is an integer”.  There are many ways to write out such a statement, the simplest is
to use the wider notation of set theory.   For example, the set of Rational numbers or Complex numbers:
\begin{equation*}
\begin{split}    \mathbb{Q} &=& \left\{ \frac{m}{n} \,\,\middle|\,\, m,\,n \in  \mathbb{Z}\right\} \\
    \mathbb{C} &=& \left\{ a + i\,b \,\,\middle|\,\, a,\,b\in \mathbb{R},\, i^2 = -1\right\}\end{split}
\end{equation*}

\section{Venn Diagrams}
\label{\detokenize{ProofLogic/setsnotation:venn-diagrams}}
\sphinxAtStartPar
We can represent sets pictorially using Venn diagrams (named after a Logician and Philosopher Dr John Venn, who’s grandfather Rev John Venn has a street named
after him in Clapham, South London!), which are an easy to see how different sets can have shared and unique elements as well as defining the Universal set \(\mathbb{U}\) in a given context.

\sphinxAtStartPar
Considering our example of sets \(A,\,B,\,\mathbb{U}\):
\begin{equation*}
\begin{split}\mathbb{U} &=& \{ 1,\,2,\,3,\,4,\,5,\,6,\,7\}\\
A &=& \{1,\,2,\,3,\,4\}\\
B &=& \{3,\,4,\,5\}\end{split}
\end{equation*}
\sphinxAtStartPar
this could be represented by the Venn diagram in \hyperref[\detokenize{ProofLogic/setsnotation:venn1}]{Fig.\@ \ref{\detokenize{ProofLogic/setsnotation:venn1}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{Venn1}.png}
\caption{Venn diagram depicting sets \(A,\,B,\,\mathbb{U}\).}\label{\detokenize{ProofLogic/setsnotation:venn1}}\end{figure}

\sphinxAtStartPar
We can see that the union of both sets is given by the entire shaded area
\begin{equation*}
\begin{split}A \cup B = \{1,\,2,\,3,\,4,\,5\}\end{split}
\end{equation*}
\sphinxAtStartPar
whilst the intersection of both sets is given by the shared shaded area
\begin{equation*}
\begin{split}A \cap B = \{ 3,\,4\}\end{split}
\end{equation*}
\sphinxAtStartPar
For the difference between the sets,
\begin{equation*}
\begin{split}(A\cup B) \setminus B &=& \{ 1,\,2\} \\
(A\cup B) \setminus A &=& \{ 5\} \end{split}
\end{equation*}
\sphinxAtStartPar
these could be represented by Venn diagrams, such as that seen in \hyperref[\detokenize{ProofLogic/setsnotation:venn2}]{Fig.\@ \ref{\detokenize{ProofLogic/setsnotation:venn2}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{Venn2}.png}
\caption{Venn diagram depicting sets \(A\), \(B\), \(A \cup A\), \(| \cap B\) and \((A\cup B) \setminus B\).}\label{\detokenize{ProofLogic/setsnotation:venn2}}\end{figure}

\sphinxAtStartPar
and likewise the complement
\begin{equation*}
\begin{split}\neg A &=& \{5,\,6,\,7\} \\
\neg B &=& \{1,\,2,\,6,\,7\} \\
\neg (A \cup B) &=& \{6,\,7\}\\
\neg (A \cap B) &=& \{1,\,2,\,5,\,6,\,7\} \end{split}
\end{equation*}
\sphinxAtStartPar
these could be represented by Venn diagrams with appropriate shading.


\section{Laws of the Algebra of Sets}
\label{\detokenize{ProofLogic/setsnotation:laws-of-the-algebra-of-sets}}
\sphinxAtStartPar
Sets follow a specific algebra, which we can deduce by following the logical principles outlined previously. There are identity laws, i.e. can we
use AND or OR like multiplying or adding on 1 or 0:
\begin{equation*}
\begin{split}A \cup \varnothing &=& A \\
A \cap \varnothing &=& \varnothing \\
A \cap \mathbb{U} &=& A \\
A \cup \mathbb{U} &=& \mathbb{U}\end{split}
\end{equation*}
\sphinxAtStartPar
Associative laws, i.e. does the position of the brackets matter:
\begin{equation*}
\begin{split}(A \cup B) \cup C &=&  A \cup (B \cup C)\\
(A \cap B) \cap C &=&  A \cap (B \cap C)\end{split}
\end{equation*}
\sphinxAtStartPar
Commutative laws, i.e. does the order of operations matter:
\begin{equation*}
\begin{split}A \cup B &=& B \cup A \\
A \cap B &=& B \cap A\end{split}
\end{equation*}
\sphinxAtStartPar
Distributive laws, i.e. does the operation in a bracket expand out:
\begin{equation*}
\begin{split}A \cup (B \cap C) &=& (A\cup B) \cap (A \cup C)\\
A \cap (B \cup C) &=& (A\cap B) \cup (A \cap C)\end{split}
\end{equation*}
\sphinxAtStartPar
Involution laws, i.e. is the inverse of the inverse return to the original state:
\begin{equation*}
\begin{split}\neg(\neg A) = A\end{split}
\end{equation*}
\sphinxAtStartPar
Idempotent laws, i.e. it’s everything or nothing:
\begin{equation*}
\begin{split}A \cup A &=& A \\
A \cap A &=& A\end{split}
\end{equation*}
\sphinxAtStartPar
Complement laws, i.e. does everything add up together or subtract to zero:
\begin{equation*}
\begin{split}A \cup \neg A &=& \mathbb{U} \\
A \cap \neg A &=& \varnothing \\
\neg \mathbb{U} &=& \varnothing \\
\neg \varnothing &=& \mathbb{U}\end{split}
\end{equation*}
\sphinxAtStartPar
And finally DeMorgan’s laws, which refer to overall inverse relations:
\begin{equation*}
\begin{split}\neg(A \cup B) &=& \neg A \cap \neg B \\
\neg(A \cap B) &=& \neg A \cup \neg B\end{split}
\end{equation*}

\section{Counting Sets}
\label{\detokenize{ProofLogic/setsnotation:counting-sets}}
\sphinxAtStartPar
It is often useful to count elements within sets and therefore use the logical extensions of these ideas to find the particular areas of shaded Venn diagrams.If \(A\) and \(B\) are finite, disjoint sets, i.e. \(A \cup B = C\) is finite and \(A \cap B = \varnothing\), then
\begin{equation*}
\begin{split}n(C) = n(A) + n(B)\end{split}
\end{equation*}
\sphinxAtStartPar
A simple example of this is
\begin{equation*}
\begin{split}n(\mathbb{U}) = n(A) + n(\neg A)\end{split}
\end{equation*}
\sphinxAtStartPar
which is simply joining up a set and its complement. One issue with counting elements in sets is over counting, consider for finite sets \(A\) and \(B\):
\begin{equation*}
\begin{split}n(A \cup B) = n(A) + n(B) - n(A \cap B)\end{split}
\end{equation*}
\sphinxAtStartPar
which is outlined graphically in Figure \hyperref[\detokenize{ProofLogic/setsnotation:venn2}]{Fig.\@ \ref{\detokenize{ProofLogic/setsnotation:venn2}}}.  We can also state this idea as:
\begin{equation*}
\begin{split}n(A \cup B) \leq n(A) + n(B)\end{split}
\end{equation*}
\sphinxAtStartPar
where the equality holds if the sets are disjoint and the inequality holds otherwise.  To avoid this over counting, we can construct the set \(A \cap B\) and so
\begin{equation*}
\begin{split}n(A\setminus B) = n(A) - n(A \cap B)\end{split}
\end{equation*}
\sphinxAtStartPar
We can also extend these statement to many sets, suppose \(A,\,B,\,C\) are finite sets:
\begin{equation*}
\begin{split}n(A \cup B \cup C) &=& n(A) + n(B) + n(C) \\ &-&  n(A\cap B) - n(A\cap C) - n(B \cap C) \\ &+&  n(A \cap B \cap C)\end{split}
\end{equation*}
\sphinxAtStartPar
where we need to remove the double counting, but in doing so we loose the triple counting, so we need to re\sphinxhyphen{}add this total intersection at the end.


\chapter{Functions}
\label{\detokenize{ProofLogic/functions:functions}}\label{\detokenize{ProofLogic/functions::doc}}
\sphinxAtStartPar
We are probably quite used to thinking about functions when we plot graphs, such as \(y = x^2\) or \(y = \cos(x)\), as we idealise in \hyperref[\detokenize{ProofLogic/functions:functionmachine}]{Fig.\@ \ref{\detokenize{ProofLogic/functions:functionmachine}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{functionmachine2}.png}
\caption{These are examples of a much richer mathematical structure, known as Functions, which we can roughly think of as a machine with inputs and outputs.}\label{\detokenize{ProofLogic/functions:functionmachine}}\end{figure}


\section{Definition of a Function}
\label{\detokenize{ProofLogic/functions:definition-of-a-function}}
\sphinxAtStartPar
To set this up in a firmer mathematical way, we can think about functions as the mapping of elements between different sets.  Lets denote the set
\(A\), which contain the elements we wish to map unique to elements in another set \(B\), this mapping will be the function \(f\) from \(A\) to \(B\):
\begin{equation*}
\begin{split}f:\,A \rightarrow B\end{split}
\end{equation*}
\sphinxAtStartPar
which we read as “\(f\) is a function from \(A\) to \(B\)”.  The elements of the set \(A\), which we think of as the range of values in the inputs, is known as the
Domain of the function and elements of the set \(B\), which we think of as the range of values of the outputs are known as the Target Set or Co\sphinxhyphen{}Domain of
the function.

\sphinxAtStartPar
There are several notations for functions:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
Notation
&\sphinxstyletheadfamily 
\sphinxAtStartPar
Meaning
\\
\hline
\sphinxAtStartPar
\(f(x) = x^2\)
&
\sphinxAtStartPar
\(x\) as a variable for the function \(f\)
\\
\hline
\sphinxAtStartPar
\(x \mapsto x^2\)
&
\sphinxAtStartPar
\(x\) goes into \(x^2\)
\\
\hline
\sphinxAtStartPar
\(y = x^2\)
&
\sphinxAtStartPar
\(x\) is the independent variable and \& \(y\) is the dependent variable
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Given a function \(f:\, A \rightarrow B\), then for an element \(a \in A\) the function \(f(a)\) maps \(a\) to a unique element in \(b \in B\).

\sphinxAtStartPar
We call \(f(a)\) the Image of \(a\) under \(f\), or \(d(a)\) is the Value of \(f\) at \(a\) or that \(f\) Sends or Maps \(a\) into \(f(a)\).

\sphinxAtStartPar
The set of all image values is called the Range or Image of \(f\), which is denoted as:
\begin{equation*}
\begin{split} \text{Im}(f) = \text{Ran}(f) = f(A) = \{b \in B\,:\, \text{there exists }\, a \in A \,\,\text{for which }\, f(a) = b\}\end{split}
\end{equation*}
\sphinxAtStartPar
and we should make clear that \(\text{Im}(f) \subset B\).

\sphinxAtStartPar
Given \(f: A \rightarrow B\), then for some subset \(A' \subset A\). \(f(A')\) denotes the set of images of elements in \(A'\) and if \(B' \subset B\) and \(f^{-1}(B')\)
denotes the set of elements of A each whose image belongs to \(B'\):
\begin{equation*}
\begin{split} f(A') = \{f(a)\,:\,a \in A\} \Longleftrightarrow f^{-1}(B') = \{a\in A\,:\,f(a)\in B\}\end{split}
\end{equation*}
\sphinxAtStartPar
given we call \(f(A')\) the imagine of \(A'\), we call \(f^{-1}(B')\) the Inverse Image or Preimage of \(B'\).

\sphinxAtStartPar
We also define an Identity function \(I_A\), which simply send an element back to itself, \(I_A:\,A \rightarrow A\):
\begin{equation*}
\begin{split}I_A(a) = a\end{split}
\end{equation*}
\sphinxAtStartPar
for every element \(a \in A\).

\sphinxAtStartPar
Finally we can define the Graph of a function \(f:\,A \rightarrow B\) as the series of order pairs of elements \(a \in A\) mapped to elements \(b = f(a) \in B\):
\begin{equation*}
\begin{split}\text{Graph of }\,f = \{(a,\,b)\,:\, a \in A,\,b = f(a)\}\end{split}
\end{equation*}
\sphinxAtStartPar
A function \(f\) is defined from a set \(A = \{a,\,b,\,c,\,d\}\) into a set \(B = \{r,\,s,\,t,\,u\}\). with a mapping:
\begin{equation*}
\begin{split}f(a) &=&\, s \\
f(b) &=&\, u \\
f(c) &=&\, r \\
f(d) &=&\, s\end{split}
\end{equation*}
\sphinxAtStartPar
which we can represent graphically as shown in \hyperref[\detokenize{ProofLogic/functions:functionimage}]{Fig.\@ \ref{\detokenize{ProofLogic/functions:functionimage}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{FunctionImage}.png}
\caption{The image \(f\) is the set \(\text{Im}(f) = \{r,\,s,\,u\}\) and the element is \(t \notin \text{Im}(f)\) because \(t\) is not the image of any
element of \(A\) under \(f\) \sphinxhyphen{} therefore any elements not mapped to under a function are excluded from the image of the function.}\label{\detokenize{ProofLogic/functions:functionimage}}\end{figure}

\sphinxAtStartPar
The graph of \(f\) is the following set of ordered pairs:
\begin{equation*}
\begin{split}\{ (a,\,s),\,(b,\,u),\,(c,\,r),\,(d,s) \}\end{split}
\end{equation*}

\section{Composite Functions}
\label{\detokenize{ProofLogic/functions:composite-functions}}
\sphinxAtStartPar
Using the idea of mapping from one set to another, it is possible to introduce functions of functions or composite functions, mapping from one set to another, through
some intermediate set.  Consider functions \(f:\,A \rightarrow B\) and \(g:\,B \rightarrow C\), where the target set \(B\) of \(f\) is the domain of \(g\).  We can call this new function
the Composition of \(f\) and \(g\), denoted by:
\begin{equation*}
\begin{split}g \circ f \equiv g(f(a)\end{split}
\end{equation*}
\sphinxAtStartPar
where we emphasise that the composition of functions is read from right to left (and not left to right as we usually do).  We picture this in \hyperref[\detokenize{ProofLogic/functions:compositefunction}]{Fig.\@ \ref{\detokenize{ProofLogic/functions:compositefunction}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{compositefunction}.png}
\caption{We can introduce more and more functions and same rules apply, however we can also consider the associativity of the composition of functions, given
\(f:\,A \rightarrow B,\,g:\, b \rightarrow C,\,h:\,c \rightarrow D\).}\label{\detokenize{ProofLogic/functions:compositefunction}}\end{figure}

\sphinxAtStartPar
The composition law is also associative:
\begin{equation*}
\begin{split}h \circ(g \circ f) = (h \circ g) \circ f\end{split}
\end{equation*}
\sphinxAtStartPar
which we prove diagrammatically in \hyperref[\detokenize{ProofLogic/functions:assocompfns}]{Fig.\@ \ref{\detokenize{ProofLogic/functions:assocompfns}}}.

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{associativitycompositefunctions}.png}
\caption{Associativity of composite functions.}\label{\detokenize{ProofLogic/functions:assocompfns}}\end{figure}

\sphinxAtStartPar
Lets think about two simple functions:
\begin{equation*}
\begin{split}f(x) &=&\, x^2\\
g(x) &=&\,\ \cos(x)\end{split}
\end{equation*}
\sphinxAtStartPar
We can composite these functions by writing:
\begin{equation*}
\begin{split}f(g(x)) = (f \circ g)(x) &=&\, (\cos(x))^2 \\
g(f(x)) = (g \circ f)(x) &=&\, \cos(x^2)\end{split}
\end{equation*}
\sphinxAtStartPar
where we notice that in general \(f(g(x)) \neq g(f(x))\).  These composite functions can be built up by looking at the function on the furthest right and
then adding more functions on to the left hand side.  Suppose we introduce a third function:
\begin{equation*}
\begin{split}h(x) = \frac{2}{x}\end{split}
\end{equation*}
\sphinxAtStartPar
then the six different functional compositions would be:
\begin{equation*}
\begin{split}f \circ (g \circ h) &=&\, \left( \cos \left( \frac{2}{x} \right) \right)^2 & f \circ (h \circ g) = \left( \frac{2}{\cos(x)} \right)^2 \\ 
g \circ (h \circ f) &=&\, \cos \left( \frac{2}{x^2} \right) & g \circ (f \circ h) = \cos \left( \left( \frac{2}{x}\right)^2  \right) \\ 
h \circ (f \circ g) &=&\, \frac{2}{\left( \cos (x) \right)^2 } & h \circ (g \circ f) = \frac{2}{\cos(x^2)}\end{split}
\end{equation*}
\sphinxAtStartPar
and we see that the associativity of these composites can be shown to be true:
\begin{equation*}
\begin{split} f\circ g &=&\, (\cos(x))^2\\
 g \circ h &=&\, \cos\left(\frac{2}{x}\right) \\ 
f \circ (g \circ h) &=&\, (f \circ g) \circ h = \left( \cos \left( \frac{2}{x} \right) \right)^2\end{split}
\end{equation*}

\section{Invertibility of Functions}
\label{\detokenize{ProofLogic/functions:invertibility-of-functions}}
\sphinxAtStartPar
A function \(f:\,A \rightarrow B\) is said to be one\sphinxhyphen{}to\sphinxhyphen{}one or Injective  if different elements in the domain \(A\) have distinct images, i.e.
\begin{equation*}
\begin{split}f\,\text{ is one-to-one if }\,f(a) = f(a') \Rightarrow a = a'\end{split}
\end{equation*}
\sphinxAtStartPar
Likewise we can set up a function \(f:\,A \rightarrow B\) is said to be an onto function or Surjective if every element \(b \in B\) is the image
of some element \(a \in A\), i.e. the image of \(f\) is the entire target set \(B\):
\begin{equation*}
\begin{split}f\,\text{ maps }\,A \text{ onto }\,B\,\text{ if }\,\forall\, b \in B,\, \exists \,a \in A, \,\text{ s.t.}\, f(a) = b\end{split}
\end{equation*}
\sphinxAtStartPar
A function \(f:\,A \rightarrow B\) is said to be invertible if there exists a function \(f^{-1}:\, B\rightarrow A\) such that:
\begin{equation*}
\begin{split}f^{-1} \circ f = I_A \Longleftrightarrow f \circ f^{-1} = I_B\end{split}
\end{equation*}
\sphinxAtStartPar
A function \(f:\,A \rightarrow B\) is invertible iff \(f\) is both one\sphinxhyphen{}to\sphinxhyphen{}one and onto.  We say such functions are a one\sphinxhyphen{}to\sphinxhyphen{}one correspondence
between \(A\) and \(B\).  This is also known as a Bijection.

\sphinxAtStartPar
Lets consider functions \(f_1:\,A \rightarrow B\), \(f_2:\,B \rightarrow C\), \(f_3:\,C \rightarrow D\), \(f_4:\,D \rightarrow E\) depicted in \hyperref[\detokenize{ProofLogic/functions:invertibilityoffunctions}]{Fig.\@ \ref{\detokenize{ProofLogic/functions:invertibilityoffunctions}}}

\begin{figure}[htbp]
\centering
\capstart

\noindent\sphinxincludegraphics{{InvertibilityOfFunctions}.png}
\caption{Invertibility of four functions which map elements from \(A \rightarrow B \rightarrow C \rightarrow D \rightarrow E\).}\label{\detokenize{ProofLogic/functions:invertibilityoffunctions}}\end{figure}
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(f_1:\,A \rightarrow B\) is one\sphinxhyphen{}to\sphinxhyphen{}one but not onto, since every element in \(A\) has a unique image, but element \(3 \in B\) does not have any image under \(f_1\).

\item {} 
\sphinxAtStartPar
\(f_2:\,B \rightarrow C\) is both one\sphinxhyphen{}to\sphinxhyphen{}one and onto, i.e. it is a onto\sphinxhyphen{}to\sphinxhyphen{}one correspondence for all elements in \(B\) and \(C\) and thus \(f^{-1}:\, C \rightarrow B\) exists.

\item {} 
\sphinxAtStartPar
\(f_3:\,C \rightarrow D\) is not one\sphinxhyphen{}to\sphinxhyphen{}one but is onto since \(f_3(r) = f_3(u) = v\), but every element in \(D\) has an image under \(f_3\).

\item {} 
\sphinxAtStartPar
\(f_4:\, D \rightarrow E\) is neither one\sphinxhyphen{}to\sphinxhyphen{}one nor onto, since \(f_4(v) = f_4(w) = z\) and there are elements in \(E\) which are not images under \(f_4\).

\end{itemize}


\chapter{Propositional Logic}
\label{\detokenize{ProofLogic/propositionallogic:propositional-logic}}\label{\detokenize{ProofLogic/propositionallogic::doc}}
\sphinxAtStartPar
We can turn out statements about set theory into statements about propositions, in the classical logic sense of TRUE and FALSE \sphinxhyphen{} so called
Propositional Logic.  If you’re interested in areas of logic where some of these ideas are challened, have a look at
\sphinxhref{https://doi.org/10.2307/1968621}{The Logic of Quantum Mechanics, by Birkhoff \& Von Neumann}.

\sphinxAtStartPar
A propositional or statement is a declaration that is either TRUE (T) or FALSE (F) but not both.  Some propositions are composite or
compound \sphinxhyphen{} i.e. composed of sub\sphinxhyphen{}propositions and then are connected in different ways.  Others are primitive or unitary, i.e. cannot be broken down in to
simpler propositions.  One way to present and calculate the outcomes of compound statements is to use a <truth table \sphinxhyphen{} these might look familiar from computer science,
where the associated algebra is known as Boolean algebra and the T/F is replaced with 1/0.

\sphinxAtStartPar
Our ideas from set theory can be very easily applied in this area, using the algebra of basic logic:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Conjunction

\end{itemize}

\sphinxAtStartPar
\(p \wedge q\): Any two propositions can be combined by the word “AND” to form a compound proposition, known as a conjunction.  The overall truth value of \(p \wedge q\)
depends on the truth values of \(p\) and \(q\), according to the truth table below:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p \wedge q\)
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Disjunction

\end{itemize}

\sphinxAtStartPar
\(p \vee q\): Any two propositions can be combined by the word “OR” to form a compound proposition known as a disjunction.  The overall truth value of
\(p \vee q\) depends on the truth values of \(p\) and \(q\), according to the truth table below:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p \vee q\)
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Negation

\end{itemize}

\sphinxAtStartPar
\(\neg p\): Given any proposition \(p\), we can formed another proposition called the negation of \(p\), which can be formed by writing a “NOT” right before it or
saying “it is false that”.  The overall truth value of \(\neg p \) depends on the truth value of \(p\), according to the truth table below:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\neg p\)
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Order of Precedence

\end{itemize}

\sphinxAtStartPar
In order to avoid a lot of parentheses when writing down logical connectives, there is a preferred order of precedence.
\begin{equation*}
\begin{split}\neg \,\text{has precedence over} \,\wedge\, \text{which has precedence over}\, \vee \end{split}
\end{equation*}
\sphinxAtStartPar
We can think of this as analogous to BIDMAS on numbers:
\begin{itemize}
\item {} 
\sphinxAtStartPar
Brackets,

\item {} 
\sphinxAtStartPar
Indices,

\item {} 
\sphinxAtStartPar
Division/Multiplication,

\item {} 
\sphinxAtStartPar
Addition/Subtraction

\end{itemize}

\sphinxAtStartPar
An example would be \(\neg p \wedge q\) means \((\neg p) \wedge q\) and NOT \(\neg(p \wedge q)\) which we can see from the truth table are different:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p \wedge q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\neg p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\neg p \wedge q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\neg (p \wedge q)\)
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
We can use these ideas to outline and differentiate logical ideas, such as those of Contradiction and Tautology. A contraction is a proposition that is always
false, e.g. it is raining and it isn’t raining, we can see this as a truth table that ends with all F’s.  Equally a tautology is a proposition that is always true,
e.g. it is raining or isn’t raining, we can see this as a truth table that ends with all T’s.  We can see these shown below:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\neg p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p \wedge \neg p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p \vee \neg p\)
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\section{Laws of the Algebra of Propositions}
\label{\detokenize{ProofLogic/propositionallogic:laws-of-the-algebra-of-propositions}}
\sphinxAtStartPar
There are identity laws, i.e. using AND or OR like multiplying or adding on 1 or 0:
\begin{equation*}
\begin{split}p \vee F &=&\, p \\
p \wedge F &=&\, F \\
p \wedge T &=&\, p \\
p \vee T &=&\, T\end{split}
\end{equation*}
\sphinxAtStartPar
Associative laws, i.e. does the position of the brackets matter:
\begin{equation*}
\begin{split}(p \vee q) \vee r &=&\,  p \vee (q \vee r)\\
(p \wedge q) \wedge r &=&\,  p \wedge (q \wedge r)\end{split}
\end{equation*}
\sphinxAtStartPar
Commutative laws, i.e. does the order of operations matter:
\begin{equation*}
\begin{split}p \vee q &=&\, q \vee p \\
p \wedge q &=&\, q \wedge p\end{split}
\end{equation*}
\sphinxAtStartPar
Distributive laws, i.e. does the operation in a bracket expand out:
\begin{equation*}
\begin{split}p \vee (q \wedge r) &=&\, (p\vee q) \wedge (p \wedge r)\\
p \wedge (q \vee r) &=&\, (p\wedge q) \vee (p \wedge r)\end{split}
\end{equation*}
\sphinxAtStartPar
Involution laws, i.e. is the inverse of the inverse return to the original state:
\begin{equation*}
\begin{split}\neg(\neg p) = p\end{split}
\end{equation*}
\sphinxAtStartPar
Idempotent laws, i.e. it’s everything or nothing:
\begin{equation*}
\begin{split}p \vee p &=&\, p \\
p \wedge p &=&\, p\end{split}
\end{equation*}
\sphinxAtStartPar
Complement laws, i.e. does everything add up together or subtract to zero:
\begin{equation*}
\begin{split}p \vee \neg p &=&\, T \\
p \wedge \neg p &=&\, F \\
\neg T &=&\, F \\
\neg F &=&\, T\end{split}
\end{equation*}
\sphinxAtStartPar
And finally DeMorgan’s laws, which refer to overall inverse relations:
\begin{equation*}
\begin{split}\neg(p \vee q) &=&\, \neg p \wedge \neg q \\
\neg(p \wedge q) &=&\, \neg p \vee \neg q\end{split}
\end{equation*}
\sphinxAtStartPar
which we see mirrors the algebra of sets.


\section{Conditional and Biconditional Statements}
\label{\detokenize{ProofLogic/propositionallogic:conditional-and-biconditional-statements}}
\sphinxAtStartPar
Many statements in mathematics and elsewhere are of the form if a proposition \(p\) (called the antecedent) applies then a proposition
\(q\) (called the consequent) follows, these are known as Conditional statements and are denoted:
\begin{equation*}
\begin{split}p \rightarrow q\end{split}
\end{equation*}
\sphinxAtStartPar
which is read \(p\) Implies \(q\) or \(p\) only if \(q\).  The truth table is defined as:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p \rightarrow q\)
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
We note that the conditional \(p \rightarrow q\) is only false when \(p = T\) and \(q = F\).

\sphinxAtStartPar
Another common statement is of the form proposition \(p\) applies if and only if proposition \(q\) applies, these are known as Biconditional statements
and are denoted:
\begin{equation*}
\begin{split}p \longleftrightarrow q\end{split}
\end{equation*}
\sphinxAtStartPar
The truth table is defined as:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p \longleftrightarrow q\)
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
We note that the conditional \(p \longleftrightarrow q\) is true when \(p\) and \(q\) have the same truth values and false otherwise.

\sphinxAtStartPar
What is also interesting here is that \(p \rightarrow q\) is composite, it can be constructed from primitive propositions:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\neg p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\neg p \vee q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p \rightarrow q\)
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
and therefore we see the equivalence between the two propositions:
\begin{equation*}
\begin{split}p \rightarrow q \equiv \neg p \vee q\end{split}
\end{equation*}

\section{Arguments and Fallacies}
\label{\detokenize{ProofLogic/propositionallogic:arguments-and-fallacies}}
\sphinxAtStartPar
A logical argument is a situation where there are given set of propositions \(\{P_1,\,P_2,\,\dots P_n\}\) called Premises have that as a consequence
(or yield) a proposition \(Q\) known as a Conclusion, we denote this:
\begin{equation*}
\begin{split}\{P_1,\,P_2,\,\dots P_n \}\vdash Q\end{split}
\end{equation*}
\sphinxAtStartPar
An argument \(\{P_1,\,P_2,\,\dots P_n\} \vdash Q\) is said to be valid if \(Q\) is true whenever all the premises \(\{P_1,\,P_2,\,\dots P_n\}\) are true
but otherwise it is false.  An argument that is not true is known as a fallacy.

\sphinxAtStartPar
We can consider some simple arguments and their validity:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\{p,\,p \rightarrow q\} \vdash q\)

\end{itemize}

\sphinxAtStartPar
We should consider the truth table for all the premises and see if they can be simultaneously true:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p \rightarrow q\)
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Since in the first line the case of the two premises \(\{p,\,p\rightarrow q\}\) being simultaneously true results in \(q\) true, this argument is valid.
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(\{p \rightarrow q,\,q\} \vdash p\)

\end{itemize}

\sphinxAtStartPar
We should consider the truth table for all the premises and see if they can be simultaneously true:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p \rightarrow q\)
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Since in the first line the case of the two premises being simultaneously true results in \(p\) being true and in the third line the case of the two premises being
true results in \(p\) being false, this argument is fallacy.


\section{Logical Implications}
\label{\detokenize{ProofLogic/propositionallogic:logical-implications}}
\sphinxAtStartPar
A proposition \(P(p,\,q,\,\dots)\) is said to Logically Imply a proposition \(Q(p,\,q,\,\dots)\) if \(Q(p,\,q,\,\dots)\) is true whenever \(P(p,\,q,\,\dots)\) is
true.  We denote this as:
\begin{equation*}
\begin{split}P(p,\,q,\,\dots) \Rightarrow Q(p,\,q,\,\dots) \end{split}
\end{equation*}
\sphinxAtStartPar
We can consider the truth table:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(p \Rightarrow p \vee q\)

\end{itemize}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p \vee q\)
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Since in the first two rows \(p \vee q\) is true whenever \(p\) is true, thus \(p \Rightarrow p \vee q\):
\begin{itemize}
\item {} 
\sphinxAtStartPar
\(p \Rightarrow \neg p \vee \neg q\).

\end{itemize}


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
\(p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\neg p\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\neg q\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\neg p \wedge \neg q\)
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
\\
\hline
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
F
\\
\hline
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
F
&
\sphinxAtStartPar
T
&
\sphinxAtStartPar
T
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Since in the final row \(\neg p \vee \neg q\) is true but \(p\) is false, this implication is false.


\chapter{Techniques of Proof}
\label{\detokenize{ProofLogic/methodsofproof:techniques-of-proof}}\label{\detokenize{ProofLogic/methodsofproof::doc}}

\section{Proof by Contradiction}
\label{\detokenize{ProofLogic/methodsofproof:proof-by-contradiction}}
\sphinxAtStartPar
This is a form of proof that seeks to establish if the validity of a proposition by showing that by assuming the proposition is false leads to a direct contradiction.
We can summarise the technique as:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
The statement to proven \(P\) is assumed false, i.e. assume \(\lnot{P}\) is true.

\item {} 
\sphinxAtStartPar
\(\lnot P\) leads directly to assertions \(Q\) and \(R\), such that \(R = \lnot Q\).

\item {} 
\sphinxAtStartPar
Since \(Q\) and \(\lnot Q\) cannot both be simultaneously true, \(\lnot P\) is also untrue and hence \(P\) is true.

\end{enumerate}

\sphinxAtStartPar
By way of an example, consider this classic proof from Euclid:

\sphinxAtStartPar
Statement: There are infinitely many prime numbers

\sphinxAtStartPar
Proof:
The fundamental theorem of arithmetic states that every positive integer (other than 1) can be represented in exactly one way (apart from rearrangement)
as a product of one or more primes.  Assume there are \(n\) finitely many prime numbers \(p\), then consider the number \(N\) composed of the product of all of the
prime numbers from the first \(p_1 = 2\) up to the largest \(p_n\):
\begin{equation*}
\begin{split}N = p_1.p_2...p_{n-1}.p_n\end{split}
\end{equation*}
\sphinxAtStartPar
Now consider the number \(N+1\)
\begin{equation*}
\begin{split}N+1 = p_1.p_2...p_{n-1}.p_n+1\end{split}
\end{equation*}
\sphinxAtStartPar
Since \(N+1\) is another whole number, it should be divisible by one of the prime numbers \(p={p_1,p_2,\dots,p_n}\), but clearly it cannot be \sphinxhyphen{} hence contradiction.  Therefore
there cannot be a finite number of primes and so there are an infinite number of primes. QED


\section{Proof by Counterexample}
\label{\detokenize{ProofLogic/methodsofproof:proof-by-counterexample}}
\sphinxAtStartPar
This is form of proof that disproves a proposition by giving an example which is a direct contradiction to the proposition.  This technique is often used to disprove a
universal (or \(\forall\) type) statement.  We can summarise the technique as:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
The statement \(P\) is shown to be satisfied by an example \(E_1\) and it is assumed

\item {} 
\sphinxAtStartPar
A further example \(E_2\) is shown not to satisfy \(P\) or leads directly to assertion \(\lnot P\) being true.

\item {} 
\sphinxAtStartPar
Since \(P\) and \(\lnot P\) cannot both be simultaneously true, \(P\) cannot be held to be always true (although can be shown to sometimes hold).

\end{enumerate}

\sphinxAtStartPar
By way of an example, consider this classic proof:

\sphinxAtStartPar
Statement: \(\forall n \in \mathbb{R}\), if \(n^2\) is divisible by 4, then \(n\) is divisible by 4.

\sphinxAtStartPar
Proof:
We can find examples where this proof holds for both divisibility, e.g. \(n=4\), \(n^2 = 16\) and non\sphinxhyphen{}divisibility e.g. \(n=5\), \(n^2=25\).

\sphinxAtStartPar
However a counter example to this statement would be given by \(n = 6\), \(n^2=36\), here the \(n^2\) statement passes the test but \(n\) statement in the
proposition does not \sphinxhyphen{} hence the statement can be shown not be always true.  QED


\section{Proof by Induction}
\label{\detokenize{ProofLogic/methodsofproof:proof-by-induction}}
\sphinxAtStartPar
This is a form of proof where a proposition, which is shown to be true for an initial case and a more general case \(n\), which then allows a higher general
case \(n+1\) to be shown to be true.  This idea of a higher and higher steps on a proof ladder can be quite a powerful technique.  We can summarise the technique as:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
A proposition \(P_n\) is shown to be true for an initial or base case, i.e. we can prove that the statement holds for \(0, 1\).

\item {} 
\sphinxAtStartPar
Assuming that the proposition is true for \(P_n\), we can show that it is true for \(P_{n+1}\).

\end{enumerate}

\sphinxAtStartPar
By way of an example, consider this classic proof:

\sphinxAtStartPar
Statement: Prove that
\begin{equation*}
\begin{split}S_n = 1 + 2 + \dots + n = \frac{n(n+1)}{2}\end{split}
\end{equation*}
\sphinxAtStartPar
Proof:
\(S_1 = \frac{1(2)}{2} = 1\) which is true, \(S_2 = \frac{2(3)}{2} = 3\) which is also true. Assuming that \(S_n\) is true, we need to see if we can prove \(S_{n+1} = \frac{(n+1)(n+2)}{2}\):
\begin{equation*}
\begin{split}S_{n+1} &=&\, 1 + 2 + \dots + n + n+1 = S_{n} + n+1 \\ 
&=&\, \frac{n(n+1)}{2} + n+1 \\ 
&=&\, \frac{n(n+1) + 2(n+1)}{2} \\ 
&=&\, \frac{(n+1)(n+2)}{2}\end{split}
\end{equation*}
\sphinxAtStartPar
QED


\section{Proof by Contraposition}
\label{\detokenize{ProofLogic/methodsofproof:proof-by-contraposition}}
\sphinxAtStartPar
We can summarise this technique as:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Given a statement \(P\) which leads directly to assertion \(Q\), i.e.

\end{enumerate}
\begin{equation*}
\begin{split}P \rightarrow Q \end{split}
\end{equation*}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
First order tells us that the negation of statement \(Q\), i.e. \(\neg Q\) leads directly to the negation of assertion \(P\), i.e. \(\neg P\),

\end{enumerate}
\begin{equation*}
\begin{split}\neg Q \rightarrow \neg P\end{split}
\end{equation*}
\sphinxAtStartPar
By way of an example, consider this classic proof:

\sphinxAtStartPar
Statement: Prove that for \(x \in \mathbb{R}\), if the function \(x^2 - 6x + 5\) is even, then \(x\) is odd.

\sphinxAtStartPar
Proof: Suppose \(x \in \mathbb{R}\) is even, when we need to show \(x^2 - 6x + 5\) is odd.Lets write \(x = 2a\) with some \(a \in \mathbb{Z}\), then we find that:
\begin{equation*}
\begin{split}x^2 - 6x + 5 &=& (2a)^2 - 6(2a) + 5 \\
&=& 4a^2 - 12a + 5 \\
&=& 2(2a^2 - 6a + 2) + 1\end{split}
\end{equation*}
\sphinxAtStartPar
which we can see clearly is odd.  Thus when \(x^2 - 6x + 5\) is odd, \(x\) is even and therefore when \(x^2 - 6x + 5\) is even, \(x\) is odd. QED


\section{Proof By Construction}
\label{\detokenize{ProofLogic/methodsofproof:proof-by-construction}}
\sphinxAtStartPar
We can summarise this technique as:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Given a statement \(P_1\), we construct  \(P_2,\,P_3,\,\dots,\,P_n\) which leads to assertion \(Q\),

\end{enumerate}
\begin{equation*}
\begin{split}    \{P_1,\,P_2,\,P_3,\,\dots,\,P_n\} \vdash Q\end{split}
\end{equation*}
\sphinxAtStartPar
Statement: Prove that for \(x \in \mathbb{R}\), if the function \(x^2 - 6x + 5\) is even, then \(x\) is odd.

\sphinxAtStartPar
Proof: For \(x \in \mathbb{R}\), lets write \(x^2 - 6x + 5 = 2a\) with some \(a \in \mathbb{N}\), so that \(x^2 - 6x + 5\) is even, then we find that:
\begin{equation*}
\begin{split}x^2 - 6x + 5 &=& 2a  \\
x^2 - 6x &=& 2a - 5 \\
x(x-6) &=& 2a - 5\end{split}
\end{equation*}
\sphinxAtStartPar
Since the RHS is clearly odd by construction, this means the LHS is odd.  Given that ODD \(\times\) ODD = ODD, then given \(x\) and \(x-6\) differ by an even numbers, \(x\) must be an odd number. QED


\chapter{Linear Systems of Equations}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/echelon_form:linear-systems-of-equations}}\label{\detokenize{LinearAlgebra/linear_systems_matrices/echelon_form::doc}}

\section{Gaussian Elimination}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/echelon_form:gaussian-elimination}}
\sphinxAtStartPar
The technique studied here makes solving large systems of equations (e.g. 200 equations in 200 unknowns) practical, and it can be implemented on a computer in a basic programming language. You might be surprised to learn that it is necessary to solve vast systems of linear equations as a matter of routine in many practical scientific applications.


\subsection{Motivation}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/echelon_form:motivation}}
\sphinxAtStartPar
Gaussian elimination is a systematic technique for solving systems of linear equations, which are of the form
\label{equation:LinearAlgebra/linear_systems_matrices/echelon_form:879189c2-8cf6-4479-ad48-c1c6f29dc91b}\begin{align}
a_{1,1} x_1 + a_{1,2} x_2 + a_{1,3} x_3 + \dots + a_{1,n} x_n &= b_1 \\

   a_{2,1} x_1 + a_{2,2} x_2 + a_{2,3} x_3 + \dots + a_{2,n} x_n &= b_2\\
                                                                     \vdots \\
 a_{m,1} x_1 + a_{m,2} x_2 + a_{m,3} x_3 + \dots + a_{m,n} x_n &= b_m
\end{align}
\sphinxAtStartPar
where \(a_{i,j}\) are constants. Usually there are the same number of equations as unknowns, so \(m = n\).  If \(m < n\) then the system is undetermined, if \(m > n\), the system is over constrained.

\begin{sphinxadmonition}{note}{Example}
\label{equation:LinearAlgebra/linear_systems_matrices/echelon_form:b7022e4f-dff8-4271-ac52-b86ef30209c4}\begin{align}4 x_1 - x_2 &= 1\\ -2 x_1 + 3 x_2 &= 12 \end{align}
\sphinxAtStartPar
Each equation here defines a line, and we are looking for a point which satisfies both equations, which means that the lines intersect.

\sphinxAtStartPar
From the first line we obtain \(x_2 = 4 x_1 - 1\), and by substituting this into the second line, we obtain \(x = \frac{3}{2}\), \(y = 5\). Two equations with two unknowns will always give a unique solution, unless the lines are parallel (and so the equations are just a scaling of each other).
\begin{itemize}
\item {} 
\sphinxAtStartPar
If they are parallel and distinct, there are no solutions because there are no points that lie on both lines.

\item {} 
\sphinxAtStartPar
If they are parallel and coincident (same line), there are an infinite number of solutions.

\end{itemize}
\end{sphinxadmonition}


\subsection{A systematic technique for solving systems of equations}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/echelon_form:a-systematic-technique-for-solving-systems-of-equations}}\label{\detokenize{LinearAlgebra/linear_systems_matrices/echelon_form:id1}}
\sphinxAtStartPar
We will begin by finding a solution to the following system:
\begin{alignat*}{5}
(r_1) &\qquad&  x_1 & {}+{} &  x_2 & {}+{} & 2x_3 & {}={} &  2  \\
(r_2) &\qquad&     2x_1 & {}+{} &  3x_2 & {}-{} & 4x_3 & {}={} &  1  \\
(r_3) &\qquad&  -x_1 & {}+{} &  x_2 & {}+{} & x_3 & {}={} & 3
\end{alignat*}
\sphinxAtStartPar
The equations have been labelled \(r_1,r_2,r_3\).

\sphinxAtStartPar
First, we will use \(r_1\) to eliminate \(x_1\) from \(r_2\) and \(r_3\). This gives two equations in two unknowns. Then, we will use \(r_2\) to eliminate \(x_2\) from \(r_3\).

\sphinxAtStartPar
The steps are written out below:
\begin{alignat*}{7}
&&&& (r_1) &\qquad&  x_1 & {}+{} &  x_2 & {}+{} & 2x_3 & {}={} &  2  \\
&&&& (r_2) &\qquad&     2x_1 & {}+{} &  3x_2 & {}-{} & 4x_3 & {}={} &  1  \\
&&&& (r_3) &\qquad&  -x_1 & {}+{} &  x_2 & {}+{} & x_3 & {}={} & 3\\
\\  
&&&& (r_1) &\qquad&  x_1 & {}+{} &  x_2 & {}+{} & 2x_3 & {}={} &  2   \\
r_2 & {}-{} & 2r_1 &\quad\longrightarrow\quad& (r_2) &\qquad&      &  &  x_2 & {}-{} & 8x_3 & {}={} &  -3  \\
r_3 & {}+{} & r_1 &\quad\longrightarrow\quad& (r_3) &\qquad&   &  &  2x_2 & {}+{} & 3x_3 & {}={} & 5  \\
  \\
&&&& (r_1) &\qquad&  x_1 & {}+{} &  x_2 & {}+{} & 2x_3 & {}={} &  2   \\
&&&& (r_2) &\qquad&      &  &  x_2 & {}-{} & 8x_3 & {}={} &  -3  \\
r_3 & {}-{} & 2r_2 &\quad\longrightarrow\quad& (r_3) &\qquad&   &  &  & & 19x_3 & {}={} & 11

\end{alignat*}
\sphinxAtStartPar
The solution for \(x_3\) can now be read off from \(r_3\), \(x_2\) can be obtained from \(r_2\) using the result for \(x_3\) and \(x_1\) can be obtained from \(r_1\) using the results for \(x_1\) and \(x_2\). This is known as \sphinxstylestrong{back\sphinxhyphen{}substitution}.

\sphinxAtStartPar
These manipulations can be conveniently done by looking only at the coefficients, which we collect together in a form called the augmented matrix:
\begin{equation*}
\begin{split}
\begin{array}{rc}
\begin{array}{r}
 (r_1)\\
 (r_2)\\
 (r_3)
\end{array}
&
\left(
\begin{array}{ccc|c}
\boxed{1} & 1 & 2 & 2 \\
2 & \boxed{3} & -4 & 1 \\
-1 & 1 & \boxed{1} & 3
\end{array}
\right)\\ \\
\begin{array}{ccr}
 & & (r_1)\\
r_2-2r_1 & \longrightarrow & (r_2) \\
r_3+r_1 & \longrightarrow & (r_3)
\end{array}
&
\left(
\begin{array}{ccc|c}
\boxed{1} & 1 & 2 & 2 \\
0 & \boxed{1} & -8 & -3 \\
0 & 2 & \boxed{3} & 5
\end{array}
\right) \\ \\
\begin{array}{ccr}
 & & (r_1)\\
& & (r_2) \\
r_3-2r_2 & \longrightarrow & (r_3)
\end{array}
&
\left(
\begin{array}{ccc|c}
\boxed{1} & 1 & 2 & 2 \\
0 & \boxed{1} & -8 & -3 \\
0 & 0 & \boxed{19} & 11
\end{array}
\right)
\end{array}
\end{split}
\end{equation*}
\sphinxAtStartPar
We can see that the algorithm (described in the box below) works by eliminating the coefficients below the leading diagonal, which is highlighted.

\begin{sphinxadmonition}{note}{Naive Gaussian elimination algorithm (obtaining upper triangular form)}

\sphinxAtStartPar
\sphinxstylestrong{Step 1} Choose initial pivot

\sphinxAtStartPar
We choose the first element from the leading diagonal as the pivot element.

\sphinxAtStartPar
\sphinxstylestrong{Step 2} Row reduction step

\sphinxAtStartPar
Add multiples of the pivot row to the rows below, to obtain zeros in the pivot column below the leading diagonal.

\sphinxAtStartPar
\sphinxstylestrong{Step 3} Choose new pivot

\sphinxAtStartPar
The pivot moves to the next element on the leading diagonal.

\sphinxAtStartPar
\sphinxstylestrong{Repeat}
Repeat from Step 2 until the matrix is in upper triangular form (containing all zeros below the leading diagonal).

\sphinxAtStartPar
The solutions can then be obtained by back\sphinxhyphen{}substitution.
\end{sphinxadmonition}
\phantomsection \label{exercise:q_elimination}

\begin{sphinxadmonition}{note}{Exercise 11.1}



\sphinxAtStartPar
Write the following system as an augmented matrix then solve it using the Naive Gaussian elimination algorithm.
\begin{equation*}
\begin{split}
\begin{alignat*}{4}
 x & {}-{} &  2y & {}+{} & z & {}={} &  0  \\
2x & {}+{} &  y & {}-{} & 3z & {}={} &  5  \\
4x & {}-{} &  7y & {}+{} & z & {}={} & -1
\end{alignat*}
\end{split}
\end{equation*}\end{sphinxadmonition}


\subsection{Generalisation}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/echelon_form:generalisation}}
\sphinxAtStartPar
The naive algorithm introduced here can be generalised to include additional row operations. In general, the acceptable row operations that we can perform are:
\begin{itemize}
\item {} 
\sphinxAtStartPar
multiplication of any row by a constant

\item {} 
\sphinxAtStartPar
addition of (a multiple of) any row to any other

\item {} 
\sphinxAtStartPar
swapping any two rows

\end{itemize}

\sphinxAtStartPar
It is often possible to apply these steps creatively to get a result with greater efficiency than using the naive algorithm described above.

\sphinxAtStartPar
It is also not necessary to stop at upper triangular form. Once the last row has been fully simplified, it can be used to obtain zeros above the main diagonal in the last column. Then, the second\sphinxhyphen{}last row is used to obtain zeros in the second\sphinxhyphen{}last column above the main diagonal, and so\sphinxhyphen{}on until the only non\sphinxhyphen{}zero elements remaining are on the main diagonal. Then the solutions can be simply read off from each row.
For instance, continuing with the naive row reduction for the example shown in the previous section, we obtain:
\begin{equation*}
\begin{split}
\begin{array}{rc}
\begin{array}{ccr}
 & & (r_1)\\
 & & (r_2)\\
 \frac{1}{19}r_3 & \longrightarrow & (r_3)
\end{array}
&
\left(
\begin{array}{ccc|c}
\boxed{1} & 1 & 2 & 2 \\
0 & \boxed{1} & -8 & -3 \\
0 & 0 & \boxed{1} & \frac{11}{19}
\end{array}
\right)\\ \\
\begin{array}{ccr}
r_1-2r_3 & \longrightarrow & (r_1)\\
r_2+8r_3 & \longrightarrow & (r_2) \\
 & & (r_3)
\end{array}
&
\left(
\begin{array}{ccc|c}
\boxed{1} & 1 & 0 & \frac{16}{19} \\
0 & \boxed{1} & 0 & \frac{31}{19} \\
0 & 0 & \boxed{1} & \frac{11}{19}
\end{array}
\right) \\ \\
\begin{array}{ccr}
r_1 - r_2 & \longrightarrow & (r_1)\\
& & (r_2) \\
& & (r_3)
\end{array}
&
\left(
\begin{array}{ccc|c}
\boxed{1} & 0 & 0 & -\frac{15}{19} \\
0 & \boxed{1} & 0 &  \frac{31}{19}\\
0 & 0 & \boxed{1} & \frac{11}{19}
\end{array}
\right)
\end{array}
\end{split}
\end{equation*}
\sphinxAtStartPar
We have obtained row\sphinxhyphen{}reduced form and the solutions for \(x_1,x_2,x_3\) can now be read off from the final column.


\section{Row Echelon Form}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/echelon_form:row-echelon-form}}
\sphinxAtStartPar
In this section we present an algorithm for solving a linear system of equations. The system algorithm works for any linear system of equations, regardless of whether there are zero, one or infinitely many solutions. It works by converting system of equations to \sphinxstylestrong{reduced row echelon form}.

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
A matrix is in \sphinxstylestrong{row echelon form} if:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
All zero rows are at the bottom.

\item {} 
\sphinxAtStartPar
The first nonzero entry of a row is to the right of the first nonzero entry of the row above.

\item {} 
\sphinxAtStartPar
Below the first nonzero entry of a row, all entries are zero.

\end{enumerate}
\label{equation:LinearAlgebra/linear_systems_matrices/echelon_form:29584da2-d089-4eca-898c-243d8049ba43}\begin{pmatrix}
\boxed{\star} & \star &\star &\star &\star \\
0     & \boxed{\star} &\star &\star &\star \\
0     &  0    & 0    & \boxed{\star} &\star \\
0 & 0 & 0 & 0 & 0           \end{pmatrix}
\sphinxAtStartPar
\(\star=\) any number\(\boxed{\star}=\) any non\sphinxhyphen{}zero number.

\sphinxAtStartPar
A \sphinxstylestrong{pivot} is the first nonzero entry of a row of a matrix in row echelon form.

\sphinxAtStartPar
A matrix is in \sphinxstylestrong{reduced row echelon form} if it is in row echelon form, and:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Each pivot is equal to 1.

\item {} 
\sphinxAtStartPar
Each pivot is the only nonzero entry in its column.

\end{enumerate}
\label{equation:LinearAlgebra/linear_systems_matrices/echelon_form:53ee6a8a-6109-456e-90a1-717d0e4b86d5}\begin{pmatrix}
1 & 0 &\star & 0 &\star \\
0     & 1 &\star &0 &\star \\
0     &  0    & 0    & 1 &\star \\
0 & 0 & 0 & 0 & 0           \end{pmatrix}
\sphinxAtStartPar
\(\star=\) any number
\end{sphinxadmonition}
\phantomsection \label{exercise:q_row_echelon_form}

\begin{sphinxadmonition}{note}{Exercise 11.2}



\sphinxAtStartPar
Which of the following matrices are in (a) row echelon form (b) reduced row echelon formed?
\begin{equation*}
\begin{split}
\begin{align*}
&1.~
\begin{pmatrix} 1 & 0 & 2 \\ 0 & 1 & -1
\end{pmatrix}\qquad
2.~\begin{pmatrix} 2 & 1 \\ 2 & 1
\end{pmatrix}\qquad
3.~\left(\begin{array}{ccc|c}
2 & 7 & 1 & 4\\
0 & 0 & 2 & 1\\
0 & 0 & 1 & 3
\end{array}\right)\\
&4.~\left(\begin{array}{ccc|c}
2 & 7 & 1 & 4\\
0 & 0 & 2 & 1\\
0 & 0 & 0 & 3
\end{array}\right)\qquad
5.~\begin{pmatrix} 0 & 1 & 8 & 0
\end{pmatrix}\qquad
6.~\begin{pmatrix} 2 & 1 & 3 \\ 0 & 0 & 0
\end{pmatrix}
\end{align*}
\end{split}
\end{equation*}\end{sphinxadmonition}


\subsection{Gaussian Elimination for Reduction to Echelon Form}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/echelon_form:gaussian-elimination-for-reduction-to-echelon-form}}
\begin{sphinxadmonition}{note}{Row Reduction Algorithm (Gaussian Elimination)}

\sphinxAtStartPar
\sphinxstylestrong{Step 1} If necessary, swap the 1st row with a lower one so a leftmost nonzero entry is in the 1st row.

\sphinxAtStartPar
\sphinxstylestrong{Step 2} Multiply the 1st row by a nonzero number so that its first nonzero entry is equal to 1.

\sphinxAtStartPar
\sphinxstylestrong{Step 3} Replace all lower rows with multiples of the first row so all entries below this 1 are 0.

\sphinxAtStartPar
\sphinxstylestrong{Step 4} Repeat Steps 1\sphinxhyphen{}3 for row 2, row 3 and so on.

\sphinxAtStartPar
The matrix is now in row echelon form. To convert it to reduced row echelon form:

\sphinxAtStartPar
\sphinxstylestrong{Step 5} Replace all rows above with multiples of the final pivot row to clear all entries above the pivot.

\sphinxAtStartPar
\sphinxstylestrong{Step 6} Repeat step 5 for each of the other pivot rows, working from bottom to top.
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example: Gaussian Elimination}

\sphinxAtStartPar
Use Gaussian elimination to reduce the following matrix to reduced row echelon form:
\begin{equation*}
\begin{split}
\begin{pmatrix}
-2 & -4 & -2 & -10 & 0\\
2 & 4 & 1 & 9 & -2\\
3 & 6 & 1 & 13 & -4
\end{pmatrix}
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Solution}

\sphinxAtStartPar
First get a 1 pivot in the first row and zeros below in the same column:
\begin{equation*}
\begin{split}
\begin{array}{rc}
\begin{array}{ccr}
 & & (r_1)\\
 & & (r_2)\\
& & (r_3)
\end{array}
&
\begin{pmatrix}
-2 & -4 & -2 & -10 & 0\\
2 & 4 & 1 & 9 & -2\\
3 & 6 & 1 & 13 & -4
\end{pmatrix}\\
\begin{array}{ccr}
 -\frac{1}{2}r_1 & \longrightarrow & (r_1)\\
 & & (r_2)\\
& & (r_3)
\end{array}
&
\begin{pmatrix}
1 & 2 & 1 & 5 & 0\\
2 & 4 & 1 & 9 & -2\\
3 & 6 & 1 & 13 & -4
\end{pmatrix}\\
\begin{array}{ccr}
 & & (r_1)\\
 r_2 - 2r_1 & \longrightarrow & (r_2)\\
 r_3 - 3r_1& \longrightarrow & (r_3)
\end{array}
&
\begin{pmatrix}
\boxed{1} & 2 & 1 & 5 & 0\\
0 & 0 & -1 & -1 & -2\\
0 & 0 & -2 & -2 & -4
\end{pmatrix}
\end{array}
\end{split}
\end{equation*}
\sphinxAtStartPar
We have zeros in the second column so the next pivot will be in column 3:
\begin{equation*}
\begin{split}
\begin{array}{rc}
\begin{array}{ccr}
 & & (r_1)\\
 -r_2 & \longrightarrow & (r_2)\\
 & & (r_3)
\end{array}
&
\begin{pmatrix}
\boxed{1} & 2 & 1 & 5 & 0\\
0 & 0 & 1 & 1 & 2\\
0 & 0 & -2 & -2 & -4
\end{pmatrix}\\
\begin{array}{ccr}
 & & (r_1)\\
 & & (r_2)\\
 r_3 + 2r_2 & \longrightarrow & (r_3)
\end{array}
&
\begin{pmatrix}
\boxed{1} & 2 & 1 & 5 & 0\\
0 & 0 & \boxed{1} & 1 & 2\\
0 & 0 & 0 & 0 & 0
\end{pmatrix}
\end{array}
\end{split}
\end{equation*}
\sphinxAtStartPar
The matrix is now in echelon form. To achieve reduced row echelon form, we eliminate the values above the pivots:
\begin{equation*}
\begin{split}
\begin{array}{rc}
\begin{array}{ccr}
 r_1 - r_2 & \longrightarrow & (r_1)\\
 & & (r_2)\\
 & & (r_3)
\end{array}
&
\begin{pmatrix}
\boxed{1} & 2 & 0 & 4 & -2\\
0 & 0 & \boxed{1} & 1 & 2\\
0 & 0 & 0 & 0 & 0
\end{pmatrix}\\
\end{array}
\end{split}
\end{equation*}\end{sphinxadmonition}
\phantomsection \label{exercise:q_echelon_form_2}

\begin{sphinxadmonition}{note}{Exercise 11.3}





\sphinxAtStartPar
Use Gaussian elimination to reduce the following matrix to row echelon form and reduced row echelon form:
\begin{equation*}
\begin{split}
\begin{pmatrix}
0 & 3 & -6 & 6 & 4 & -5\\
3 & -7 & 8 & -5 & 8 & 9\\
3 & -9 & 12 & -9 & 6 & 15
\end{pmatrix}\end{split}
\end{equation*}\end{sphinxadmonition}


\section{Parametric Solutions to a Linear System}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/echelon_form:parametric-solutions-to-a-linear-system}}
\sphinxAtStartPar
The reduced row echelon form of the augmented matrix allows us to determine the solutions to the system. There are three cases:

\sphinxAtStartPar
1. \sphinxstylestrong{Every column except the last column is a pivot column}. In this case, the system of equations is consistent and there is a single unique solution. For example,
\begin{equation*}
\begin{split}
\left(\begin{array}{ccc|c}
\boxed{1} & 0 & 0 & 5\\
0 & \boxed{1} & 0 & 2\\
0 & 0 & \boxed{1} & -1
\end{array}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
has the solution \(\pmatrix{x_1\\x_2\\x_3} = \pmatrix{5\\2\\-1}\).

\sphinxAtStartPar
2. \sphinxstylestrong{The last column is a pivot column}. In this case the system is inconsistent and there are no solutions. For example,
\begin{equation*}
\begin{split}
\left(\begin{array}{cc|c}
\boxed{1} & 0 & 0\\
0 & \boxed{1} & 0\\
0 & 0 & \boxed{1}
\end{array}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
is equivalent to \(\pmatrix{x_1\\x_2\\0} = \pmatrix{0\\0\\1}\) which is inconsistent. There are no values of \(x_1, x_2\) and \(x_3\) which solve this system.

\sphinxAtStartPar
3. \sphinxstylestrong{The last column is not a pivot column, and some other column is also not a pivot column}. In this case, there are infinitely many solutions. For example,
\begin{equation*}
\begin{split}
\left(\begin{array}{cccc|c}
\boxed{1} & 2 & 0 & 3 & 1\\
0 & 0 & \boxed{1} & -2 & -2
\end{array}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
has infinitely many solutions since columns 2 and 4 are non\sphinxhyphen{}pivot columns. The variables corresponding to a non\sphinxhyphen{}pivot column of the matrix are termed \sphinxstylestrong{free variables}. In the next section will explore how these solutions can be determined.


\subsection{General Solution Set}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/echelon_form:general-solution-set}}
\sphinxAtStartPar
The following system of equations,
\begin{equation*}
\begin{split}
\begin{alignat*}{4}
x_1 & {}+{} & 2x_2 & {}+{} & 9x_3 & {}={} & -1\\
2x_1 & {}+{} & x_2 & {}+{} & 12x_3 &  {}={} & 1
\end{alignat*}\end{split}
\end{equation*}
\sphinxAtStartPar
is represented by the following augmented matrix,
\begin{equation*}
\begin{split}
\left(\begin{array}{ccc|c}
1 & 2 & 9 & -1\\
2 & 1 & 12 & 1
\end{array}
\right)
\end{split}
\end{equation*}
\sphinxAtStartPar
which through Gaussian elimination may be reduced to the following echelon form,
\begin{equation*}
\begin{split}
\left(\begin{array}{ccc|c}
1 & 0 & 5 & 1\\
0 & 1 & 2 & -1
\end{array}
\right)
\end{split}
\end{equation*}
\sphinxAtStartPar
corresponding to the following pair of equations:
\begin{equation*}
\begin{split}
\begin{alignat*}{3}
x_1 & {}+{} & 5x_3 & {}={} & 1\\
x_2 & {}+{} & 2x_3 &  {}={} & -1&.
\end{alignat*}\end{split}
\end{equation*}
\sphinxAtStartPar
Rearranging slightly,
\begin{equation*}
\begin{split}
\begin{alignat*}{3}
x_1 & {}={} & 1 & {}-{} & 5x_3\\
x_2 & {}={} & -1 & {}-{} & 2x_3 &.
\end{alignat*}\end{split}
\end{equation*}
\sphinxAtStartPar
For any value of \(x_3\), there is exactly one value of \(x_1\) and \(x_2\) that satisfy the equations. But we are free to choose \sphinxstyleemphasis{any} value of \(x_3\), and so we have found all the solutions: the set of all values \(x_1, x_2, x_3\) where
\begin{equation*}
\begin{split}
\begin{alignat*}{3}
x_1 & {}={} & 1 & {}-{} & 5t\\
x_2 & {}={} & -1 & {}-{} & 2t\\
x_3 & {}={} &  &  & t
\end{alignat*}\end{split}
\end{equation*}
\sphinxAtStartPar
for any \(t \in \mathbb{R}\).

\sphinxAtStartPar
This is the \sphinxstylestrong{general solution in parametric form} of the system of equations, and \(x_3\) is a \sphinxstylestrong{free variable}.

\sphinxAtStartPar
In a later section we will see how to write this in vector form as follows:
\begin{equation*}
\begin{split}
\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix} = t\begin{pmatrix}-5\\-2\\1\end{pmatrix} + \begin{pmatrix}1\\-1\\0\end{pmatrix}.
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{The solution set is a straight line}.

\begin{sphinxadmonition}{note}{Parametric solution to system of linear equations}

\sphinxAtStartPar
Suppose we have a linear system of \(m\) equations in \(n\) unknowns. Determine the \sphinxstylestrong{parameteric form} of the solution set as follows:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Write the system of as an augmented matrix.

\item {} 
\sphinxAtStartPar
Use Gaussian elimination to reduce to reduced row echelon form.

\item {} 
\sphinxAtStartPar
Write the corresponding system of linear equations.

\item {} 
\sphinxAtStartPar
Move all free variables to the right hand side.

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Write the solution to the system represented by the following augmented matrix in parametric form.
\begin{equation*}
\begin{split}\left(\begin{array}{cccc|c}
\boxed{1} & 2 & 0 & 3 & 1\\
0 & 0 & \boxed{1} & -2 & -2
\end{array}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Solution}

\sphinxAtStartPar
The matrix is already in reduced row echelon form. The pivot variables are \(x_1\) and \(x_3\); the free variables are \(x_2\) and \(x_4\). It corresponds to the following equations:
\begin{equation*}
\begin{split}\begin{alignat*}{4}
x_1 & {}+{} & 2x_2 & \quad &      & {}+{} & 3x_4 & {}={} & 1\\
    &       &      & \quad & x_3 & {}-{} & 2x_4 & {}={} & -2.
\end{alignat*}
\end{split}
\end{equation*}
\sphinxAtStartPar
Move the free variables to the right hand side to give the parametric solution:
\begin{equation*}
\begin{split}\begin{alignat*}{5}
x_1 & {}={} & -2x_2 & {}-{} & 3x_4 & {}+{} & 1\\
x_3 & {}={} &       & {}-{} & 2x_4 & {}-{} & 2
\end{alignat*}
\end{split}
\end{equation*}
\sphinxAtStartPar
for any \(x_2, x_4 \in \mathbb{R}\).

\sphinxAtStartPar
This is the equation of a (2d) plane.
\end{sphinxadmonition}
\phantomsection \label{exercise:q_parametric_form}

\begin{sphinxadmonition}{note}{Exercise 11.4}



\sphinxAtStartPar
The reduced row echelon form of the matrix for a linear system in four variables \(x_1, x_2, x_3, x_4\) is
\begin{equation*}
\begin{split}\left(\begin{array}{cccc|c}1 & 0 & 0 & 3 & 2\\
0 & 0 & 1 & 4 & -1\end{array}\right).\end{split}
\end{equation*}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Identify the pivot variables and free variables.

\item {} 
\sphinxAtStartPar
Write the solution to the system in parametric form.

\end{enumerate}
\end{sphinxadmonition}


\section{Solutions}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/echelon_form:solutions}}\phantomsection \label{LinearAlgebra/linear_systems_matrices/echelon_form:LinearAlgebra/linear_systems_matrices/echelon_form-solution-4}

\begin{sphinxadmonition}{note}{Solution to Exercise 11.1}



\sphinxAtStartPar
\sphinxstylestrong{Gaussian elimination}
\begin{equation*}
\begin{split}
\begin{array}{rc}
\begin{array}{r}
 (r_1)\\
 (r_2)\\
 (r_3)
\end{array}
&
\left(
\begin{array}{ccc|c}
1 & -2 & 1 & 0 \\
2 & 1 & -3 & 5 \\
4 & -7 & 1 & -1
\end{array}
\right)\\ \\
\begin{array}{ccr}
 & & (r_1)\\
r_2-2r_1 & \longrightarrow & (r_2) \\
r_3-4r_1 & \longrightarrow & (r_3)
\end{array}
&
\left(
\begin{array}{ccc|c}
1 & -2 & 1 & 0 \\
0 & 5 & -5 & 5 \\
0 & 1 & -3 & -1
\end{array}
\right) \\ \\
\begin{array}{ccr}
 & & (r_1)\\
& & (r_2) \\
r_3-\frac{1}{5}r_2 & \longrightarrow & (r_3)
\end{array}
&
\left(
\begin{array}{ccc|c}
1 & -2 & 1 & 0 \\
0 & 5 & -5 & 5 \\
0 & 0 & -2 & -2
\end{array}
\right)
\end{array}
\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Back\sphinxhyphen{}substitution}
\begin{align*}
-2z = -2 &\Rightarrow z = 1.\\
5y - 5z = 5 &\Rightarrow y = 1 + z = 2.\\
x - 2y + z = 0 &\Rightarrow x = 2y-z = 3.
\end{align*}
\sphinxAtStartPar
The solution is \(\begin{pmatrix}x\\y\\z\end{pmatrix} = \begin{pmatrix}3\\2\\1\end{pmatrix}\).
\end{sphinxadmonition}
\phantomsection \label{LinearAlgebra/linear_systems_matrices/echelon_form:LinearAlgebra/linear_systems_matrices/echelon_form-solution-5}

\begin{sphinxadmonition}{note}{Solution to Exercise 11.2}



\sphinxAtStartPar
1, 4, 5, 6 are in row echelon form.

\sphinxAtStartPar
1, 5 are in reduced row echelon form.
\end{sphinxadmonition}
\phantomsection \label{LinearAlgebra/linear_systems_matrices/echelon_form:LinearAlgebra/linear_systems_matrices/echelon_form-solution-6}

\begin{sphinxadmonition}{note}{Solution to Exercise 11.3}



\sphinxAtStartPar
Row echelon form:
\begin{equation*}
\begin{split}
\begin{pmatrix}
3 & -9 & 12  & -9 & 6 & 15\\
0 & 1 & -2 & 2 & 1 & -3\\
0 & 0 & 0 & 0 & 1 & 4
\end{pmatrix}
\end{split}
\end{equation*}
\sphinxAtStartPar
Reduced row echelon form:
\begin{equation*}
\begin{split}
\begin{pmatrix}
1 & 0 & -2  & 3 & 0 & -24\\
0 & 1 & -2 & 2 & 0 & -7\\
0 & 0 & 0 & 0 & 1 & 4
\end{pmatrix}
\end{split}
\end{equation*}\end{sphinxadmonition}
\phantomsection \label{LinearAlgebra/linear_systems_matrices/echelon_form:LinearAlgebra/linear_systems_matrices/echelon_form-solution-7}

\begin{sphinxadmonition}{note}{Solution to Exercise 11.4}



\sphinxAtStartPar
1. The pivots are \(x_1, x_3\); the free variables are \(x_2, x_4\).

\sphinxAtStartPar
2. Write the system of equations:
\begin{equation*}
\begin{split}
\begin{alignat*}{4}
x_1 & \quad &     & {}+{} & 3x_4 & {}={} & 2\\
    &       & x_3 & {}+{} & 4x_4 & {}={} & -1
\end{alignat*}.
\end{split}
\end{equation*}
\sphinxAtStartPar
In parametric form:
\begin{equation*}
\begin{split}
\begin{alignat*}{3}
x_1 & {}={} & 2 & {}-{} & 3x_4\\
x_3 & {}={} & -1 & {}-{} & 4x_4
\end{alignat*}.
\end{split}
\end{equation*}
\sphinxAtStartPar
What happened to \(x_2\)? It is a free variable, but no other variable depends on it. The general solution is:
\begin{equation*}
\begin{split}
\begin{pmatrix}
x_1\\x_2\\x_3\\x_4
\end{pmatrix}
=
\begin{pmatrix}
2-3x_4\\x_2\\-1-4x_4\\x_4
\end{pmatrix}
\end{split}
\end{equation*}
\sphinxAtStartPar
for any values of \(x_2\) and \(x_4\).
\end{sphinxadmonition}


\chapter{Matrices}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices:matrices}}\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices::doc}}

\section{Matrix Definitions}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices:matrix-definitions}}
\sphinxAtStartPar
A matrix (plural: matrices) is essentially just an array of values, arranged in rows and columns. For example, when we were solving systems of linear equations by Gaussian elimination, we formed the \sphinxstylestrong{augmented matrix} of coefficients:
\begin{equation*}
\begin{split}
\left(
\begin{array}{cccc|c}
    a_{1,1} & a_{1,2} & \cdots & a_{1,n} &  b_1 \\
    a_{2,1} & a_{2,2} & \cdots & a_{2,n} &  b_2 \\
    \vdots & \vdots & \ddots & \vdots & \vdots \\
    a_{m,1} & a_{m,2} & \cdots & a_{m,n} & b_m
\end{array}
\right)
\end{split}
\end{equation*}
\sphinxAtStartPar
The vertical line was used to indicate that the matrix is partitioned into two sub\sphinxhyphen{}matrices, representing the coefficients and constant terms, respectively.

\sphinxAtStartPar
In general, the values contained in a matrix could represent anything, although manipulating systems of linear equations is one of the most valuable uses of matrices.

\sphinxAtStartPar
The Gaussian elimination technique that we have looked at is a brute force method for solving a given set of equations, whilst matrix methods are more concerned with finding general solutions and simplifications of certain types of problems.


\subsection{Notation}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices:notation}}
\sphinxAtStartPar
Two example matrices are given below
\begin{equation}\label{equation:LinearAlgebra/linear_systems_matrices/matrices:square_matrix}
\begin{split}\left( \begin{matrix} 1 & -3 \\ 2 & -1 \end{matrix} \right) \qquad \left[ \begin{matrix} 1 & -3 \\ 2 & -1 \end{matrix} \right]\end{split}
\end{equation}
\sphinxAtStartPar
It is important that you do not use commas to separate the elements, which is incorrect notation.

\sphinxAtStartPar
Either square or round brackets can be used to denote a matrix \sphinxhyphen{} but you should avoid mixing notation. Other types of brackets cannot be used, so none of the expressions below are matrices. In fact, the third expression has a special meaning, as we will see later.
\label{equation:LinearAlgebra/linear_systems_matrices/matrices:1d40cf03-f440-4674-98f0-3fc7a6847240}\begin{align}\begin{matrix} 1 & -3 \\ 2 & -1 \end{matrix} \qquad \left\{ \begin{matrix} 1 & -3 \\ 2 & -1 \end{matrix} \right\} \qquad \left| \begin{matrix} 1 & -3 \\ 2 & -1 \end{matrix} \right|	\end{align}

\subsection{Terminology}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices:terminology}}
\sphinxAtStartPar
The matrix featured in \eqref{equation:LinearAlgebra/linear_systems_matrices/matrices:square_matrix} is referred to as a square matrix because it has the same number of rows and columns. We also can say that it is a (2x2) matrix, because it has two rows and two columns.

\sphinxAtStartPar
The number of rows must be given first:

\sphinxAtStartPar
\( \left( \begin{matrix} 1 & -3 & 5\\ 2 & -1 & 7\end{matrix} \right) \)  is a (2 x 3) matrix, \( \left( \begin{matrix} 1 & -3 \\ 2 & -1 \\ 5 & 7\end{matrix} \right) \) is a (3 x 2) matrix.

\sphinxAtStartPar
This measurement is properly referred to as the \sphinxstylestrong{order} of a matrix, but is also often referred to as the \sphinxstylestrong{size}.

\sphinxAtStartPar
The individual values in a matrix are called \sphinxstylestrong{elements}, so in the matrix \( M = \left( \begin{matrix} 1 &2 &3 \\ 4& 5& 6\end{matrix} \right) \) we can say that the element in the \(2^{nd}\) row and \(3^{rd}\) column is the number 6. Subscripts can be used to refer to the elements, by writing \( M_{2,3} = 6\) for example.

\sphinxAtStartPar
The \sphinxstylestrong{transpose} of a matrix, written with a superscript letter T, means that we swap the rows and columns, as in the example given below:

\sphinxAtStartPar
\( M = \left( \begin{matrix} 1 &2 &3 \\ 4& 5& 6\end{matrix} \right) \Rightarrow M^T = \left( \begin{matrix} 1 & 4 \\ 2 & 5  \\ 3 & 6\end{matrix} \right)\)

\sphinxAtStartPar
In element notation, for any matrix \(X\), we can write that \(\left(X^T\right)_{i,j} = X_{j,i}\).

\sphinxAtStartPar
That is, the element in the \(i^{th}\) row and \(j^{th}\) column of \(X\) becomes the element in the \(j^{th}\) row and \(i^{th}\) column of \(X^T\).

\sphinxAtStartPar
The order of a matrix is reversed when it it transposed.

\sphinxAtStartPar
In a square matrix, two diagonals are called the \sphinxstylestrong{main diagonal} (top\sphinxhyphen{}left two bottom right), and the \sphinxstylestrong{anti\sphinxhyphen{}diagonal} (bottom\sphinxhyphen{}left to top\sphinxhyphen{}right). Square matrices for which \(A_{i,j}=A_{j,i}\) are called \sphinxstylestrong{symmetric matrices}.

\sphinxAtStartPar
An \sphinxstylestrong{upper\sphinxhyphen{}triangular matrix} is a square matrix in which the elements below the main diagonal are all zero, and a \sphinxstylestrong{lower\sphinxhyphen{}triangular matrix} is one where the elements above the main diagonal are all zero.

\sphinxAtStartPar
A \sphinxstylestrong{diagonal matrix} is one in which all of the elements are zero apart from those on the main diagonal. These type of matrices are very special, since they have “nice” properties for the purpose of matrix algebra.
\phantomsection \label{exercise:q_matrix_definitions}

\begin{sphinxadmonition}{note}{Exercise 12.1}



\sphinxAtStartPar
1. What is the order of each of the matrices shown?

\sphinxAtStartPar
\(A=\left(\begin{array}{cc}0 & -1 \\2 & 3 \\-1 & 0 \\\end{array}\right)\),   \(b=\left(\begin{array}{c}1 \\2 \\3 \\\end{array}\right)\),   \(c=0\).

\sphinxAtStartPar
2. Given the matrix \(X=\left(\begin{array}{ccc}-3 & 4 & 0 \\1 & 1 & 2 \\7 & -4 & 3 \\\end{array}\right)\), what element is represented by \((X^T)_{2,3}\) ?

\sphinxAtStartPar
3. Which of the following matrices is an upper\sphinxhyphen{}triangular matrix?

\sphinxAtStartPar
\(A=\left(\begin{array}{cccc}2&8&-1&0\\0&2&2&2\\0&0&1&-5\\0&0&0&3\end{array}\right)\), \(B=\left(\begin{array}{cccc}1&-2&5&2\\3&6&-2&0\\8&2&0&0\\-2&0&0&0\end{array}\right)\), \(C=\left(\begin{array}{ccc}6&0&0\\-3&-4&0\\2&7&7\end{array}\right)\).
\end{sphinxadmonition}


\section{Matrix algebra}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices:matrix-algebra}}
\sphinxAtStartPar
We will look at how real number algebra, such as addition and multiplication, can be extended to work with matrices. These are entirely human constructs, and you may be easily forgiven for asking why do we do it this way?

\sphinxAtStartPar
However, the best way to appreciate the practicalities is by tackling some problems, and so the definitions will first be introduced without much explanation. From a mathematical perspective, we simply note that the definitions must be consistent and well\sphinxhyphen{}determined (unambiguous).


\subsection{Multiplication by a scalar}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices:multiplication-by-a-scalar}}
\sphinxAtStartPar
Let \(\lambda\) be a scalar (a single number) and \(M\) be a matrix. Then \(\lambda M\) means that every element in matrix \(M\) is multiplied by \(\lambda\). This can be written in element notation as follows:
\begin{equation*}
\begin{split} (\lambda M)_{i,j} = \lambda M_{i,j}\end{split}
\end{equation*}
\sphinxAtStartPar
For example, \( -3\left( \begin{matrix} 0 & -2 \\ 1 & 5 \\ -1 & 3 \end{matrix} \right) = \left( \begin{matrix} 0 & 6 \\ -3 & -15 \\ 3 & -9 \end{matrix} \right) \).


\subsection{Addition}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices:addition}}
\sphinxAtStartPar
Let \(A\) and \(B\) be two matrices of the same order. Then,
\begin{equation*}
\begin{split}\left(A + B\right)_{i,j} = A_{i,j} + B_{i,j}\end{split}
\end{equation*}
\sphinxAtStartPar
The expression states that to add two matrices, we add together the corresponding elements. This type of operation on two matrices can be referred to as an element\sphinxhyphen{}wise operation.

\sphinxAtStartPar
For example, \( \left( \begin{matrix} 1 & -3 \\ 3 & 0 \\ 5 & -7 \end{matrix} \right) + \left( \begin{matrix} 0 & 6 \\ -3 & -15 \\ 3 & -9 \end{matrix} \right) = \left( \begin{matrix} 1 & 3 \\ 0 & -15 \\ 8 & -16 \end{matrix} \right) \).

\sphinxAtStartPar
The element\sphinxhyphen{}wise property means that only matrices of the same order can be added, and the expressions below are both meaningless:
\begin{equation*}
\begin{split} \left( \begin{matrix} 1 & 2 \end{matrix} \right) + \left( \begin{matrix} 1 & 2 \\ 3 & 4 \end{matrix} \right) \end{split}
\end{equation*}\begin{equation*}
\begin{split}\left( \begin{matrix} 1 & 2 \\ 3 & 4 \end{matrix} \right) + 1 \end{split}
\end{equation*}
\sphinxAtStartPar
Matrix addition can be combined with multiplication by a scalar to add multiples of one matrix to another.

\sphinxAtStartPar
For example, \( \left( \begin{matrix} 1 & -3 \\ 3 & 0 \\ 5 & -7 \end{matrix} \right) - 3\left( \begin{matrix} 0 & -2 \\ 1 & 5 \\ -1 & 3 \end{matrix} \right) = \left( \begin{matrix} 1 & 3 \\ 0 & -15 \\ 8 & -16 \end{matrix} \right) \).
\phantomsection \label{exercise:q_matrix_arithmetic}

\begin{sphinxadmonition}{note}{Exercise 12.2}



\sphinxAtStartPar
Given the matrices \(A=\left(\begin{array}{cc}1 & 2 \\-1 & 0 \\3 & 1 \\\end{array}\right)\), \(B=\left(\begin{array}{cc}-4 & 1 \\1 & 2 \\-2 & 3 \\\end{array}\right)\), \(C=\left(\begin{array}{cc}0 & 3 \\4 & 2 \\1 & 1 \\\end{array}\right)\), \(D=\left(\begin{array}{cc}5 & 1 \\3 & 2 \\\end{array}\right)\), what will be the result of the following expressions?
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
\(\left(A+B\right)+C\)

\item {} 
\sphinxAtStartPar
\((C+B)+A\)

\item {} 
\sphinxAtStartPar
\(A-2B+\frac{1}{2}C\)

\item {} 
\sphinxAtStartPar
\(A+D\)

\end{enumerate}
\end{sphinxadmonition}


\subsection{Matrix multiplication}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices:matrix-multiplication}}
\sphinxAtStartPar
To multiply two matrices together, their inner dimensions must be the same. That is, to calculate \( \boldsymbol{A}\boldsymbol{B} \), the number of columns in \(\boldsymbol{A}\) must be the same as the number of rows in \(\boldsymbol{B}\). The order of the product matrix is given by the outer dimensions of the two matrices. We can represent this result visually:

\sphinxAtStartPar
\sphinxincludegraphics{{MatrixDimensions}.png}

\begin{sphinxadmonition}{note}{Matrix Multiplication}

\sphinxAtStartPar
Given a \((p × r)\) matrix \(\boldsymbol{A}\) and a \((r × q)\) matrix \(\boldsymbol{B}\), the matrix product \(\boldsymbol{A\,B}\) defines a \((p × q)\) matrix, whose elements are given by
\begin{equation*}
\begin{split} \left(A B\right)_{i,j} = \sum_k  A_{i,k} B_{k,j} \end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
To perform matrix multiplication, we must take elements in a row on the left hand side matrix and multiply with elements in a column on the right hand side matrix. The process is illustrate graphically here for a (2 x 2 ) example:

\sphinxAtStartPar
\sphinxincludegraphics{{MatrixMultiplicationExpanded}.png}
\phantomsection \label{exercise:q_matrix_multiplication}

\begin{sphinxadmonition}{note}{Exercise 12.3}



\sphinxAtStartPar
Given that

\sphinxAtStartPar
\(A=\left(\begin{array}{ccc}3 & 1 & -2 \\0 & 2 & 4 \\\end{array}\right)\),   \(B=\left(\begin{array}{cc}2 & 3 \\-3 & 0 \\1 & 1 \\\end{array}\right)\),   \(C=\left(\begin{array}{cccc}1 & -8 & 2 & 11 \\0 & 4 & -3 & -7 \\6 & 1 & 8 & 1 \\\end{array}\right)\),    \(D=\left(\begin{array}{ccc}1 & 2 & 3 \\1 & 1 & 1 \\2 & 0 & 1 \end{array}\right)\),
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Calculate \(AB\) and \(BA\). Are these results the same?

\item {} 
\sphinxAtStartPar
Explain why the result \(A\left(\begin{array}{c}1\\2\end{array}\right)\) cannot be calculated.

\item {} 
\sphinxAtStartPar
What will be the order of the matrix \(A C\)?

\item {} 
\sphinxAtStartPar
Calculate the element in the second row and third column of \(AC\)

\item {} 
\sphinxAtStartPar
Calculate the result \(D^2\) (this question is a bit boring, but good practice!)

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example: Walk Lengths}

\sphinxAtStartPar
Consider the connected graph below, in which the vertices have been numbered 1\sphinxhyphen{}4:

\sphinxAtStartPar
\sphinxincludegraphics{{network1}.png}

\sphinxAtStartPar
The graph can be represented by an adjacency matrix \(A\) in which element \(A_{i,j}\) is either 1 or 0 identifying if  vertex \(i\) is or is not connected to vertex \(j\). For this graph we have:
\begin{equation*}
\begin{split}A=\left(\begin{array}{cccc}0 & 1 & 1 & 0 \\1 & 0 & 1 & 1 \\1 & 1 & 0 & 1 \\0 & 1 & 1 & 0 \\\end{array}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
It can be proved by induction that the result \(S^N\) tells us how many \(N\)\sphinxhyphen{}step paths there are between each pair of vertices (see inductive step outline below). Therefore, if we want the number of 3\sphinxhyphen{}step paths between each pair of vertices, we can compute
\begin{equation*}
\begin{split}M^3=\left(\begin{array}{cccc}2 & 5 & 5 & 2 \\5 & 4 & 5 & 5 \\5 & 5 & 4 & 5 \\2 & 5 & 5 & 2 \\\end{array}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
For instance, there are 5 walks of length 3 between vertices 1 and 2. Can you find them all?

\sphinxAtStartPar
\sphinxstylestrong{Inductive step outline:}

\sphinxAtStartPar
If \(S^{N-1}\) gives all walks of length \(N-1\) between pairs of vertices, then the following result gives the number of paths starting at node \(i\) and ending at vertex \(j\), obtained by taking one extra step from each connected vertex:
\begin{equation*}
\begin{split}S^N_{i,j}=S^{N-1}_{i,1}S_{1,j}+S^{N-1}_{i,2}S_{2,j}+S^{N-1}_{i,3}S_{3,j}+S^{N-1}_{i,4}S_{4,j}\end{split}
\end{equation*}\end{sphinxadmonition}


\subsection{Properties of Matrix Multiplication}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices:properties-of-matrix-multiplication}}
\sphinxAtStartPar
Matrix multiplication is \sphinxstylestrong{associative}, that is
\begin{equation*}
\begin{split}A (B C)\equiv (A B)C\end{split}
\end{equation*}
\sphinxAtStartPar
This can be proved by showing that the left and right hand sides are the same order, and that \((A(B C))_{i,j}=((A B)C)_{i,j}\).

\sphinxAtStartPar
Matrix multiplication is \sphinxstylestrong{NOT commutative}, that is
\begin{equation*}
\begin{split}\begin{array}{c}A B\neq B A \end{array}\end{split}
\end{equation*}
\sphinxAtStartPar
(although the  \(AB\) and \(BA\) may be equal in some special cases).

\begin{sphinxadmonition}{warning}{Warning:}
\sphinxAtStartPar
For two matrices \(A\) and \(B\), in general \(AB \neq BA\).

\sphinxAtStartPar
Forgetting the matrix multiplication is non\sphinxhyphen{}commutative leads to disaster!
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
\sphinxstylestrong{Worked example illustrating non\sphinxhyphen{}commutative property}
\begin{equation*}
\begin{split}\left(\begin{array}{cc}1 & 2 \\-3 & 0 \end{array}\right) \left(\begin{array}{cc}2 & 1 \\1 & 2 \\\end{array}\right)=\left(\begin{array}{cc}1\ 2+2\ 1 & 1\ 1+2\ 2 \\0\ 1-3\ 2 & 0\ 2-3\ 1\end{array}\right)=\left(\begin{array}{cc}4 & 5 \\-6 & -3 \\\end{array}\right)\end{split}
\end{equation*}\begin{equation*}
\begin{split}\left(\begin{array}{cc}2 & 1 \\1 & 2 \\\end{array}\right) \left(\begin{array}{cc}1 & 2 \\-3 & 0 \end{array}\right)=\left(\begin{array}{cc}2\ 1+1 (-3) & 2\ 2+1\ 0 \\1\ 1+2 (-3) & 1\ 2+2\ 0 \end{array}\right)=\left(\begin{array}{cc}-1 & 4 \\-5 & 2 \\\end{array}\right)\end{split}
\end{equation*}\end{sphinxadmonition}


\section{Matrix equations}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices:matrix-equations}}
\sphinxAtStartPar
In this section we make the connection between matrices and linear systems of equations. Our aim is to find the general solution to the equation
\begin{equation*}
\begin{split}Ax = b\end{split}
\end{equation*}
\sphinxAtStartPar
where \(A\) is an \((m \times n)\) matrix and \(b \in \mathbb{R}^m\) and \(x \in \mathbb{R}^n\) are vectors.

\sphinxAtStartPar
Such an equation is exactly equivalent to a linear system of \(m\) equations in \(n\) unknowns. For example, we can write the system
\begin{alignat*}{4}
2x_1 & {}+{} & 3x_2 & {}-{} & 2x_3 & {}={} & 7 \\
  x_1 & {}-{} & x_2 & {}-{} & 3x_3 & {}={} & 5
\end{alignat*}
\sphinxAtStartPar
as the matrix equation
\begin{equation*}
\begin{split}
\begin{pmatrix} 2 & 3 & -2\\
1 & -1 & -3\end{pmatrix}\begin{pmatrix}x_1\\x_2\\x_3\end{pmatrix} = \begin{pmatrix}7\\5\end{pmatrix}.
\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{Matrix Equation}

\sphinxAtStartPar
The linear system of equations
\begin{align*}
a_{1,1} x_1 + a_{1,2} x_2 + a_{1,3} x_3 + \dots + a_{1,n} x_n &= b_1 \\

   a_{2,1} x_1 + a_{2,2} x_2 + a_{2,3} x_3 + \dots + a_{2,n} x_n &= b_2\\
                                                                     \vdots \\
 a_{m,1} x_1 + a_{m,2} x_2 + a_{m,3} x_3 + \dots + a_{m,n} x_n &= b_m
\end{align*}
\sphinxAtStartPar
is equivalent to the matrix equation
\begin{equation*}
\begin{split}Ax=b\end{split}
\end{equation*}
\sphinxAtStartPar
where \(A=\begin{pmatrix}
a_{1,1} & \cdots & a_{1,n}\\
\vdots & \ddots & \vdots\\
a_{m,1} & \cdots & a_{m,n}
\end{pmatrix}\), \(x=\begin{pmatrix}x_1\\ \vdots \\ x_n\end{pmatrix}\) and \(b=\begin{pmatrix}b_1\\ \vdots \\b_m\end{pmatrix}\).
\end{sphinxadmonition}

\sphinxAtStartPar
This equivalence means that we can move freely between these two ways of writing and thinking about a linear system.


\subsection{Solving \protect\(Ax = 0\protect\)}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices:solving-ax-0}}
\sphinxAtStartPar
The equation \(Ax=0\) has special significance and is easier to solve than the general equation \(Ax = b\).

\begin{sphinxadmonition}{note}{Definition}

\sphinxAtStartPar
An equation of the form \(Ax = 0\) is \sphinxstylestrong{homogeneous}.

\sphinxAtStartPar
An equation of the form \(Ax = b\) with \(b \neq 0\) is \sphinxstylestrong{inhomogeneous}.
\end{sphinxadmonition}

\sphinxAtStartPar
For example, given the homogeneous equation \(Ax=0\), where
\begin{equation*}
\begin{split}A=
\begin{pmatrix}
1 & 3 & 4\\
2 & -1 & 2\\
1 & 0 & 1\\
\end{pmatrix}
\end{split}
\end{equation*}
\sphinxAtStartPar
we can use row operations to reduce the augmented matrix
\begin{equation*}
\begin{split}
\left(
\begin{array}{ccc|c}
1 & 3 & 4 & 0\\
2 & -1 & 2 & 0\\
1 & 0 & 1 & 0
\end{array}
\right)
\end{split}
\end{equation*}
\sphinxAtStartPar
to reduced row echelon form:
\begin{equation*}
\begin{split}
\left(
\begin{array}{ccc|c}
1 & 0 & 0 & 0\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 0
\end{array}
\right)
\end{split}
\end{equation*}
\sphinxAtStartPar
which has only the trivial solution \(x=0\).

\sphinxAtStartPar
Note that the augmented part of the matrix is redundant since the zeros are not affected by the row operations. \sphinxstylestrong{It is not necessary to write an augmented matrix when solving homogeneous systems}.

\begin{sphinxadmonition}{note}{Null space and special solutions}

\sphinxAtStartPar
The \sphinxstylestrong{null space} of a matrix \(A\) is the full solution to the equation
\begin{equation*}
\begin{split}Ax=0.\end{split}
\end{equation*}
\sphinxAtStartPar
For each free variable \(x_i\) in the echelon form of \(A\) there is a \sphinxstylestrong{special solution} \(v_i\) found by setting \(x_i\) to \(1\) and all other free variables to \(0\).

\sphinxAtStartPar
The null space is all linear combinations of the special solutions:
\begin{equation*}
\begin{split}t_1v_1 + \cdots + t_kv_k\quad \mathrm{for}\quad t_i\in\mathbb{R}.\end{split}
\end{equation*}\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Solve the homogeneous equation \(Ax=0\) where
\begin{equation*}
\begin{split}A = \begin{pmatrix}1 & 0 & -8 & -7\\
0 & 1 & 4 & 3\\
 0 & 0 & 0 & 0\end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Solution}

\sphinxAtStartPar
The matrix \(A\) is already in echelon form. The equivalent system of equations is
\begin{alignat*}{4}
 x_1 & \quad & & {}-{} & 8x_3 & {}-{} 7x_4 & {}={} & 0\\
& \quad & x_2 & {}+{} & 4x_3 & {}+{} 3x_4 & {}={} & 0
 \end{alignat*}
\sphinxAtStartPar
which can be written in parametric form:
\begin{alignat*}{3}
 x_1 & {}={} & 8x_3 & {}+{} & 7x_4\\
x_2 & {}={} & -4x_3 & {}-{} & 3x_4\\
  x_3 & {}={} & x_3 & &\\
 x_4 & {}={} & & & x_4.
 \end{alignat*}
\sphinxAtStartPar
Or as a \sphinxstyleemphasis{vector equation}:
\begin{equation*}
\begin{split}x = \begin{pmatrix}x_1\\x_2\\x_3\\x_4\end{pmatrix}
 = x_3\begin{pmatrix}8\\-4\\1\\0\end{pmatrix}
 + x_4\begin{pmatrix}7\\-3\\0\\1\end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
for any \(x_3, x_4 \in \mathbb{R}\).

\sphinxAtStartPar
The two vectors \(\begin{pmatrix}8 \\-4\\ 1 \\ 0\end{pmatrix}\) and \(\begin{pmatrix}7 \\ -3 \\ 0\\1\end{pmatrix}\) are the special solutions corresponding to the free variables \(x_3\) and \(x_4\) respectively. The solution is the set of all linear combinations of the special solutions.

\sphinxAtStartPar
\sphinxstylestrong{The solution set is a plane passing through the origin}.
\end{sphinxadmonition}


\subsection{Solving \protect\(Ax = b\protect\)}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices:solving-ax-b}}
\sphinxAtStartPar
We now have everything we need to find the general solution to the inhomogeneous equation
\begin{equation*}
\begin{split}Ax=b\end{split}
\end{equation*}
\begin{sphinxadmonition}{note}{The general solution to \protect\(Ax = b\protect\)}

\sphinxAtStartPar
Let \(A\) be an \((m \times n)\) matrix and \(b\) a length\sphinxhyphen{}\(m\) vector. Then the general solution to
\begin{equation*}
\begin{split}Ax=b\end{split}
\end{equation*}
\sphinxAtStartPar
is
\begin{equation*}
\begin{split}x = t_1v_1 + \cdots + t_kv_k + v_0\end{split}
\end{equation*}
\sphinxAtStartPar
where \(t_1, \ldots\ t_k \in \mathbb{R}\) are real numbers and \(v_1, \ldots, v_k\) are the \(k\) special solutions corresponding to the \(k\) free variables.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Form the augmented matrix \(A|b\).

\item {} 
\sphinxAtStartPar
Use Gaussian elimination to find the reduced row echelon form and determine the \(k\) free variables.

\item {} 
\sphinxAtStartPar
Write the parametric form of the solution set (write the corresponding system of linear equations, moving all free variables to the right hand side.)

\item {} 
\sphinxAtStartPar
Write the solution as a vector equation \(v = t_1v_1 + \ldots + t_kv_k + v_0\).

\end{enumerate}
\end{sphinxadmonition}

\begin{sphinxadmonition}{note}{Example}

\sphinxAtStartPar
Determine the general solution to the following system of equations, expressing the answer in vector form:
\begin{equation*}
\begin{split}
\begin{alignat*}{5}
-2x_1 & {}-{} & 4x_2 & {}-{} & 2x_3 & {}-{} & 10x_4 {}={} & 0\\
2x_1 & {}+{} & 4x_2 & {}+{} & x_3 & {}+{} & 9x_4 {}={} & -2\\
3x_1 & {}+{} & 6x_2 & {}+{} & x_3 & {}+{} & 13x_4 {}={} & -4.
\end{alignat*}\end{split}
\end{equation*}
\sphinxAtStartPar
\sphinxstylestrong{Solution}

\sphinxAtStartPar
The augmented matrix is:
\begin{equation*}
\begin{split}
\left(
\begin{array}{cccc|c}
-2 & -4 & -2 & -10 & 0\\
2 & 4 & 1 & 9 & -2\\
3 & 6 & 1 & 13 & -4
\end{array}\right).
\end{split}
\end{equation*}
\sphinxAtStartPar
We have already determined the reduced row echelon form in  {\hyperref[\detokenize{LinearAlgebra/linear_systems_matrices/echelon_form:ex-gaussian-elimination}]{\sphinxcrossref{\DUrole{std,std-ref}{this example}}}}:
\begin{equation*}
\begin{split}
\left(
\begin{array}{cccc|c}
\boxed{1} & 2 & 0 & 4 & -2\\
0 & 0 & \boxed{1} & 1 & 2\\
0 & 0 & 0 & 0 & 0
\end{array}\right).
\end{split}
\end{equation*}
\sphinxAtStartPar
Write as a system of equations with the free variables \(x_2\) and \(x_4\) on the right hand side:
\begin{equation*}
\begin{split}
\begin{alignat*}{4}
x_1 & {}={} & -2x_2 & {}-{} & 4x_4 & {}-{} & 2\\
x_2 & {}={} & x_2\\
x_3 & {}={} &       &       & -x_4 & {}+{} & 2\\
x_4 & {}={} & x_4
\end{alignat*}.\end{split}
\end{equation*}
\sphinxAtStartPar
Write this in vector form:
\begin{equation*}
\begin{split}
\begin{pmatrix}x_1\\x_2\\x_3\\x_4\end{pmatrix} = \begin{pmatrix}-2x_2&-4x_4&-2\\x_2&&\\&-x_4&+2\\&x_4&\end{pmatrix} = x_2\begin{pmatrix}-2\\1\\0\\0\end{pmatrix} + x_4\begin{pmatrix}-4\\0\\-1\\1\end{pmatrix} + \begin{pmatrix}-2\\0\\2\\0\end{pmatrix}
\end{split}
\end{equation*}
\sphinxAtStartPar
for any \(x_2, x_4 \in \mathbb{R}\).
\end{sphinxadmonition}
\phantomsection \label{exercise:q_solve_system}

\begin{sphinxadmonition}{note}{Exercise 12.4}



\sphinxAtStartPar
For the matrix
\begin{equation*}
\begin{split}A = \begin{pmatrix}1 & 1 \\ 0 & 0\end{pmatrix},\end{split}
\end{equation*}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
What are the special solution(s) to the homogeneous equation \(Ax=0\)?

\item {} 
\sphinxAtStartPar
What is the null space of \(A\)?

\item {} 
\sphinxAtStartPar
Find the general solution to \(Ax = b\)  where \(b = \begin{pmatrix}5 \\ 0\end{pmatrix}\). Describe the solution geometrically.

\end{enumerate}
\end{sphinxadmonition}


\section{Solutions}
\label{\detokenize{LinearAlgebra/linear_systems_matrices/matrices:solutions}}\phantomsection \label{LinearAlgebra/linear_systems_matrices/matrices:LinearAlgebra/linear_systems_matrices/matrices-solution-4}

\begin{sphinxadmonition}{note}{Solution to Exercise 12.1}



\sphinxAtStartPar
1. \(A\) is a (3 x 2) matrix, since it has 3 rows and 2 columns.
Matrices are nearly always given upper case letters as variable names.

\sphinxAtStartPar
\(b\) is a (3 x 1) matrix.
Matrices with a single column are a special case, called a column vector.

\sphinxAtStartPar
\(c\) is a (1 x 1) matrix.
In that case, we could dispense with the brackets, since it is equivalent to a scalar (basically just a single value).

\sphinxAtStartPar
2. The element in the second row and third column of the transpose matrix is the element in the third row and second column of the original matrix, so the result is \sphinxhyphen{}4.

\sphinxAtStartPar
3. The only upper\sphinxhyphen{}triangular matrix here is \(A\). Matrix \(B\) is an upper anti\sphinxhyphen{}triangular matrix and matrix \(C\) is a lower triangular matrix
\end{sphinxadmonition}
\phantomsection \label{LinearAlgebra/linear_systems_matrices/matrices:LinearAlgebra/linear_systems_matrices/matrices-solution-5}

\begin{sphinxadmonition}{note}{Solution to Exercise 12.2}



\sphinxAtStartPar
Matrix addition is both commutative and associative, because it is an elementwise operation and therefore has the same properties as addition of real numbers. Thus, the first two expressions give the same result:

\sphinxAtStartPar
1. and 2. \((A+B)+C=A+(B+C)=\left(\begin{array}{cc}1-4+0 & 2+1+3 \\-1+1+4 & 0+2+2 \\3-2+1 & 1+3+1 \\\end{array}\right)=\left(\begin{array}{cc}-3 & 6 \\4 & 4 \\2 & 5 \\\end{array}\right)\)

\sphinxAtStartPar
3. \(A-2 B+\frac{C}{2}=\left(\begin{array}{cc}1+8+0 & 2-2+\frac{3}{2} \\-1-2+2 & 0-4+1 \\3+4+\frac{1}{2} & 1-6+\frac{1}{2} \\\end{array}\right)=\left(\begin{array}{cc}9 & \frac{3}{2} \\-1 & -3 \\\frac{15}{2} & -\frac{9}{2} \\\end{array}\right)\)

\sphinxAtStartPar
4. Since \(A\) and \(D\) are not the same order, these two matrices cannot be added
\end{sphinxadmonition}
\phantomsection \label{LinearAlgebra/linear_systems_matrices/matrices:LinearAlgebra/linear_systems_matrices/matrices-solution-6}

\begin{sphinxadmonition}{note}{Solution to Exercise 12.3}



\sphinxAtStartPar
1.

\sphinxAtStartPar
\(A B=\left(\begin{array}{cc}(3\times 2)+(1 \times-3)+(-2\times 1) & (3\times 3)+(1\times 0)+(-2\times 1) \\ (0\times 2)+(2\times -3)+(4\times 1) & (0\times 3)+(2\times 0)+(4\times 1) \end{array}\right)=\left(\begin{array}{cc}1 & 7 \\-2 & 4 \end{array}\right)\)

\sphinxAtStartPar
We multiplied a (2x3) matrix with a (3x2) matrix. The result is a (2x2) matrix. The two results are not the same, and do not even have the same dimensions.

\sphinxAtStartPar
In general, \(A B\neq B A\), even when \(A\) and \(B\) are square matrices. That is, matrix multiplication is NOT COMMUTATIVE.

\sphinxAtStartPar
According to the definition \(A B_{i,j}= \sum _k A_{i,k} B_{k,j}\), whilst \(B A_{i,j}= \sum _k A_{k,j} B_{i,k}\). In the first case, the multiplied elements come from the \(i^{th}\) row of \(A\) and the \(j^{th}\) column of \(B\). In the second case, the multiplied elements come from the \(i^{th}\) row of \(B\) and the \(j^{th}\) column of \(A\)

\sphinxAtStartPar
2. The given result cannot be calculated because the inner dimensions do not match. That is, the number of columns in the left hand matrix does not match the number of rows in the right hand matrix.

\sphinxAtStartPar
3. Since \(A\) is (2x3) and \(C\) is (3x4), the result \(AC\) is (2x4). Notice that the result \(CA\) is impossible.

\sphinxAtStartPar
4. The element in the second row and third column is given by multiplying the second row of \(A\) and the third column of \(C\) to give \((0\times 2)+(2 \times -3)+(4 \times8)=26\).

\sphinxAtStartPar
5. \(\left(\begin{array}{ccc}9 & 4 & 8 \\4 & 3 & 5 \\4 & 4 & 7 \\\end{array}\right)\)
\end{sphinxadmonition}
\phantomsection \label{LinearAlgebra/linear_systems_matrices/matrices:LinearAlgebra/linear_systems_matrices/matrices-solution-7}

\begin{sphinxadmonition}{note}{Solution to Exercise 12.4}



\sphinxAtStartPar
The matrix \(A\) is already in reduced row echelon form, and \(x_1\) is a pivot variable and \(x_2\) a free variable.
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
There is one special solution corresponding to \(x_2=1\) and it is \(\begin{pmatrix}x_1\\x_2\end{pmatrix}=\begin{pmatrix}-1\\1\end{pmatrix}\)

\item {} 
\sphinxAtStartPar
The null space is the space of all vectors \(t\begin{pmatrix}-1\\1\end{pmatrix}, t \in \mathbb{R}\).

\item {} 
\sphinxAtStartPar
The general solution to \(Ax = b\) is \(x = t\begin{pmatrix}-1\\1\end{pmatrix} + \begin{pmatrix}5\\0\end{pmatrix}\) for \(t \in \mathbb{R}\) which is a straight line parallel to \(\begin{pmatrix}-1\\1\end{pmatrix}\) through the point \(\begin{pmatrix}5\\0\end{pmatrix}\).

\end{enumerate}
\end{sphinxadmonition}


\chapter{Linear Algebra \sphinxhyphen{} Problem Sheet 1}
\label{\detokenize{LinearAlgebra/problems/problems_1:linear-algebra-problem-sheet-1}}\label{\detokenize{LinearAlgebra/problems/problems_1::doc}}

\section{Question 1}
\label{\detokenize{LinearAlgebra/problems/problems_1:question-1}}


\sphinxAtStartPar
Solve the following system of linear equations by transforming its augmented matrix to reduced echelon form. Which are the free variables and pivot variables? Write your answer in parametric vector form and describe the solution geometrially.
\begin{equation*}
\begin{split}
\begin{align}
x_1 - x_3 - 3x_5 &= 1\\
3x_1 + x_2 - x_3 + x_4 - 9x_5 &= 3\\
x_1 - x_3 + x_4 - 2x_5 &= 1.
\end{align}
\end{split}
\end{equation*}

\section{Question 2}
\label{\detokenize{LinearAlgebra/problems/problems_1:question-2}}


\sphinxAtStartPar
1. Reduce \(A\) and \(B\) to row echelon form. Which variables are free?

\sphinxAtStartPar
a) \(A = \begin{pmatrix}
1 & 2 & 2 & 4 & 6\\
1 & 2 & 3 & 6 & 9\\
0 & 0 & 1 & 2 & 3
\end{pmatrix}\)
b) \(B = \begin{pmatrix}
2 & 4 & 2\\
0 & 4 & 4\\
0 & 8 & 8\\
\end{pmatrix}\)

\sphinxAtStartPar
2. For the matrices \(A\) and \(B\), find a special solution for each free variable.

\sphinxAtStartPar
3. Calculate the null space of each matrix.

\sphinxAtStartPar
4. \sphinxstyleemphasis{True or False, with explanation}: The null space of a matrix is the same as the null space of its reduced echelon form.


\section{Question 3}
\label{\detokenize{LinearAlgebra/problems/problems_1:question-3}}


\sphinxAtStartPar
Kirchoff’s Law states that at a junction of an electrical circuit \(\mathrm{current~in}=\mathrm{current~out}\). At junction \(1\) this says that \(y_3 = y_1+y_4\).

\noindent{\hspace*{\fill}\sphinxincludegraphics[width=300\sphinxpxdimen]{{kirchoff}.png}\hspace*{\fill}}
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
Write the four equations for Kirchoff’s Law at each of the four nodes.

\item {} 
\sphinxAtStartPar
Reduce the resulting matrix to reduced row echelon form.

\item {} 
\sphinxAtStartPar
Write down the three special solutions.

\item {} 
\sphinxAtStartPar
Calculate the full solution to the system in vector form.

\end{enumerate}


\section{Question 4}
\label{\detokenize{LinearAlgebra/problems/problems_1:question-4}}


\sphinxAtStartPar
Find a cubic polynomial
\begin{equation*}
\begin{split}p(x) = a + bx + cx^2 + dx^3\end{split}
\end{equation*}
\sphinxAtStartPar
such that \(p(1) = 1, p'(1)=5, p(-1)=3\) and \(p'(-1)=1\).


\section{Question 5}
\label{\detokenize{LinearAlgebra/problems/problems_1:question-5}}\begin{equation*}
\begin{split}A = \begin{pmatrix}1 & 2\\ 3 & 4\end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
1. Find all matrices
\begin{equation*}
\begin{split}B = \begin{pmatrix}x_{11} & x_{12} \\ x_{21} & x_{22}\end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
such that \(AB=BA\).

\sphinxAtStartPar
2. Use your answer to part 1 to find a \((2 \times 2)\) matrix \(C\) such that \(AC\neq CA\).


\section{Question 6}
\label{\detokenize{LinearAlgebra/problems/problems_1:question-6}}


\sphinxAtStartPar
Let
\begin{equation*}
\begin{split}M = \begin{pmatrix}1 & 0 & 2\\-2 & 0 & -3\\0 & 2 & 0\end{pmatrix}.\end{split}
\end{equation*}
\sphinxAtStartPar
We can reduce \(M\) to reduced row echelon form by perform a sequence of \sphinxstyleemphasis{elementary row operations}. The first elementary row operation is \(r_2 + 2r_1 \rightarrow r_2\).

\sphinxAtStartPar
An \sphinxstyleemphasis{elementary matrix} is a matrix which has the same effect as an elementary row operation. For example, left\sphinxhyphen{}multiplying by
\begin{equation*}
\begin{split}E_1 = \begin{pmatrix}1 & 0 & 0\\2 & 1 & 0\\0 & 0 & 1\end{pmatrix}\end{split}
\end{equation*}
\sphinxAtStartPar
has the same effect as the elementary row operation \(r_2 + 2r_1 \rightarrow r_2\).

\sphinxAtStartPar
1. Calculate \(E_1M\) to show that left\sphinxhyphen{}multiplying by \(E_1\) has the same effect as the elementary row operation on the matrix \(M\).

\sphinxAtStartPar
2. Determine the elementary matrix \(E_2\) that has the same effect as the elementary row operation \(r_2 \leftrightarrow r_3\), then calculate \(E_2\left(E_1M\right)\).

\sphinxAtStartPar
3. Determine the remaining two elementary row operations that reduce the matrix \(M\) to row reduced form and calculate the elementary matrices \(E_3\) and \(E_4\).

\sphinxAtStartPar
4. Calculate the matrix \(A = \left(\left(\left(E_4\right)E_3\right)E_2\right)E_1\) and check that
\begin{equation*}
\begin{split}AM = \begin{pmatrix}1 & 0 & 0\\0 & 1 & 0\\0 & 0 & 1\end{pmatrix}.\end{split}
\end{equation*}

\chapter{Liner Algebra \sphinxhyphen{} Answers to Problem Sheet 1}
\label{\detokenize{LinearAlgebra/problems/solutions_1:liner-algebra-answers-to-problem-sheet-1}}\label{\detokenize{LinearAlgebra/problems/solutions_1::doc}}

\section{Question 1}
\label{\detokenize{LinearAlgebra/problems/solutions_1:question-1}}
\sphinxAtStartPar
Write as augmented matrix then reduce to echelon form (NB I have omitted the vertical line):
\begin{equation*}
\begin{split}
\begin{array}{rc}
\begin{array}{ccr}
 & & (r_1)\\
 & & (r_2)\\
& & (r_3)
\end{array}
&
\begin{pmatrix}
1 & 0 & -1 & 0 & -3 & 1\\
3 & 1 & -1 & 1 & -9 & 3\\
1 & 0 & -1 & 1 & -2 & 1
\end{pmatrix}\\
\begin{array}{ccr}
  & & (r_1)\\
r_2 - 3r_1 & \longrightarrow & (r_2)\\
r_3 - r_1 & \longrightarrow & (r_3)
\end{array}
&
\begin{pmatrix}
1 & 0 & -1 & 9 & -3 & 1\\
0 & 1 & 2 & 1 & 0 & 0\\
0 & 0 & 0 & 1 & 1 & 0
\end{pmatrix}\\
\begin{array}{ccr}
 & & (r_1)\\
 r_2 - 2r_3 & \longrightarrow & (r_2)\\
 & & (r_3)
\end{array}
&
\begin{pmatrix}
1 & 0 & -3 & 0 & -3 & 1\\
0 & 1 & 2 & 0 & -1 & 0\\
0 & 0 & 0 & 1 & 1 & 0
\end{pmatrix}
\end{array}
\end{split}
\end{equation*}
\sphinxAtStartPar
Write the pivot variables in terms of the free variables to find the general solution:
\begin{equation*}
\begin{split}
\begin{align*}
x_1 &= 3x_3 + 5x_5 + 1\\
x_2 &= -2x_3 + x_5\\
x_4 &= -x_5
\end{align*}
\end{split}
\end{equation*}
\sphinxAtStartPar
for any \(x_3, x_5 \in \mathbb{R}\).

\sphinxAtStartPar
Finally we can write the solution in vector form:
\begin{equation*}
\begin{split}
\begin{pmatrix}x_1\\x_2\\x_3\\x_4\\x_5\end{pmatrix} = \begin{pmatrix}x_3 +3x_5 + 1\\-2x_3+x_5\\x_3\\-x_5\\x_5\end{pmatrix} = x_3\begin{pmatrix}1\\-2\\1\\0\\0\end{pmatrix} + x_5\begin{pmatrix}3\\1\\0\\-1\\1\end{pmatrix} + \begin{pmatrix}1\\0\\0\\0\\0\end{pmatrix}.
\end{split}
\end{equation*}
\sphinxAtStartPar
This is the equation of a plane in \(\mathbb{R}^5\) parallel to \(\begin{pmatrix}1\\-2\\1\\0\\0\end{pmatrix}\) and \(\begin{pmatrix}3\\1\\0\\-1\\1\end{pmatrix}\) and passing through the point \(\begin{pmatrix}1\\0\\0\\0\\0\end{pmatrix}\).


\section{Application: Kirchoff’s Law}
\label{\detokenize{LinearAlgebra/problems/solutions_1:application-kirchoffs-law}}
\sphinxAtStartPar
In general, Gaussian elimination can be used to solve the problems obtained by applying Kirchoff’s laws. For example, see the problems given here:

\sphinxAtStartPar
\sphinxurl{https://www.intmath.com/matrices-determinants/6-matrices-linear-equations.php}

\sphinxAtStartPar
In the example below, the technique is applied to a case where the system of equations is under\sphinxhyphen{}determined, so a unique solution cannot be obtained.

\begin{sphinxadmonition}{note}{Kirchoff’s Law}

\sphinxAtStartPar
Kirchoff’s law states that
\begin{equation*}
\begin{split}\mathrm{current~in} = \mathrm{current~out}\end{split}
\end{equation*}\end{sphinxadmonition}

\sphinxAtStartPar
For the system of 4 nodes shown above, this gives us four equations:
\label{equation:LinearAlgebra/problems/solutions_1:46785d17-49ea-476d-a7cd-7200c5c65151}\begin{align}y_3&=y_1+y_4\\y_1&=y_2+y_5\\y_2&=y_3+y_6\\y_4+y_5+y_6&=0\end{align}
\sphinxAtStartPar
The equations at each node are of the form \(c_1 y_1 +c_2 y_2+\dots +c_6 y_6=d\). Written in augmented matrix form, the system is:
\begin{equation*}
\begin{split}\left(\begin{array}{cccccc:c}1 & 0 & -1 & 1 & 0 & 0 &0\\-1 & 1 & 0 & 0 & 1 & 0&0 \\0 & -1 & 1 & 0 & 0 & 1&0 \\0 & 0 & 0 & -1 & -1 & -1 &0\\\end{array}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
The first 6 columns are for the coefficients of \(y_1,\dots y_6\) and the last column is the constant term that appears on the right hand side of the equation.

\sphinxAtStartPar
Here, Gaussian elimination is applied as usual, but the complicating factor is that there are more unknowns than equations and so the system is under\sphinxhyphen{}determined. It has “free variables”, that can be made to take any value!

\sphinxAtStartPar
After applying Gaussian elimination to the pivot elements in the first and second column, we can’t do anything with the third column without spoiling the progress we’ve made in the first two columns, so we leave that one and move on to use the fourth column as a pivot. After that, we can’t make any more progress so we stop. We obtain:
\begin{equation*}
\begin{split}\left(\begin{array}{cccccc:c}1 & 0 & -1 & 0 & -1 & -1 & 0 \\0 & 1 & -1 & 0 & 0 & -1 & 0 \\0 & 0 & 0 & 1 & 1 & 1 & 0 \\0 & 0 & 0 & 0 & 0 & 0 & 0 \\\end{array}\right)\end{split}
\end{equation*}
\sphinxAtStartPar
The first, second, and fourth columns are the pivot columns, and the other columns are all “free” since they can be obtained from a combination of the other columns.

\sphinxAtStartPar
Choosing \((y_3,y_5,y_6)=(1,0,0)\) gives the special solution \(s_1:(1,1,1,0,0,0)\)Choosing \((y_3,y_5,y_6)=(0,1,0)\) gives the special solution \(s_2:(1,0,0,-1,1,0)\)Choosing \((y_3,y_5,y_6)=(0,0,1)\) gives the special solution \(s_3:(1,1,0,-1,0,1)\)

\sphinxAtStartPar
The full solution space consists of all possible linear combinations \(a s_1 + b s_2 +c s_3\).







\renewcommand{\indexname}{Index}
\printindex
\end{document}